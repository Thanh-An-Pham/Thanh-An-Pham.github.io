{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP 2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2pUwZEIWzZmZ"},"source":["# **1. Prepare Movie Review Data for Sentiment Analysis**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7OEtL0oDrwt","executionInfo":{"status":"ok","timestamp":1637563732095,"user_tz":-420,"elapsed":16324,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"}},"outputId":"9810d206-e9fb-4fc5-af3c-2c3ad0443188"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"ee7yf5lKzo5T"},"source":["## 1.1. Load Text Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-X9Ycm2Wzf9m","executionInfo":{"status":"ok","timestamp":1637563761804,"user_tz":-420,"elapsed":6466,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"}},"outputId":"5e1e3c14-fda9-43e5-c6bb-4f59b45fc30d"},"source":["# load one file\n","filename = '/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg/cv000_29416.txt'\n","#filename = '/home/labhhc/GoogleDrive/SharedDataset/review_polarity/txt_sentoken/neg/cv000_29416.txt'\n","# open the file as read only\n","file = open(filename, 'r')\n","# read all text\n","text = file.read()\n","# close the file\n","file.close()\n","\n","print(text[:100])"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["plot : two teen couples go to a church party , drink and then drive . \n","they get into an accident . \n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rPXMDZNR0JfT","executionInfo":{"status":"ok","timestamp":1637564016835,"user_tz":-420,"elapsed":233857,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"}},"outputId":"073e9bd6-863e-41e1-f774-f85e18203387"},"source":["from os import listdir # get list of files\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  #close the file\n","  file.close()\n","  return text\n","\n","# specifiy directory to load\n","directory = '/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg'\n","# walk through all files in the folder\n","for filename in listdir(directory):\n","  # skip files that do not have the right extension\n","  if not filename.endswith(\".txt\"):\n","    next\n","  # create the full path of the file to open\n","  path = directory + '/' + filename\n","  # load documnet\n","  doc = load_doc(path)\n","  print('Loaded %s'% filename)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded cv000_29416.txt\n","Loaded cv001_19502.txt\n","Loaded cv002_17424.txt\n","Loaded cv003_12683.txt\n","Loaded cv004_12641.txt\n","Loaded cv005_29357.txt\n","Loaded cv006_17022.txt\n","Loaded cv007_4992.txt\n","Loaded cv008_29326.txt\n","Loaded cv009_29417.txt\n","Loaded cv010_29063.txt\n","Loaded cv011_13044.txt\n","Loaded cv012_29411.txt\n","Loaded cv013_10494.txt\n","Loaded cv014_15600.txt\n","Loaded cv015_29356.txt\n","Loaded cv016_4348.txt\n","Loaded cv017_23487.txt\n","Loaded cv018_21672.txt\n","Loaded cv019_16117.txt\n","Loaded cv020_9234.txt\n","Loaded cv021_17313.txt\n","Loaded cv022_14227.txt\n","Loaded cv023_13847.txt\n","Loaded cv024_7033.txt\n","Loaded cv025_29825.txt\n","Loaded cv026_29229.txt\n","Loaded cv027_26270.txt\n","Loaded cv028_26964.txt\n","Loaded cv029_19943.txt\n","Loaded cv030_22893.txt\n","Loaded cv031_19540.txt\n","Loaded cv032_23718.txt\n","Loaded cv033_25680.txt\n","Loaded cv034_29446.txt\n","Loaded cv035_3343.txt\n","Loaded cv036_18385.txt\n","Loaded cv037_19798.txt\n","Loaded cv038_9781.txt\n","Loaded cv039_5963.txt\n","Loaded cv040_8829.txt\n","Loaded cv041_22364.txt\n","Loaded cv042_11927.txt\n","Loaded cv043_16808.txt\n","Loaded cv044_18429.txt\n","Loaded cv045_25077.txt\n","Loaded cv046_10613.txt\n","Loaded cv047_18725.txt\n","Loaded cv048_18380.txt\n","Loaded cv049_21917.txt\n","Loaded cv050_12128.txt\n","Loaded cv051_10751.txt\n","Loaded cv052_29318.txt\n","Loaded cv053_23117.txt\n","Loaded cv054_4101.txt\n","Loaded cv055_8926.txt\n","Loaded cv056_14663.txt\n","Loaded cv057_7962.txt\n","Loaded cv058_8469.txt\n","Loaded cv059_28723.txt\n","Loaded cv060_11754.txt\n","Loaded cv061_9321.txt\n","Loaded cv062_24556.txt\n","Loaded cv063_28852.txt\n","Loaded cv064_25842.txt\n","Loaded cv065_16909.txt\n","Loaded cv066_11668.txt\n","Loaded cv067_21192.txt\n","Loaded cv068_14810.txt\n","Loaded cv069_11613.txt\n","Loaded cv070_13249.txt\n","Loaded cv071_12969.txt\n","Loaded cv072_5928.txt\n","Loaded cv073_23039.txt\n","Loaded cv074_7188.txt\n","Loaded cv075_6250.txt\n","Loaded cv076_26009.txt\n","Loaded cv077_23172.txt\n","Loaded cv078_16506.txt\n","Loaded cv079_12766.txt\n","Loaded cv080_14899.txt\n","Loaded cv081_18241.txt\n","Loaded cv082_11979.txt\n","Loaded cv083_25491.txt\n","Loaded cv084_15183.txt\n","Loaded cv085_15286.txt\n","Loaded cv086_19488.txt\n","Loaded cv087_2145.txt\n","Loaded cv088_25274.txt\n","Loaded cv089_12222.txt\n","Loaded cv090_0049.txt\n","Loaded cv091_7899.txt\n","Loaded cv092_27987.txt\n","Loaded cv093_15606.txt\n","Loaded cv094_27868.txt\n","Loaded cv095_28730.txt\n","Loaded cv096_12262.txt\n","Loaded cv097_26081.txt\n","Loaded cv098_17021.txt\n","Loaded cv099_11189.txt\n","Loaded cv100_12406.txt\n","Loaded cv101_10537.txt\n","Loaded cv102_8306.txt\n","Loaded cv103_11943.txt\n","Loaded cv104_19176.txt\n","Loaded cv105_19135.txt\n","Loaded cv106_18379.txt\n","Loaded cv107_25639.txt\n","Loaded cv108_17064.txt\n","Loaded cv109_22599.txt\n","Loaded cv110_27832.txt\n","Loaded cv111_12253.txt\n","Loaded cv112_12178.txt\n","Loaded cv113_24354.txt\n","Loaded cv114_19501.txt\n","Loaded cv115_26443.txt\n","Loaded cv116_28734.txt\n","Loaded cv117_25625.txt\n","Loaded cv118_28837.txt\n","Loaded cv119_9909.txt\n","Loaded cv120_3793.txt\n","Loaded cv121_18621.txt\n","Loaded cv122_7891.txt\n","Loaded cv123_12165.txt\n","Loaded cv124_3903.txt\n","Loaded cv125_9636.txt\n","Loaded cv126_28821.txt\n","Loaded cv127_16451.txt\n","Loaded cv128_29444.txt\n","Loaded cv129_18373.txt\n","Loaded cv130_18521.txt\n","Loaded cv131_11568.txt\n","Loaded cv132_5423.txt\n","Loaded cv133_18065.txt\n","Loaded cv134_23300.txt\n","Loaded cv135_12506.txt\n","Loaded cv136_12384.txt\n","Loaded cv137_17020.txt\n","Loaded cv138_13903.txt\n","Loaded cv139_14236.txt\n","Loaded cv140_7963.txt\n","Loaded cv141_17179.txt\n","Loaded cv142_23657.txt\n","Loaded cv143_21158.txt\n","Loaded cv144_5010.txt\n","Loaded cv145_12239.txt\n","Loaded cv146_19587.txt\n","Loaded cv147_22625.txt\n","Loaded cv148_18084.txt\n","Loaded cv149_17084.txt\n","Loaded cv150_14279.txt\n","Loaded cv151_17231.txt\n","Loaded cv152_9052.txt\n","Loaded cv153_11607.txt\n","Loaded cv154_9562.txt\n","Loaded cv155_7845.txt\n","Loaded cv156_11119.txt\n","Loaded cv157_29302.txt\n","Loaded cv158_10914.txt\n","Loaded cv159_29374.txt\n","Loaded cv160_10848.txt\n","Loaded cv161_12224.txt\n","Loaded cv162_10977.txt\n","Loaded cv163_10110.txt\n","Loaded cv164_23451.txt\n","Loaded cv165_2389.txt\n","Loaded cv166_11959.txt\n","Loaded cv167_18094.txt\n","Loaded cv168_7435.txt\n","Loaded cv169_24973.txt\n","Loaded cv170_29808.txt\n","Loaded cv171_15164.txt\n","Loaded cv172_12037.txt\n","Loaded cv173_4295.txt\n","Loaded cv174_9735.txt\n","Loaded cv175_7375.txt\n","Loaded cv176_14196.txt\n","Loaded cv177_10904.txt\n","Loaded cv178_14380.txt\n","Loaded cv179_9533.txt\n","Loaded cv180_17823.txt\n","Loaded cv181_16083.txt\n","Loaded cv182_7791.txt\n","Loaded cv183_19826.txt\n","Loaded cv184_26935.txt\n","Loaded cv185_28372.txt\n","Loaded cv186_2396.txt\n","Loaded cv187_14112.txt\n","Loaded cv188_20687.txt\n","Loaded cv189_24248.txt\n","Loaded cv190_27176.txt\n","Loaded cv191_29539.txt\n","Loaded cv192_16079.txt\n","Loaded cv193_5393.txt\n","Loaded cv194_12855.txt\n","Loaded cv195_16146.txt\n","Loaded cv196_28898.txt\n","Loaded cv197_29271.txt\n","Loaded cv198_19313.txt\n","Loaded cv199_9721.txt\n","Loaded cv200_29006.txt\n","Loaded cv201_7421.txt\n","Loaded cv202_11382.txt\n","Loaded cv203_19052.txt\n","Loaded cv204_8930.txt\n","Loaded cv205_9676.txt\n","Loaded cv206_15893.txt\n","Loaded cv207_29141.txt\n","Loaded cv208_9475.txt\n","Loaded cv209_28973.txt\n","Loaded cv210_9557.txt\n","Loaded cv211_9955.txt\n","Loaded cv212_10054.txt\n","Loaded cv213_20300.txt\n","Loaded cv214_13285.txt\n","Loaded cv215_23246.txt\n","Loaded cv216_20165.txt\n","Loaded cv217_28707.txt\n","Loaded cv218_25651.txt\n","Loaded cv219_19874.txt\n","Loaded cv220_28906.txt\n","Loaded cv221_27081.txt\n","Loaded cv222_18720.txt\n","Loaded cv223_28923.txt\n","Loaded cv224_18875.txt\n","Loaded cv225_29083.txt\n","Loaded cv226_26692.txt\n","Loaded cv227_25406.txt\n","Loaded cv228_5644.txt\n","Loaded cv229_15200.txt\n","Loaded cv230_7913.txt\n","Loaded cv231_11028.txt\n","Loaded cv232_16768.txt\n","Loaded cv233_17614.txt\n","Loaded cv234_22123.txt\n","Loaded cv235_10704.txt\n","Loaded cv236_12427.txt\n","Loaded cv237_20635.txt\n","Loaded cv238_14285.txt\n","Loaded cv239_29828.txt\n","Loaded cv240_15948.txt\n","Loaded cv241_24602.txt\n","Loaded cv242_11354.txt\n","Loaded cv243_22164.txt\n","Loaded cv244_22935.txt\n","Loaded cv245_8938.txt\n","Loaded cv246_28668.txt\n","Loaded cv247_14668.txt\n","Loaded cv248_15672.txt\n","Loaded cv249_12674.txt\n","Loaded cv250_26462.txt\n","Loaded cv251_23901.txt\n","Loaded cv252_24974.txt\n","Loaded cv253_10190.txt\n","Loaded cv254_5870.txt\n","Loaded cv255_15267.txt\n","Loaded cv256_16529.txt\n","Loaded cv257_11856.txt\n","Loaded cv258_5627.txt\n","Loaded cv259_11827.txt\n","Loaded cv260_15652.txt\n","Loaded cv261_11855.txt\n","Loaded cv262_13812.txt\n","Loaded cv263_20693.txt\n","Loaded cv264_14108.txt\n","Loaded cv265_11625.txt\n","Loaded cv266_26644.txt\n","Loaded cv267_16618.txt\n","Loaded cv268_20288.txt\n","Loaded cv269_23018.txt\n","Loaded cv270_5873.txt\n","Loaded cv271_15364.txt\n","Loaded cv272_20313.txt\n","Loaded cv273_28961.txt\n","Loaded cv274_26379.txt\n","Loaded cv275_28725.txt\n","Loaded cv276_17126.txt\n","Loaded cv277_20467.txt\n","Loaded cv278_14533.txt\n","Loaded cv279_19452.txt\n","Loaded cv280_8651.txt\n","Loaded cv281_24711.txt\n","Loaded cv282_6833.txt\n","Loaded cv283_11963.txt\n","Loaded cv284_20530.txt\n","Loaded cv285_18186.txt\n","Loaded cv286_26156.txt\n","Loaded cv287_17410.txt\n","Loaded cv288_20212.txt\n","Loaded cv289_6239.txt\n","Loaded cv290_11981.txt\n","Loaded cv291_26844.txt\n","Loaded cv292_7804.txt\n","Loaded cv293_29731.txt\n","Loaded cv294_12695.txt\n","Loaded cv295_17060.txt\n","Loaded cv296_13146.txt\n","Loaded cv297_10104.txt\n","Loaded cv298_24487.txt\n","Loaded cv299_17950.txt\n","Loaded cv300_23302.txt\n","Loaded cv301_13010.txt\n","Loaded cv302_26481.txt\n","Loaded cv303_27366.txt\n","Loaded cv304_28489.txt\n","Loaded cv305_9937.txt\n","Loaded cv306_10859.txt\n","Loaded cv307_26382.txt\n","Loaded cv308_5079.txt\n","Loaded cv309_23737.txt\n","Loaded cv310_14568.txt\n","Loaded cv311_17708.txt\n","Loaded cv312_29308.txt\n","Loaded cv313_19337.txt\n","Loaded cv314_16095.txt\n","Loaded cv315_12638.txt\n","Loaded cv316_5972.txt\n","Loaded cv317_25111.txt\n","Loaded cv318_11146.txt\n","Loaded cv319_16459.txt\n","Loaded cv320_9693.txt\n","Loaded cv321_14191.txt\n","Loaded cv322_21820.txt\n","Loaded cv323_29633.txt\n","Loaded cv324_7502.txt\n","Loaded cv325_18330.txt\n","Loaded cv326_14777.txt\n","Loaded cv327_21743.txt\n","Loaded cv328_10908.txt\n","Loaded cv329_29293.txt\n","Loaded cv330_29675.txt\n","Loaded cv331_8656.txt\n","Loaded cv332_17997.txt\n","Loaded cv333_9443.txt\n","Loaded cv334_0074.txt\n","Loaded cv335_16299.txt\n","Loaded cv336_10363.txt\n","Loaded cv337_29061.txt\n","Loaded cv338_9183.txt\n","Loaded cv339_22452.txt\n","Loaded cv340_14776.txt\n","Loaded cv341_25667.txt\n","Loaded cv342_20917.txt\n","Loaded cv343_10906.txt\n","Loaded cv344_5376.txt\n","Loaded cv345_9966.txt\n","Loaded cv346_19198.txt\n","Loaded cv347_14722.txt\n","Loaded cv348_19207.txt\n","Loaded cv349_15032.txt\n","Loaded cv350_22139.txt\n","Loaded cv351_17029.txt\n","Loaded cv352_5414.txt\n","Loaded cv353_19197.txt\n","Loaded cv354_8573.txt\n","Loaded cv355_18174.txt\n","Loaded cv356_26170.txt\n","Loaded cv357_14710.txt\n","Loaded cv358_11557.txt\n","Loaded cv359_6751.txt\n","Loaded cv360_8927.txt\n","Loaded cv361_28738.txt\n","Loaded cv362_16985.txt\n","Loaded cv363_29273.txt\n","Loaded cv364_14254.txt\n","Loaded cv365_12442.txt\n","Loaded cv366_10709.txt\n","Loaded cv367_24065.txt\n","Loaded cv368_11090.txt\n","Loaded cv369_14245.txt\n","Loaded cv370_5338.txt\n","Loaded cv371_8197.txt\n","Loaded cv372_6654.txt\n","Loaded cv373_21872.txt\n","Loaded cv374_26455.txt\n","Loaded cv375_9932.txt\n","Loaded cv376_20883.txt\n","Loaded cv377_8440.txt\n","Loaded cv378_21982.txt\n","Loaded cv379_23167.txt\n","Loaded cv380_8164.txt\n","Loaded cv381_21673.txt\n","Loaded cv382_8393.txt\n","Loaded cv383_14662.txt\n","Loaded cv384_18536.txt\n","Loaded cv385_29621.txt\n","Loaded cv386_10229.txt\n","Loaded cv387_12391.txt\n","Loaded cv388_12810.txt\n","Loaded cv389_9611.txt\n","Loaded cv390_12187.txt\n","Loaded cv391_11615.txt\n","Loaded cv392_12238.txt\n","Loaded cv393_29234.txt\n","Loaded cv394_5311.txt\n","Loaded cv395_11761.txt\n","Loaded cv396_19127.txt\n","Loaded cv397_28890.txt\n","Loaded cv398_17047.txt\n","Loaded cv399_28593.txt\n","Loaded cv400_20631.txt\n","Loaded cv401_13758.txt\n","Loaded cv402_16097.txt\n","Loaded cv403_6721.txt\n","Loaded cv404_21805.txt\n","Loaded cv405_21868.txt\n","Loaded cv406_22199.txt\n","Loaded cv407_23928.txt\n","Loaded cv408_5367.txt\n","Loaded cv409_29625.txt\n","Loaded cv410_25624.txt\n","Loaded cv411_16799.txt\n","Loaded cv412_25254.txt\n","Loaded cv413_7893.txt\n","Loaded cv414_11161.txt\n","Loaded cv415_23674.txt\n","Loaded cv416_12048.txt\n","Loaded cv417_14653.txt\n","Loaded cv418_16562.txt\n","Loaded cv419_14799.txt\n","Loaded cv420_28631.txt\n","Loaded cv421_9752.txt\n","Loaded cv422_9632.txt\n","Loaded cv423_12089.txt\n","Loaded cv424_9268.txt\n","Loaded cv425_8603.txt\n","Loaded cv426_10976.txt\n","Loaded cv427_11693.txt\n","Loaded cv428_12202.txt\n","Loaded cv429_7937.txt\n","Loaded cv430_18662.txt\n","Loaded cv431_7538.txt\n","Loaded cv432_15873.txt\n","Loaded cv433_10443.txt\n","Loaded cv434_5641.txt\n","Loaded cv435_24355.txt\n","Loaded cv436_20564.txt\n","Loaded cv437_24070.txt\n","Loaded cv438_8500.txt\n","Loaded cv439_17633.txt\n","Loaded cv440_16891.txt\n","Loaded cv441_15276.txt\n","Loaded cv442_15499.txt\n","Loaded cv443_22367.txt\n","Loaded cv444_9975.txt\n","Loaded cv445_26683.txt\n","Loaded cv446_12209.txt\n","Loaded cv447_27334.txt\n","Loaded cv448_16409.txt\n","Loaded cv449_9126.txt\n","Loaded cv450_8319.txt\n","Loaded cv451_11502.txt\n","Loaded cv452_5179.txt\n","Loaded cv453_10911.txt\n","Loaded cv454_21961.txt\n","Loaded cv455_28866.txt\n","Loaded cv456_20370.txt\n","Loaded cv457_19546.txt\n","Loaded cv458_9000.txt\n","Loaded cv459_21834.txt\n","Loaded cv460_11723.txt\n","Loaded cv461_21124.txt\n","Loaded cv462_20788.txt\n","Loaded cv463_10846.txt\n","Loaded cv464_17076.txt\n","Loaded cv465_23401.txt\n","Loaded cv466_20092.txt\n","Loaded cv467_26610.txt\n","Loaded cv468_16844.txt\n","Loaded cv469_21998.txt\n","Loaded cv470_17444.txt\n","Loaded cv471_18405.txt\n","Loaded cv472_29140.txt\n","Loaded cv473_7869.txt\n","Loaded cv474_10682.txt\n","Loaded cv475_22978.txt\n","Loaded cv476_18402.txt\n","Loaded cv477_23530.txt\n","Loaded cv478_15921.txt\n","Loaded cv479_5450.txt\n","Loaded cv480_21195.txt\n","Loaded cv481_7930.txt\n","Loaded cv482_11233.txt\n","Loaded cv483_18103.txt\n","Loaded cv484_26169.txt\n","Loaded cv485_26879.txt\n","Loaded cv486_9788.txt\n","Loaded cv487_11058.txt\n","Loaded cv488_21453.txt\n","Loaded cv489_19046.txt\n","Loaded cv490_18986.txt\n","Loaded cv491_12992.txt\n","Loaded cv492_19370.txt\n","Loaded cv493_14135.txt\n","Loaded cv494_18689.txt\n","Loaded cv495_16121.txt\n","Loaded cv496_11185.txt\n","Loaded cv497_27086.txt\n","Loaded cv498_9288.txt\n","Loaded cv499_11407.txt\n","Loaded cv500_10722.txt\n","Loaded cv501_12675.txt\n","Loaded cv502_10970.txt\n","Loaded cv503_11196.txt\n","Loaded cv504_29120.txt\n","Loaded cv505_12926.txt\n","Loaded cv506_17521.txt\n","Loaded cv507_9509.txt\n","Loaded cv508_17742.txt\n","Loaded cv509_17354.txt\n","Loaded cv510_24758.txt\n","Loaded cv511_10360.txt\n","Loaded cv512_17618.txt\n","Loaded cv513_7236.txt\n","Loaded cv514_12173.txt\n","Loaded cv515_18484.txt\n","Loaded cv516_12117.txt\n","Loaded cv517_20616.txt\n","Loaded cv518_14798.txt\n","Loaded cv519_16239.txt\n","Loaded cv520_13297.txt\n","Loaded cv521_1730.txt\n","Loaded cv522_5418.txt\n","Loaded cv523_18285.txt\n","Loaded cv524_24885.txt\n","Loaded cv525_17930.txt\n","Loaded cv526_12868.txt\n","Loaded cv527_10338.txt\n","Loaded cv528_11669.txt\n","Loaded cv529_10972.txt\n","Loaded cv530_17949.txt\n","Loaded cv531_26838.txt\n","Loaded cv532_6495.txt\n","Loaded cv533_9843.txt\n","Loaded cv534_15683.txt\n","Loaded cv535_21183.txt\n","Loaded cv536_27221.txt\n","Loaded cv537_13516.txt\n","Loaded cv538_28485.txt\n","Loaded cv539_21865.txt\n","Loaded cv540_3092.txt\n","Loaded cv541_28683.txt\n","Loaded cv542_20359.txt\n","Loaded cv543_5107.txt\n","Loaded cv544_5301.txt\n","Loaded cv545_12848.txt\n","Loaded cv546_12723.txt\n","Loaded cv547_18043.txt\n","Loaded cv548_18944.txt\n","Loaded cv549_22771.txt\n","Loaded cv550_23226.txt\n","Loaded cv551_11214.txt\n","Loaded cv552_0150.txt\n","Loaded cv553_26965.txt\n","Loaded cv554_14678.txt\n","Loaded cv555_25047.txt\n","Loaded cv556_16563.txt\n","Loaded cv557_12237.txt\n","Loaded cv558_29376.txt\n","Loaded cv559_0057.txt\n","Loaded cv560_18608.txt\n","Loaded cv561_9484.txt\n","Loaded cv562_10847.txt\n","Loaded cv563_18610.txt\n","Loaded cv564_12011.txt\n","Loaded cv565_29403.txt\n","Loaded cv566_8967.txt\n","Loaded cv567_29420.txt\n","Loaded cv568_17065.txt\n","Loaded cv569_26750.txt\n","Loaded cv570_28960.txt\n","Loaded cv571_29292.txt\n","Loaded cv572_20053.txt\n","Loaded cv573_29384.txt\n","Loaded cv574_23191.txt\n","Loaded cv575_22598.txt\n","Loaded cv576_15688.txt\n","Loaded cv577_28220.txt\n","Loaded cv578_16825.txt\n","Loaded cv579_12542.txt\n","Loaded cv580_15681.txt\n","Loaded cv581_20790.txt\n","Loaded cv582_6678.txt\n","Loaded cv583_29465.txt\n","Loaded cv584_29549.txt\n","Loaded cv585_23576.txt\n","Loaded cv586_8048.txt\n","Loaded cv587_20532.txt\n","Loaded cv588_14467.txt\n","Loaded cv589_12853.txt\n","Loaded cv590_20712.txt\n","Loaded cv591_24887.txt\n","Loaded cv592_23391.txt\n","Loaded cv593_11931.txt\n","Loaded cv594_11945.txt\n","Loaded cv595_26420.txt\n","Loaded cv596_4367.txt\n","Loaded cv597_26744.txt\n","Loaded cv598_18184.txt\n","Loaded cv599_22197.txt\n","Loaded cv600_25043.txt\n","Loaded cv601_24759.txt\n","Loaded cv602_8830.txt\n","Loaded cv603_18885.txt\n","Loaded cv604_23339.txt\n","Loaded cv605_12730.txt\n","Loaded cv606_17672.txt\n","Loaded cv607_8235.txt\n","Loaded cv608_24647.txt\n","Loaded cv609_25038.txt\n","Loaded cv610_24153.txt\n","Loaded cv611_2253.txt\n","Loaded cv612_5396.txt\n","Loaded cv613_23104.txt\n","Loaded cv614_11320.txt\n","Loaded cv615_15734.txt\n","Loaded cv616_29187.txt\n","Loaded cv617_9561.txt\n","Loaded cv618_9469.txt\n","Loaded cv619_13677.txt\n","Loaded cv620_2556.txt\n","Loaded cv621_15984.txt\n","Loaded cv622_8583.txt\n","Loaded cv623_16988.txt\n","Loaded cv624_11601.txt\n","Loaded cv625_13518.txt\n","Loaded cv626_7907.txt\n","Loaded cv627_12603.txt\n","Loaded cv628_20758.txt\n","Loaded cv629_16604.txt\n","Loaded cv630_10152.txt\n","Loaded cv631_4782.txt\n","Loaded cv632_9704.txt\n","Loaded cv633_29730.txt\n","Loaded cv634_11989.txt\n","Loaded cv635_0984.txt\n","Loaded cv636_16954.txt\n","Loaded cv637_13682.txt\n","Loaded cv638_29394.txt\n","Loaded cv639_10797.txt\n","Loaded cv640_5380.txt\n","Loaded cv641_13412.txt\n","Loaded cv642_29788.txt\n","Loaded cv643_29282.txt\n","Loaded cv644_18551.txt\n","Loaded cv645_17078.txt\n","Loaded cv646_16817.txt\n","Loaded cv647_15275.txt\n","Loaded cv648_17277.txt\n","Loaded cv649_13947.txt\n","Loaded cv650_15974.txt\n","Loaded cv651_11120.txt\n","Loaded cv652_15653.txt\n","Loaded cv653_2107.txt\n","Loaded cv654_19345.txt\n","Loaded cv655_12055.txt\n","Loaded cv656_25395.txt\n","Loaded cv657_25835.txt\n","Loaded cv658_11186.txt\n","Loaded cv659_21483.txt\n","Loaded cv660_23140.txt\n","Loaded cv661_25780.txt\n","Loaded cv662_14791.txt\n","Loaded cv663_14484.txt\n","Loaded cv664_4264.txt\n","Loaded cv665_29386.txt\n","Loaded cv666_20301.txt\n","Loaded cv667_19672.txt\n","Loaded cv668_18848.txt\n","Loaded cv669_24318.txt\n","Loaded cv670_2666.txt\n","Loaded cv671_5164.txt\n","Loaded cv672_27988.txt\n","Loaded cv673_25874.txt\n","Loaded cv674_11593.txt\n","Loaded cv675_22871.txt\n","Loaded cv676_22202.txt\n","Loaded cv677_18938.txt\n","Loaded cv678_14887.txt\n","Loaded cv679_28221.txt\n","Loaded cv680_10533.txt\n","Loaded cv681_9744.txt\n","Loaded cv682_17947.txt\n","Loaded cv683_13047.txt\n","Loaded cv684_12727.txt\n","Loaded cv685_5710.txt\n","Loaded cv686_15553.txt\n","Loaded cv687_22207.txt\n","Loaded cv688_7884.txt\n","Loaded cv689_13701.txt\n","Loaded cv690_5425.txt\n","Loaded cv691_5090.txt\n","Loaded cv692_17026.txt\n","Loaded cv693_19147.txt\n","Loaded cv694_4526.txt\n","Loaded cv695_22268.txt\n","Loaded cv696_29619.txt\n","Loaded cv697_12106.txt\n","Loaded cv698_16930.txt\n","Loaded cv699_7773.txt\n","Loaded cv700_23163.txt\n","Loaded cv701_15880.txt\n","Loaded cv702_12371.txt\n","Loaded cv703_17948.txt\n","Loaded cv704_17622.txt\n","Loaded cv705_11973.txt\n","Loaded cv706_25883.txt\n","Loaded cv707_11421.txt\n","Loaded cv708_28539.txt\n","Loaded cv709_11173.txt\n","Loaded cv710_23745.txt\n","Loaded cv711_12687.txt\n","Loaded cv712_24217.txt\n","Loaded cv713_29002.txt\n","Loaded cv714_19704.txt\n","Loaded cv715_19246.txt\n","Loaded cv716_11153.txt\n","Loaded cv717_17472.txt\n","Loaded cv718_12227.txt\n","Loaded cv719_5581.txt\n","Loaded cv720_5383.txt\n","Loaded cv721_28993.txt\n","Loaded cv722_7571.txt\n","Loaded cv723_9002.txt\n","Loaded cv724_15265.txt\n","Loaded cv725_10266.txt\n","Loaded cv726_4365.txt\n","Loaded cv727_5006.txt\n","Loaded cv728_17931.txt\n","Loaded cv729_10475.txt\n","Loaded cv730_10729.txt\n","Loaded cv731_3968.txt\n","Loaded cv732_13092.txt\n","Loaded cv733_9891.txt\n","Loaded cv734_22821.txt\n","Loaded cv735_20218.txt\n","Loaded cv736_24947.txt\n","Loaded cv737_28733.txt\n","Loaded cv738_10287.txt\n","Loaded cv739_12179.txt\n","Loaded cv740_13643.txt\n","Loaded cv741_12765.txt\n","Loaded cv742_8279.txt\n","Loaded cv743_17023.txt\n","Loaded cv744_10091.txt\n","Loaded cv745_14009.txt\n","Loaded cv746_10471.txt\n","Loaded cv747_18189.txt\n","Loaded cv748_14044.txt\n","Loaded cv749_18960.txt\n","Loaded cv750_10606.txt\n","Loaded cv751_17208.txt\n","Loaded cv752_25330.txt\n","Loaded cv753_11812.txt\n","Loaded cv754_7709.txt\n","Loaded cv755_24881.txt\n","Loaded cv756_23676.txt\n","Loaded cv757_10668.txt\n","Loaded cv758_9740.txt\n","Loaded cv759_15091.txt\n","Loaded cv760_8977.txt\n","Loaded cv761_13769.txt\n","Loaded cv762_15604.txt\n","Loaded cv763_16486.txt\n","Loaded cv764_12701.txt\n","Loaded cv765_20429.txt\n","Loaded cv766_7983.txt\n","Loaded cv767_15673.txt\n","Loaded cv768_12709.txt\n","Loaded cv769_8565.txt\n","Loaded cv770_11061.txt\n","Loaded cv771_28466.txt\n","Loaded cv772_12971.txt\n","Loaded cv773_20264.txt\n","Loaded cv774_15488.txt\n","Loaded cv775_17966.txt\n","Loaded cv776_21934.txt\n","Loaded cv777_10247.txt\n","Loaded cv778_18629.txt\n","Loaded cv779_18989.txt\n","Loaded cv780_8467.txt\n","Loaded cv781_5358.txt\n","Loaded cv782_21078.txt\n","Loaded cv783_14724.txt\n","Loaded cv784_16077.txt\n","Loaded cv785_23748.txt\n","Loaded cv786_23608.txt\n","Loaded cv787_15277.txt\n","Loaded cv788_26409.txt\n","Loaded cv789_12991.txt\n","Loaded cv790_16202.txt\n","Loaded cv791_17995.txt\n","Loaded cv792_3257.txt\n","Loaded cv793_15235.txt\n","Loaded cv794_17353.txt\n","Loaded cv795_10291.txt\n","Loaded cv796_17243.txt\n","Loaded cv797_7245.txt\n","Loaded cv798_24779.txt\n","Loaded cv799_19812.txt\n","Loaded cv800_13494.txt\n","Loaded cv801_26335.txt\n","Loaded cv802_28381.txt\n","Loaded cv803_8584.txt\n","Loaded cv804_11763.txt\n","Loaded cv805_21128.txt\n","Loaded cv806_9405.txt\n","Loaded cv807_23024.txt\n","Loaded cv808_13773.txt\n","Loaded cv809_5012.txt\n","Loaded cv810_13660.txt\n","Loaded cv811_22646.txt\n","Loaded cv812_19051.txt\n","Loaded cv813_6649.txt\n","Loaded cv814_20316.txt\n","Loaded cv815_23466.txt\n","Loaded cv816_15257.txt\n","Loaded cv817_3675.txt\n","Loaded cv818_10698.txt\n","Loaded cv819_9567.txt\n","Loaded cv820_24157.txt\n","Loaded cv821_29283.txt\n","Loaded cv822_21545.txt\n","Loaded cv823_17055.txt\n","Loaded cv824_9335.txt\n","Loaded cv825_5168.txt\n","Loaded cv826_12761.txt\n","Loaded cv827_19479.txt\n","Loaded cv828_21392.txt\n","Loaded cv829_21725.txt\n","Loaded cv830_5778.txt\n","Loaded cv831_16325.txt\n","Loaded cv832_24713.txt\n","Loaded cv833_11961.txt\n","Loaded cv834_23192.txt\n","Loaded cv835_20531.txt\n","Loaded cv836_14311.txt\n","Loaded cv837_27232.txt\n","Loaded cv838_25886.txt\n","Loaded cv839_22807.txt\n","Loaded cv840_18033.txt\n","Loaded cv841_3367.txt\n","Loaded cv842_5702.txt\n","Loaded cv843_17054.txt\n","Loaded cv844_13890.txt\n","Loaded cv845_15886.txt\n","Loaded cv846_29359.txt\n","Loaded cv847_20855.txt\n","Loaded cv848_10061.txt\n","Loaded cv849_17215.txt\n","Loaded cv850_18185.txt\n","Loaded cv851_21895.txt\n","Loaded cv852_27512.txt\n","Loaded cv853_29119.txt\n","Loaded cv854_18955.txt\n","Loaded cv855_22134.txt\n","Loaded cv856_28882.txt\n","Loaded cv857_17527.txt\n","Loaded cv858_20266.txt\n","Loaded cv859_15689.txt\n","Loaded cv860_15520.txt\n","Loaded cv861_12809.txt\n","Loaded cv862_15924.txt\n","Loaded cv863_7912.txt\n","Loaded cv864_3087.txt\n","Loaded cv865_28796.txt\n","Loaded cv866_29447.txt\n","Loaded cv867_18362.txt\n","Loaded cv868_12799.txt\n","Loaded cv869_24782.txt\n","Loaded cv870_18090.txt\n","Loaded cv871_25971.txt\n","Loaded cv872_13710.txt\n","Loaded cv873_19937.txt\n","Loaded cv874_12182.txt\n","Loaded cv875_5622.txt\n","Loaded cv876_9633.txt\n","Loaded cv877_29132.txt\n","Loaded cv878_17204.txt\n","Loaded cv879_16585.txt\n","Loaded cv880_29629.txt\n","Loaded cv881_14767.txt\n","Loaded cv882_10042.txt\n","Loaded cv883_27621.txt\n","Loaded cv884_15230.txt\n","Loaded cv885_13390.txt\n","Loaded cv886_19210.txt\n","Loaded cv887_5306.txt\n","Loaded cv888_25678.txt\n","Loaded cv889_22670.txt\n","Loaded cv890_3515.txt\n","Loaded cv891_6035.txt\n","Loaded cv892_18788.txt\n","Loaded cv893_26731.txt\n","Loaded cv894_22140.txt\n","Loaded cv895_22200.txt\n","Loaded cv896_17819.txt\n","Loaded cv897_11703.txt\n","Loaded cv898_1576.txt\n","Loaded cv899_17812.txt\n","Loaded cv900_10800.txt\n","Loaded cv901_11934.txt\n","Loaded cv902_13217.txt\n","Loaded cv903_18981.txt\n","Loaded cv904_25663.txt\n","Loaded cv905_28965.txt\n","Loaded cv906_12332.txt\n","Loaded cv907_3193.txt\n","Loaded cv908_17779.txt\n","Loaded cv909_9973.txt\n","Loaded cv910_21930.txt\n","Loaded cv911_21695.txt\n","Loaded cv912_5562.txt\n","Loaded cv913_29127.txt\n","Loaded cv914_2856.txt\n","Loaded cv915_9342.txt\n","Loaded cv916_17034.txt\n","Loaded cv917_29484.txt\n","Loaded cv918_27080.txt\n","Loaded cv919_18155.txt\n","Loaded cv920_29423.txt\n","Loaded cv921_13988.txt\n","Loaded cv922_10185.txt\n","Loaded cv923_11951.txt\n","Loaded cv924_29397.txt\n","Loaded cv925_9459.txt\n","Loaded cv926_18471.txt\n","Loaded cv927_11471.txt\n","Loaded cv928_9478.txt\n","Loaded cv929_1841.txt\n","Loaded cv930_14949.txt\n","Loaded cv931_18783.txt\n","Loaded cv932_14854.txt\n","Loaded cv933_24953.txt\n","Loaded cv934_20426.txt\n","Loaded cv935_24977.txt\n","Loaded cv936_17473.txt\n","Loaded cv937_9816.txt\n","Loaded cv938_10706.txt\n","Loaded cv939_11247.txt\n","Loaded cv940_18935.txt\n","Loaded cv941_10718.txt\n","Loaded cv942_18509.txt\n","Loaded cv943_23547.txt\n","Loaded cv944_15042.txt\n","Loaded cv945_13012.txt\n","Loaded cv946_20084.txt\n","Loaded cv947_11316.txt\n","Loaded cv948_25870.txt\n","Loaded cv949_21565.txt\n","Loaded cv950_13478.txt\n","Loaded cv951_11816.txt\n","Loaded cv952_26375.txt\n","Loaded cv953_7078.txt\n","Loaded cv954_19932.txt\n","Loaded cv955_26154.txt\n","Loaded cv956_12547.txt\n","Loaded cv957_9059.txt\n","Loaded cv958_13020.txt\n","Loaded cv959_16218.txt\n","Loaded cv960_28877.txt\n","Loaded cv961_5578.txt\n","Loaded cv962_9813.txt\n","Loaded cv963_7208.txt\n","Loaded cv964_5794.txt\n","Loaded cv965_26688.txt\n","Loaded cv966_28671.txt\n","Loaded cv967_5626.txt\n","Loaded cv968_25413.txt\n","Loaded cv969_14760.txt\n","Loaded cv970_19532.txt\n","Loaded cv971_11790.txt\n","Loaded cv972_26837.txt\n","Loaded cv973_10171.txt\n","Loaded cv974_24303.txt\n","Loaded cv975_11920.txt\n","Loaded cv976_10724.txt\n","Loaded cv977_4776.txt\n","Loaded cv978_22192.txt\n","Loaded cv979_2029.txt\n","Loaded cv980_11851.txt\n","Loaded cv981_16679.txt\n","Loaded cv982_22209.txt\n","Loaded cv983_24219.txt\n","Loaded cv984_14006.txt\n","Loaded cv985_5964.txt\n","Loaded cv986_15092.txt\n","Loaded cv987_7394.txt\n","Loaded cv988_20168.txt\n","Loaded cv989_17297.txt\n","Loaded cv990_12443.txt\n","Loaded cv991_19973.txt\n","Loaded cv992_12806.txt\n","Loaded cv993_29565.txt\n","Loaded cv994_13229.txt\n","Loaded cv995_23113.txt\n","Loaded cv996_12447.txt\n","Loaded cv997_5152.txt\n","Loaded cv998_15691.txt\n","Loaded cv999_14636.txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"bZjI5cGO2ycS","executionInfo":{"status":"error","timestamp":1637564368241,"user_tz":-420,"elapsed":41,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"}},"outputId":"f36b8e76-8a1d-4023-e43a-53438ec6acfb"},"source":["len(doc)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6a8db655454f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"Y8XgJdZQEF-m"},"source":["### Complete code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxQ7ILtk1lzF","executionInfo":{"status":"ok","timestamp":1637564019334,"user_tz":-420,"elapsed":2503,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"}},"outputId":"d878a06e-6798-4439-bb5f-28ba113b6d54"},"source":["from os import listdir # get list of files\n","\n","# 1. load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  #close the file\n","  file.close()\n","  return text\n","\n","# 2. load all docs in a directory\n","def process_docs(directory):\n","  # walk through all files in the folder\n","  for filename in listdir(directory):\n","    #skip file that do not have the right extension\n","    if not filename.endswith('.txt'):\n","      next\n","    # create the full path to open\n","    path = directory + '/' + filename\n","    #load document\n","    doc = load_doc(path)\n","    print('Loaded %s' % filename)\n","\n","# specify directory to load\n","directory = '/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg'\n","process_docs(directory)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded cv000_29416.txt\n","Loaded cv001_19502.txt\n","Loaded cv002_17424.txt\n","Loaded cv003_12683.txt\n","Loaded cv004_12641.txt\n","Loaded cv005_29357.txt\n","Loaded cv006_17022.txt\n","Loaded cv007_4992.txt\n","Loaded cv008_29326.txt\n","Loaded cv009_29417.txt\n","Loaded cv010_29063.txt\n","Loaded cv011_13044.txt\n","Loaded cv012_29411.txt\n","Loaded cv013_10494.txt\n","Loaded cv014_15600.txt\n","Loaded cv015_29356.txt\n","Loaded cv016_4348.txt\n","Loaded cv017_23487.txt\n","Loaded cv018_21672.txt\n","Loaded cv019_16117.txt\n","Loaded cv020_9234.txt\n","Loaded cv021_17313.txt\n","Loaded cv022_14227.txt\n","Loaded cv023_13847.txt\n","Loaded cv024_7033.txt\n","Loaded cv025_29825.txt\n","Loaded cv026_29229.txt\n","Loaded cv027_26270.txt\n","Loaded cv028_26964.txt\n","Loaded cv029_19943.txt\n","Loaded cv030_22893.txt\n","Loaded cv031_19540.txt\n","Loaded cv032_23718.txt\n","Loaded cv033_25680.txt\n","Loaded cv034_29446.txt\n","Loaded cv035_3343.txt\n","Loaded cv036_18385.txt\n","Loaded cv037_19798.txt\n","Loaded cv038_9781.txt\n","Loaded cv039_5963.txt\n","Loaded cv040_8829.txt\n","Loaded cv041_22364.txt\n","Loaded cv042_11927.txt\n","Loaded cv043_16808.txt\n","Loaded cv044_18429.txt\n","Loaded cv045_25077.txt\n","Loaded cv046_10613.txt\n","Loaded cv047_18725.txt\n","Loaded cv048_18380.txt\n","Loaded cv049_21917.txt\n","Loaded cv050_12128.txt\n","Loaded cv051_10751.txt\n","Loaded cv052_29318.txt\n","Loaded cv053_23117.txt\n","Loaded cv054_4101.txt\n","Loaded cv055_8926.txt\n","Loaded cv056_14663.txt\n","Loaded cv057_7962.txt\n","Loaded cv058_8469.txt\n","Loaded cv059_28723.txt\n","Loaded cv060_11754.txt\n","Loaded cv061_9321.txt\n","Loaded cv062_24556.txt\n","Loaded cv063_28852.txt\n","Loaded cv064_25842.txt\n","Loaded cv065_16909.txt\n","Loaded cv066_11668.txt\n","Loaded cv067_21192.txt\n","Loaded cv068_14810.txt\n","Loaded cv069_11613.txt\n","Loaded cv070_13249.txt\n","Loaded cv071_12969.txt\n","Loaded cv072_5928.txt\n","Loaded cv073_23039.txt\n","Loaded cv074_7188.txt\n","Loaded cv075_6250.txt\n","Loaded cv076_26009.txt\n","Loaded cv077_23172.txt\n","Loaded cv078_16506.txt\n","Loaded cv079_12766.txt\n","Loaded cv080_14899.txt\n","Loaded cv081_18241.txt\n","Loaded cv082_11979.txt\n","Loaded cv083_25491.txt\n","Loaded cv084_15183.txt\n","Loaded cv085_15286.txt\n","Loaded cv086_19488.txt\n","Loaded cv087_2145.txt\n","Loaded cv088_25274.txt\n","Loaded cv089_12222.txt\n","Loaded cv090_0049.txt\n","Loaded cv091_7899.txt\n","Loaded cv092_27987.txt\n","Loaded cv093_15606.txt\n","Loaded cv094_27868.txt\n","Loaded cv095_28730.txt\n","Loaded cv096_12262.txt\n","Loaded cv097_26081.txt\n","Loaded cv098_17021.txt\n","Loaded cv099_11189.txt\n","Loaded cv100_12406.txt\n","Loaded cv101_10537.txt\n","Loaded cv102_8306.txt\n","Loaded cv103_11943.txt\n","Loaded cv104_19176.txt\n","Loaded cv105_19135.txt\n","Loaded cv106_18379.txt\n","Loaded cv107_25639.txt\n","Loaded cv108_17064.txt\n","Loaded cv109_22599.txt\n","Loaded cv110_27832.txt\n","Loaded cv111_12253.txt\n","Loaded cv112_12178.txt\n","Loaded cv113_24354.txt\n","Loaded cv114_19501.txt\n","Loaded cv115_26443.txt\n","Loaded cv116_28734.txt\n","Loaded cv117_25625.txt\n","Loaded cv118_28837.txt\n","Loaded cv119_9909.txt\n","Loaded cv120_3793.txt\n","Loaded cv121_18621.txt\n","Loaded cv122_7891.txt\n","Loaded cv123_12165.txt\n","Loaded cv124_3903.txt\n","Loaded cv125_9636.txt\n","Loaded cv126_28821.txt\n","Loaded cv127_16451.txt\n","Loaded cv128_29444.txt\n","Loaded cv129_18373.txt\n","Loaded cv130_18521.txt\n","Loaded cv131_11568.txt\n","Loaded cv132_5423.txt\n","Loaded cv133_18065.txt\n","Loaded cv134_23300.txt\n","Loaded cv135_12506.txt\n","Loaded cv136_12384.txt\n","Loaded cv137_17020.txt\n","Loaded cv138_13903.txt\n","Loaded cv139_14236.txt\n","Loaded cv140_7963.txt\n","Loaded cv141_17179.txt\n","Loaded cv142_23657.txt\n","Loaded cv143_21158.txt\n","Loaded cv144_5010.txt\n","Loaded cv145_12239.txt\n","Loaded cv146_19587.txt\n","Loaded cv147_22625.txt\n","Loaded cv148_18084.txt\n","Loaded cv149_17084.txt\n","Loaded cv150_14279.txt\n","Loaded cv151_17231.txt\n","Loaded cv152_9052.txt\n","Loaded cv153_11607.txt\n","Loaded cv154_9562.txt\n","Loaded cv155_7845.txt\n","Loaded cv156_11119.txt\n","Loaded cv157_29302.txt\n","Loaded cv158_10914.txt\n","Loaded cv159_29374.txt\n","Loaded cv160_10848.txt\n","Loaded cv161_12224.txt\n","Loaded cv162_10977.txt\n","Loaded cv163_10110.txt\n","Loaded cv164_23451.txt\n","Loaded cv165_2389.txt\n","Loaded cv166_11959.txt\n","Loaded cv167_18094.txt\n","Loaded cv168_7435.txt\n","Loaded cv169_24973.txt\n","Loaded cv170_29808.txt\n","Loaded cv171_15164.txt\n","Loaded cv172_12037.txt\n","Loaded cv173_4295.txt\n","Loaded cv174_9735.txt\n","Loaded cv175_7375.txt\n","Loaded cv176_14196.txt\n","Loaded cv177_10904.txt\n","Loaded cv178_14380.txt\n","Loaded cv179_9533.txt\n","Loaded cv180_17823.txt\n","Loaded cv181_16083.txt\n","Loaded cv182_7791.txt\n","Loaded cv183_19826.txt\n","Loaded cv184_26935.txt\n","Loaded cv185_28372.txt\n","Loaded cv186_2396.txt\n","Loaded cv187_14112.txt\n","Loaded cv188_20687.txt\n","Loaded cv189_24248.txt\n","Loaded cv190_27176.txt\n","Loaded cv191_29539.txt\n","Loaded cv192_16079.txt\n","Loaded cv193_5393.txt\n","Loaded cv194_12855.txt\n","Loaded cv195_16146.txt\n","Loaded cv196_28898.txt\n","Loaded cv197_29271.txt\n","Loaded cv198_19313.txt\n","Loaded cv199_9721.txt\n","Loaded cv200_29006.txt\n","Loaded cv201_7421.txt\n","Loaded cv202_11382.txt\n","Loaded cv203_19052.txt\n","Loaded cv204_8930.txt\n","Loaded cv205_9676.txt\n","Loaded cv206_15893.txt\n","Loaded cv207_29141.txt\n","Loaded cv208_9475.txt\n","Loaded cv209_28973.txt\n","Loaded cv210_9557.txt\n","Loaded cv211_9955.txt\n","Loaded cv212_10054.txt\n","Loaded cv213_20300.txt\n","Loaded cv214_13285.txt\n","Loaded cv215_23246.txt\n","Loaded cv216_20165.txt\n","Loaded cv217_28707.txt\n","Loaded cv218_25651.txt\n","Loaded cv219_19874.txt\n","Loaded cv220_28906.txt\n","Loaded cv221_27081.txt\n","Loaded cv222_18720.txt\n","Loaded cv223_28923.txt\n","Loaded cv224_18875.txt\n","Loaded cv225_29083.txt\n","Loaded cv226_26692.txt\n","Loaded cv227_25406.txt\n","Loaded cv228_5644.txt\n","Loaded cv229_15200.txt\n","Loaded cv230_7913.txt\n","Loaded cv231_11028.txt\n","Loaded cv232_16768.txt\n","Loaded cv233_17614.txt\n","Loaded cv234_22123.txt\n","Loaded cv235_10704.txt\n","Loaded cv236_12427.txt\n","Loaded cv237_20635.txt\n","Loaded cv238_14285.txt\n","Loaded cv239_29828.txt\n","Loaded cv240_15948.txt\n","Loaded cv241_24602.txt\n","Loaded cv242_11354.txt\n","Loaded cv243_22164.txt\n","Loaded cv244_22935.txt\n","Loaded cv245_8938.txt\n","Loaded cv246_28668.txt\n","Loaded cv247_14668.txt\n","Loaded cv248_15672.txt\n","Loaded cv249_12674.txt\n","Loaded cv250_26462.txt\n","Loaded cv251_23901.txt\n","Loaded cv252_24974.txt\n","Loaded cv253_10190.txt\n","Loaded cv254_5870.txt\n","Loaded cv255_15267.txt\n","Loaded cv256_16529.txt\n","Loaded cv257_11856.txt\n","Loaded cv258_5627.txt\n","Loaded cv259_11827.txt\n","Loaded cv260_15652.txt\n","Loaded cv261_11855.txt\n","Loaded cv262_13812.txt\n","Loaded cv263_20693.txt\n","Loaded cv264_14108.txt\n","Loaded cv265_11625.txt\n","Loaded cv266_26644.txt\n","Loaded cv267_16618.txt\n","Loaded cv268_20288.txt\n","Loaded cv269_23018.txt\n","Loaded cv270_5873.txt\n","Loaded cv271_15364.txt\n","Loaded cv272_20313.txt\n","Loaded cv273_28961.txt\n","Loaded cv274_26379.txt\n","Loaded cv275_28725.txt\n","Loaded cv276_17126.txt\n","Loaded cv277_20467.txt\n","Loaded cv278_14533.txt\n","Loaded cv279_19452.txt\n","Loaded cv280_8651.txt\n","Loaded cv281_24711.txt\n","Loaded cv282_6833.txt\n","Loaded cv283_11963.txt\n","Loaded cv284_20530.txt\n","Loaded cv285_18186.txt\n","Loaded cv286_26156.txt\n","Loaded cv287_17410.txt\n","Loaded cv288_20212.txt\n","Loaded cv289_6239.txt\n","Loaded cv290_11981.txt\n","Loaded cv291_26844.txt\n","Loaded cv292_7804.txt\n","Loaded cv293_29731.txt\n","Loaded cv294_12695.txt\n","Loaded cv295_17060.txt\n","Loaded cv296_13146.txt\n","Loaded cv297_10104.txt\n","Loaded cv298_24487.txt\n","Loaded cv299_17950.txt\n","Loaded cv300_23302.txt\n","Loaded cv301_13010.txt\n","Loaded cv302_26481.txt\n","Loaded cv303_27366.txt\n","Loaded cv304_28489.txt\n","Loaded cv305_9937.txt\n","Loaded cv306_10859.txt\n","Loaded cv307_26382.txt\n","Loaded cv308_5079.txt\n","Loaded cv309_23737.txt\n","Loaded cv310_14568.txt\n","Loaded cv311_17708.txt\n","Loaded cv312_29308.txt\n","Loaded cv313_19337.txt\n","Loaded cv314_16095.txt\n","Loaded cv315_12638.txt\n","Loaded cv316_5972.txt\n","Loaded cv317_25111.txt\n","Loaded cv318_11146.txt\n","Loaded cv319_16459.txt\n","Loaded cv320_9693.txt\n","Loaded cv321_14191.txt\n","Loaded cv322_21820.txt\n","Loaded cv323_29633.txt\n","Loaded cv324_7502.txt\n","Loaded cv325_18330.txt\n","Loaded cv326_14777.txt\n","Loaded cv327_21743.txt\n","Loaded cv328_10908.txt\n","Loaded cv329_29293.txt\n","Loaded cv330_29675.txt\n","Loaded cv331_8656.txt\n","Loaded cv332_17997.txt\n","Loaded cv333_9443.txt\n","Loaded cv334_0074.txt\n","Loaded cv335_16299.txt\n","Loaded cv336_10363.txt\n","Loaded cv337_29061.txt\n","Loaded cv338_9183.txt\n","Loaded cv339_22452.txt\n","Loaded cv340_14776.txt\n","Loaded cv341_25667.txt\n","Loaded cv342_20917.txt\n","Loaded cv343_10906.txt\n","Loaded cv344_5376.txt\n","Loaded cv345_9966.txt\n","Loaded cv346_19198.txt\n","Loaded cv347_14722.txt\n","Loaded cv348_19207.txt\n","Loaded cv349_15032.txt\n","Loaded cv350_22139.txt\n","Loaded cv351_17029.txt\n","Loaded cv352_5414.txt\n","Loaded cv353_19197.txt\n","Loaded cv354_8573.txt\n","Loaded cv355_18174.txt\n","Loaded cv356_26170.txt\n","Loaded cv357_14710.txt\n","Loaded cv358_11557.txt\n","Loaded cv359_6751.txt\n","Loaded cv360_8927.txt\n","Loaded cv361_28738.txt\n","Loaded cv362_16985.txt\n","Loaded cv363_29273.txt\n","Loaded cv364_14254.txt\n","Loaded cv365_12442.txt\n","Loaded cv366_10709.txt\n","Loaded cv367_24065.txt\n","Loaded cv368_11090.txt\n","Loaded cv369_14245.txt\n","Loaded cv370_5338.txt\n","Loaded cv371_8197.txt\n","Loaded cv372_6654.txt\n","Loaded cv373_21872.txt\n","Loaded cv374_26455.txt\n","Loaded cv375_9932.txt\n","Loaded cv376_20883.txt\n","Loaded cv377_8440.txt\n","Loaded cv378_21982.txt\n","Loaded cv379_23167.txt\n","Loaded cv380_8164.txt\n","Loaded cv381_21673.txt\n","Loaded cv382_8393.txt\n","Loaded cv383_14662.txt\n","Loaded cv384_18536.txt\n","Loaded cv385_29621.txt\n","Loaded cv386_10229.txt\n","Loaded cv387_12391.txt\n","Loaded cv388_12810.txt\n","Loaded cv389_9611.txt\n","Loaded cv390_12187.txt\n","Loaded cv391_11615.txt\n","Loaded cv392_12238.txt\n","Loaded cv393_29234.txt\n","Loaded cv394_5311.txt\n","Loaded cv395_11761.txt\n","Loaded cv396_19127.txt\n","Loaded cv397_28890.txt\n","Loaded cv398_17047.txt\n","Loaded cv399_28593.txt\n","Loaded cv400_20631.txt\n","Loaded cv401_13758.txt\n","Loaded cv402_16097.txt\n","Loaded cv403_6721.txt\n","Loaded cv404_21805.txt\n","Loaded cv405_21868.txt\n","Loaded cv406_22199.txt\n","Loaded cv407_23928.txt\n","Loaded cv408_5367.txt\n","Loaded cv409_29625.txt\n","Loaded cv410_25624.txt\n","Loaded cv411_16799.txt\n","Loaded cv412_25254.txt\n","Loaded cv413_7893.txt\n","Loaded cv414_11161.txt\n","Loaded cv415_23674.txt\n","Loaded cv416_12048.txt\n","Loaded cv417_14653.txt\n","Loaded cv418_16562.txt\n","Loaded cv419_14799.txt\n","Loaded cv420_28631.txt\n","Loaded cv421_9752.txt\n","Loaded cv422_9632.txt\n","Loaded cv423_12089.txt\n","Loaded cv424_9268.txt\n","Loaded cv425_8603.txt\n","Loaded cv426_10976.txt\n","Loaded cv427_11693.txt\n","Loaded cv428_12202.txt\n","Loaded cv429_7937.txt\n","Loaded cv430_18662.txt\n","Loaded cv431_7538.txt\n","Loaded cv432_15873.txt\n","Loaded cv433_10443.txt\n","Loaded cv434_5641.txt\n","Loaded cv435_24355.txt\n","Loaded cv436_20564.txt\n","Loaded cv437_24070.txt\n","Loaded cv438_8500.txt\n","Loaded cv439_17633.txt\n","Loaded cv440_16891.txt\n","Loaded cv441_15276.txt\n","Loaded cv442_15499.txt\n","Loaded cv443_22367.txt\n","Loaded cv444_9975.txt\n","Loaded cv445_26683.txt\n","Loaded cv446_12209.txt\n","Loaded cv447_27334.txt\n","Loaded cv448_16409.txt\n","Loaded cv449_9126.txt\n","Loaded cv450_8319.txt\n","Loaded cv451_11502.txt\n","Loaded cv452_5179.txt\n","Loaded cv453_10911.txt\n","Loaded cv454_21961.txt\n","Loaded cv455_28866.txt\n","Loaded cv456_20370.txt\n","Loaded cv457_19546.txt\n","Loaded cv458_9000.txt\n","Loaded cv459_21834.txt\n","Loaded cv460_11723.txt\n","Loaded cv461_21124.txt\n","Loaded cv462_20788.txt\n","Loaded cv463_10846.txt\n","Loaded cv464_17076.txt\n","Loaded cv465_23401.txt\n","Loaded cv466_20092.txt\n","Loaded cv467_26610.txt\n","Loaded cv468_16844.txt\n","Loaded cv469_21998.txt\n","Loaded cv470_17444.txt\n","Loaded cv471_18405.txt\n","Loaded cv472_29140.txt\n","Loaded cv473_7869.txt\n","Loaded cv474_10682.txt\n","Loaded cv475_22978.txt\n","Loaded cv476_18402.txt\n","Loaded cv477_23530.txt\n","Loaded cv478_15921.txt\n","Loaded cv479_5450.txt\n","Loaded cv480_21195.txt\n","Loaded cv481_7930.txt\n","Loaded cv482_11233.txt\n","Loaded cv483_18103.txt\n","Loaded cv484_26169.txt\n","Loaded cv485_26879.txt\n","Loaded cv486_9788.txt\n","Loaded cv487_11058.txt\n","Loaded cv488_21453.txt\n","Loaded cv489_19046.txt\n","Loaded cv490_18986.txt\n","Loaded cv491_12992.txt\n","Loaded cv492_19370.txt\n","Loaded cv493_14135.txt\n","Loaded cv494_18689.txt\n","Loaded cv495_16121.txt\n","Loaded cv496_11185.txt\n","Loaded cv497_27086.txt\n","Loaded cv498_9288.txt\n","Loaded cv499_11407.txt\n","Loaded cv500_10722.txt\n","Loaded cv501_12675.txt\n","Loaded cv502_10970.txt\n","Loaded cv503_11196.txt\n","Loaded cv504_29120.txt\n","Loaded cv505_12926.txt\n","Loaded cv506_17521.txt\n","Loaded cv507_9509.txt\n","Loaded cv508_17742.txt\n","Loaded cv509_17354.txt\n","Loaded cv510_24758.txt\n","Loaded cv511_10360.txt\n","Loaded cv512_17618.txt\n","Loaded cv513_7236.txt\n","Loaded cv514_12173.txt\n","Loaded cv515_18484.txt\n","Loaded cv516_12117.txt\n","Loaded cv517_20616.txt\n","Loaded cv518_14798.txt\n","Loaded cv519_16239.txt\n","Loaded cv520_13297.txt\n","Loaded cv521_1730.txt\n","Loaded cv522_5418.txt\n","Loaded cv523_18285.txt\n","Loaded cv524_24885.txt\n","Loaded cv525_17930.txt\n","Loaded cv526_12868.txt\n","Loaded cv527_10338.txt\n","Loaded cv528_11669.txt\n","Loaded cv529_10972.txt\n","Loaded cv530_17949.txt\n","Loaded cv531_26838.txt\n","Loaded cv532_6495.txt\n","Loaded cv533_9843.txt\n","Loaded cv534_15683.txt\n","Loaded cv535_21183.txt\n","Loaded cv536_27221.txt\n","Loaded cv537_13516.txt\n","Loaded cv538_28485.txt\n","Loaded cv539_21865.txt\n","Loaded cv540_3092.txt\n","Loaded cv541_28683.txt\n","Loaded cv542_20359.txt\n","Loaded cv543_5107.txt\n","Loaded cv544_5301.txt\n","Loaded cv545_12848.txt\n","Loaded cv546_12723.txt\n","Loaded cv547_18043.txt\n","Loaded cv548_18944.txt\n","Loaded cv549_22771.txt\n","Loaded cv550_23226.txt\n","Loaded cv551_11214.txt\n","Loaded cv552_0150.txt\n","Loaded cv553_26965.txt\n","Loaded cv554_14678.txt\n","Loaded cv555_25047.txt\n","Loaded cv556_16563.txt\n","Loaded cv557_12237.txt\n","Loaded cv558_29376.txt\n","Loaded cv559_0057.txt\n","Loaded cv560_18608.txt\n","Loaded cv561_9484.txt\n","Loaded cv562_10847.txt\n","Loaded cv563_18610.txt\n","Loaded cv564_12011.txt\n","Loaded cv565_29403.txt\n","Loaded cv566_8967.txt\n","Loaded cv567_29420.txt\n","Loaded cv568_17065.txt\n","Loaded cv569_26750.txt\n","Loaded cv570_28960.txt\n","Loaded cv571_29292.txt\n","Loaded cv572_20053.txt\n","Loaded cv573_29384.txt\n","Loaded cv574_23191.txt\n","Loaded cv575_22598.txt\n","Loaded cv576_15688.txt\n","Loaded cv577_28220.txt\n","Loaded cv578_16825.txt\n","Loaded cv579_12542.txt\n","Loaded cv580_15681.txt\n","Loaded cv581_20790.txt\n","Loaded cv582_6678.txt\n","Loaded cv583_29465.txt\n","Loaded cv584_29549.txt\n","Loaded cv585_23576.txt\n","Loaded cv586_8048.txt\n","Loaded cv587_20532.txt\n","Loaded cv588_14467.txt\n","Loaded cv589_12853.txt\n","Loaded cv590_20712.txt\n","Loaded cv591_24887.txt\n","Loaded cv592_23391.txt\n","Loaded cv593_11931.txt\n","Loaded cv594_11945.txt\n","Loaded cv595_26420.txt\n","Loaded cv596_4367.txt\n","Loaded cv597_26744.txt\n","Loaded cv598_18184.txt\n","Loaded cv599_22197.txt\n","Loaded cv600_25043.txt\n","Loaded cv601_24759.txt\n","Loaded cv602_8830.txt\n","Loaded cv603_18885.txt\n","Loaded cv604_23339.txt\n","Loaded cv605_12730.txt\n","Loaded cv606_17672.txt\n","Loaded cv607_8235.txt\n","Loaded cv608_24647.txt\n","Loaded cv609_25038.txt\n","Loaded cv610_24153.txt\n","Loaded cv611_2253.txt\n","Loaded cv612_5396.txt\n","Loaded cv613_23104.txt\n","Loaded cv614_11320.txt\n","Loaded cv615_15734.txt\n","Loaded cv616_29187.txt\n","Loaded cv617_9561.txt\n","Loaded cv618_9469.txt\n","Loaded cv619_13677.txt\n","Loaded cv620_2556.txt\n","Loaded cv621_15984.txt\n","Loaded cv622_8583.txt\n","Loaded cv623_16988.txt\n","Loaded cv624_11601.txt\n","Loaded cv625_13518.txt\n","Loaded cv626_7907.txt\n","Loaded cv627_12603.txt\n","Loaded cv628_20758.txt\n","Loaded cv629_16604.txt\n","Loaded cv630_10152.txt\n","Loaded cv631_4782.txt\n","Loaded cv632_9704.txt\n","Loaded cv633_29730.txt\n","Loaded cv634_11989.txt\n","Loaded cv635_0984.txt\n","Loaded cv636_16954.txt\n","Loaded cv637_13682.txt\n","Loaded cv638_29394.txt\n","Loaded cv639_10797.txt\n","Loaded cv640_5380.txt\n","Loaded cv641_13412.txt\n","Loaded cv642_29788.txt\n","Loaded cv643_29282.txt\n","Loaded cv644_18551.txt\n","Loaded cv645_17078.txt\n","Loaded cv646_16817.txt\n","Loaded cv647_15275.txt\n","Loaded cv648_17277.txt\n","Loaded cv649_13947.txt\n","Loaded cv650_15974.txt\n","Loaded cv651_11120.txt\n","Loaded cv652_15653.txt\n","Loaded cv653_2107.txt\n","Loaded cv654_19345.txt\n","Loaded cv655_12055.txt\n","Loaded cv656_25395.txt\n","Loaded cv657_25835.txt\n","Loaded cv658_11186.txt\n","Loaded cv659_21483.txt\n","Loaded cv660_23140.txt\n","Loaded cv661_25780.txt\n","Loaded cv662_14791.txt\n","Loaded cv663_14484.txt\n","Loaded cv664_4264.txt\n","Loaded cv665_29386.txt\n","Loaded cv666_20301.txt\n","Loaded cv667_19672.txt\n","Loaded cv668_18848.txt\n","Loaded cv669_24318.txt\n","Loaded cv670_2666.txt\n","Loaded cv671_5164.txt\n","Loaded cv672_27988.txt\n","Loaded cv673_25874.txt\n","Loaded cv674_11593.txt\n","Loaded cv675_22871.txt\n","Loaded cv676_22202.txt\n","Loaded cv677_18938.txt\n","Loaded cv678_14887.txt\n","Loaded cv679_28221.txt\n","Loaded cv680_10533.txt\n","Loaded cv681_9744.txt\n","Loaded cv682_17947.txt\n","Loaded cv683_13047.txt\n","Loaded cv684_12727.txt\n","Loaded cv685_5710.txt\n","Loaded cv686_15553.txt\n","Loaded cv687_22207.txt\n","Loaded cv688_7884.txt\n","Loaded cv689_13701.txt\n","Loaded cv690_5425.txt\n","Loaded cv691_5090.txt\n","Loaded cv692_17026.txt\n","Loaded cv693_19147.txt\n","Loaded cv694_4526.txt\n","Loaded cv695_22268.txt\n","Loaded cv696_29619.txt\n","Loaded cv697_12106.txt\n","Loaded cv698_16930.txt\n","Loaded cv699_7773.txt\n","Loaded cv700_23163.txt\n","Loaded cv701_15880.txt\n","Loaded cv702_12371.txt\n","Loaded cv703_17948.txt\n","Loaded cv704_17622.txt\n","Loaded cv705_11973.txt\n","Loaded cv706_25883.txt\n","Loaded cv707_11421.txt\n","Loaded cv708_28539.txt\n","Loaded cv709_11173.txt\n","Loaded cv710_23745.txt\n","Loaded cv711_12687.txt\n","Loaded cv712_24217.txt\n","Loaded cv713_29002.txt\n","Loaded cv714_19704.txt\n","Loaded cv715_19246.txt\n","Loaded cv716_11153.txt\n","Loaded cv717_17472.txt\n","Loaded cv718_12227.txt\n","Loaded cv719_5581.txt\n","Loaded cv720_5383.txt\n","Loaded cv721_28993.txt\n","Loaded cv722_7571.txt\n","Loaded cv723_9002.txt\n","Loaded cv724_15265.txt\n","Loaded cv725_10266.txt\n","Loaded cv726_4365.txt\n","Loaded cv727_5006.txt\n","Loaded cv728_17931.txt\n","Loaded cv729_10475.txt\n","Loaded cv730_10729.txt\n","Loaded cv731_3968.txt\n","Loaded cv732_13092.txt\n","Loaded cv733_9891.txt\n","Loaded cv734_22821.txt\n","Loaded cv735_20218.txt\n","Loaded cv736_24947.txt\n","Loaded cv737_28733.txt\n","Loaded cv738_10287.txt\n","Loaded cv739_12179.txt\n","Loaded cv740_13643.txt\n","Loaded cv741_12765.txt\n","Loaded cv742_8279.txt\n","Loaded cv743_17023.txt\n","Loaded cv744_10091.txt\n","Loaded cv745_14009.txt\n","Loaded cv746_10471.txt\n","Loaded cv747_18189.txt\n","Loaded cv748_14044.txt\n","Loaded cv749_18960.txt\n","Loaded cv750_10606.txt\n","Loaded cv751_17208.txt\n","Loaded cv752_25330.txt\n","Loaded cv753_11812.txt\n","Loaded cv754_7709.txt\n","Loaded cv755_24881.txt\n","Loaded cv756_23676.txt\n","Loaded cv757_10668.txt\n","Loaded cv758_9740.txt\n","Loaded cv759_15091.txt\n","Loaded cv760_8977.txt\n","Loaded cv761_13769.txt\n","Loaded cv762_15604.txt\n","Loaded cv763_16486.txt\n","Loaded cv764_12701.txt\n","Loaded cv765_20429.txt\n","Loaded cv766_7983.txt\n","Loaded cv767_15673.txt\n","Loaded cv768_12709.txt\n","Loaded cv769_8565.txt\n","Loaded cv770_11061.txt\n","Loaded cv771_28466.txt\n","Loaded cv772_12971.txt\n","Loaded cv773_20264.txt\n","Loaded cv774_15488.txt\n","Loaded cv775_17966.txt\n","Loaded cv776_21934.txt\n","Loaded cv777_10247.txt\n","Loaded cv778_18629.txt\n","Loaded cv779_18989.txt\n","Loaded cv780_8467.txt\n","Loaded cv781_5358.txt\n","Loaded cv782_21078.txt\n","Loaded cv783_14724.txt\n","Loaded cv784_16077.txt\n","Loaded cv785_23748.txt\n","Loaded cv786_23608.txt\n","Loaded cv787_15277.txt\n","Loaded cv788_26409.txt\n","Loaded cv789_12991.txt\n","Loaded cv790_16202.txt\n","Loaded cv791_17995.txt\n","Loaded cv792_3257.txt\n","Loaded cv793_15235.txt\n","Loaded cv794_17353.txt\n","Loaded cv795_10291.txt\n","Loaded cv796_17243.txt\n","Loaded cv797_7245.txt\n","Loaded cv798_24779.txt\n","Loaded cv799_19812.txt\n","Loaded cv800_13494.txt\n","Loaded cv801_26335.txt\n","Loaded cv802_28381.txt\n","Loaded cv803_8584.txt\n","Loaded cv804_11763.txt\n","Loaded cv805_21128.txt\n","Loaded cv806_9405.txt\n","Loaded cv807_23024.txt\n","Loaded cv808_13773.txt\n","Loaded cv809_5012.txt\n","Loaded cv810_13660.txt\n","Loaded cv811_22646.txt\n","Loaded cv812_19051.txt\n","Loaded cv813_6649.txt\n","Loaded cv814_20316.txt\n","Loaded cv815_23466.txt\n","Loaded cv816_15257.txt\n","Loaded cv817_3675.txt\n","Loaded cv818_10698.txt\n","Loaded cv819_9567.txt\n","Loaded cv820_24157.txt\n","Loaded cv821_29283.txt\n","Loaded cv822_21545.txt\n","Loaded cv823_17055.txt\n","Loaded cv824_9335.txt\n","Loaded cv825_5168.txt\n","Loaded cv826_12761.txt\n","Loaded cv827_19479.txt\n","Loaded cv828_21392.txt\n","Loaded cv829_21725.txt\n","Loaded cv830_5778.txt\n","Loaded cv831_16325.txt\n","Loaded cv832_24713.txt\n","Loaded cv833_11961.txt\n","Loaded cv834_23192.txt\n","Loaded cv835_20531.txt\n","Loaded cv836_14311.txt\n","Loaded cv837_27232.txt\n","Loaded cv838_25886.txt\n","Loaded cv839_22807.txt\n","Loaded cv840_18033.txt\n","Loaded cv841_3367.txt\n","Loaded cv842_5702.txt\n","Loaded cv843_17054.txt\n","Loaded cv844_13890.txt\n","Loaded cv845_15886.txt\n","Loaded cv846_29359.txt\n","Loaded cv847_20855.txt\n","Loaded cv848_10061.txt\n","Loaded cv849_17215.txt\n","Loaded cv850_18185.txt\n","Loaded cv851_21895.txt\n","Loaded cv852_27512.txt\n","Loaded cv853_29119.txt\n","Loaded cv854_18955.txt\n","Loaded cv855_22134.txt\n","Loaded cv856_28882.txt\n","Loaded cv857_17527.txt\n","Loaded cv858_20266.txt\n","Loaded cv859_15689.txt\n","Loaded cv860_15520.txt\n","Loaded cv861_12809.txt\n","Loaded cv862_15924.txt\n","Loaded cv863_7912.txt\n","Loaded cv864_3087.txt\n","Loaded cv865_28796.txt\n","Loaded cv866_29447.txt\n","Loaded cv867_18362.txt\n","Loaded cv868_12799.txt\n","Loaded cv869_24782.txt\n","Loaded cv870_18090.txt\n","Loaded cv871_25971.txt\n","Loaded cv872_13710.txt\n","Loaded cv873_19937.txt\n","Loaded cv874_12182.txt\n","Loaded cv875_5622.txt\n","Loaded cv876_9633.txt\n","Loaded cv877_29132.txt\n","Loaded cv878_17204.txt\n","Loaded cv879_16585.txt\n","Loaded cv880_29629.txt\n","Loaded cv881_14767.txt\n","Loaded cv882_10042.txt\n","Loaded cv883_27621.txt\n","Loaded cv884_15230.txt\n","Loaded cv885_13390.txt\n","Loaded cv886_19210.txt\n","Loaded cv887_5306.txt\n","Loaded cv888_25678.txt\n","Loaded cv889_22670.txt\n","Loaded cv890_3515.txt\n","Loaded cv891_6035.txt\n","Loaded cv892_18788.txt\n","Loaded cv893_26731.txt\n","Loaded cv894_22140.txt\n","Loaded cv895_22200.txt\n","Loaded cv896_17819.txt\n","Loaded cv897_11703.txt\n","Loaded cv898_1576.txt\n","Loaded cv899_17812.txt\n","Loaded cv900_10800.txt\n","Loaded cv901_11934.txt\n","Loaded cv902_13217.txt\n","Loaded cv903_18981.txt\n","Loaded cv904_25663.txt\n","Loaded cv905_28965.txt\n","Loaded cv906_12332.txt\n","Loaded cv907_3193.txt\n","Loaded cv908_17779.txt\n","Loaded cv909_9973.txt\n","Loaded cv910_21930.txt\n","Loaded cv911_21695.txt\n","Loaded cv912_5562.txt\n","Loaded cv913_29127.txt\n","Loaded cv914_2856.txt\n","Loaded cv915_9342.txt\n","Loaded cv916_17034.txt\n","Loaded cv917_29484.txt\n","Loaded cv918_27080.txt\n","Loaded cv919_18155.txt\n","Loaded cv920_29423.txt\n","Loaded cv921_13988.txt\n","Loaded cv922_10185.txt\n","Loaded cv923_11951.txt\n","Loaded cv924_29397.txt\n","Loaded cv925_9459.txt\n","Loaded cv926_18471.txt\n","Loaded cv927_11471.txt\n","Loaded cv928_9478.txt\n","Loaded cv929_1841.txt\n","Loaded cv930_14949.txt\n","Loaded cv931_18783.txt\n","Loaded cv932_14854.txt\n","Loaded cv933_24953.txt\n","Loaded cv934_20426.txt\n","Loaded cv935_24977.txt\n","Loaded cv936_17473.txt\n","Loaded cv937_9816.txt\n","Loaded cv938_10706.txt\n","Loaded cv939_11247.txt\n","Loaded cv940_18935.txt\n","Loaded cv941_10718.txt\n","Loaded cv942_18509.txt\n","Loaded cv943_23547.txt\n","Loaded cv944_15042.txt\n","Loaded cv945_13012.txt\n","Loaded cv946_20084.txt\n","Loaded cv947_11316.txt\n","Loaded cv948_25870.txt\n","Loaded cv949_21565.txt\n","Loaded cv950_13478.txt\n","Loaded cv951_11816.txt\n","Loaded cv952_26375.txt\n","Loaded cv953_7078.txt\n","Loaded cv954_19932.txt\n","Loaded cv955_26154.txt\n","Loaded cv956_12547.txt\n","Loaded cv957_9059.txt\n","Loaded cv958_13020.txt\n","Loaded cv959_16218.txt\n","Loaded cv960_28877.txt\n","Loaded cv961_5578.txt\n","Loaded cv962_9813.txt\n","Loaded cv963_7208.txt\n","Loaded cv964_5794.txt\n","Loaded cv965_26688.txt\n","Loaded cv966_28671.txt\n","Loaded cv967_5626.txt\n","Loaded cv968_25413.txt\n","Loaded cv969_14760.txt\n","Loaded cv970_19532.txt\n","Loaded cv971_11790.txt\n","Loaded cv972_26837.txt\n","Loaded cv973_10171.txt\n","Loaded cv974_24303.txt\n","Loaded cv975_11920.txt\n","Loaded cv976_10724.txt\n","Loaded cv977_4776.txt\n","Loaded cv978_22192.txt\n","Loaded cv979_2029.txt\n","Loaded cv980_11851.txt\n","Loaded cv981_16679.txt\n","Loaded cv982_22209.txt\n","Loaded cv983_24219.txt\n","Loaded cv984_14006.txt\n","Loaded cv985_5964.txt\n","Loaded cv986_15092.txt\n","Loaded cv987_7394.txt\n","Loaded cv988_20168.txt\n","Loaded cv989_17297.txt\n","Loaded cv990_12443.txt\n","Loaded cv991_19973.txt\n","Loaded cv992_12806.txt\n","Loaded cv993_29565.txt\n","Loaded cv994_13229.txt\n","Loaded cv995_23113.txt\n","Loaded cv996_12447.txt\n","Loaded cv997_5152.txt\n","Loaded cv998_15691.txt\n","Loaded cv999_14636.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"Cj0IsUzT2i3d"},"source":["## 1.2. Clean Text Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tb4N7_fD2g33","executionInfo":{"elapsed":1532,"status":"ok","timestamp":1635135999546,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"b71aec6c-8c46-4b7f-db4b-a93efbaebee1"},"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import string\n","import re\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  #close the file\n","  file.close()\n","  return text\n","\n","# 1.load the document\n","\n","filename = '/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg/cv000_29416.txt'\n","text = load_doc(filename)\n","\n","# 2.split into tokens by white space\n","tokens = text.split()\n","\n","# prepare regex for char filtering\n","re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","\n","# 3. remove punctuation from each word\n","tokens = [re_punc.sub('',w) for w in tokens]\n","\n","# 4. remove remaining tokens that are not alphabetic\n","tokens = [word for word in tokens if word.isalpha()]\n","\n","# 5. filter out stop word\n","stop_words = set(stopwords.words('english'))\n","tokens = [w for w in tokens if not w in stop_words]\n","\n","# filter out short tokens\n","tokens = [word for word in tokens if len(word) >1]\n","print(tokens)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["['plot', 'two', 'teen', 'couples', 'go', 'church', 'party', 'drink', 'drive', 'get', 'accident', 'one', 'guys', 'dies', 'girlfriend', 'continues', 'see', 'life', 'nightmares', 'whats', 'deal', 'watch', 'movie', 'sorta', 'find', 'critique', 'mindfuck', 'movie', 'teen', 'generation', 'touches', 'cool', 'idea', 'presents', 'bad', 'package', 'makes', 'review', 'even', 'harder', 'one', 'write', 'since', 'generally', 'applaud', 'films', 'attempt', 'break', 'mold', 'mess', 'head', 'lost', 'highway', 'memento', 'good', 'bad', 'ways', 'making', 'types', 'films', 'folks', 'didnt', 'snag', 'one', 'correctly', 'seem', 'taken', 'pretty', 'neat', 'concept', 'executed', 'terribly', 'problems', 'movie', 'well', 'main', 'problem', 'simply', 'jumbled', 'starts', 'normal', 'downshifts', 'fantasy', 'world', 'audience', 'member', 'idea', 'whats', 'going', 'dreams', 'characters', 'coming', 'back', 'dead', 'others', 'look', 'like', 'dead', 'strange', 'apparitions', 'disappearances', 'looooot', 'chase', 'scenes', 'tons', 'weird', 'things', 'happen', 'simply', 'explained', 'personally', 'dont', 'mind', 'trying', 'unravel', 'film', 'every', 'give', 'clue', 'get', 'kind', 'fed', 'films', 'biggest', 'problem', 'obviously', 'got', 'big', 'secret', 'hide', 'seems', 'want', 'hide', 'completely', 'final', 'five', 'minutes', 'make', 'things', 'entertaining', 'thrilling', 'even', 'engaging', 'meantime', 'really', 'sad', 'part', 'arrow', 'dig', 'flicks', 'like', 'actually', 'figured', 'halfway', 'point', 'strangeness', 'start', 'make', 'little', 'bit', 'sense', 'still', 'didnt', 'make', 'film', 'entertaining', 'guess', 'bottom', 'line', 'movies', 'like', 'always', 'make', 'sure', 'audience', 'even', 'given', 'secret', 'password', 'enter', 'world', 'understanding', 'mean', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'visions', 'minutes', 'throughout', 'movie', 'plain', 'lazy', 'okay', 'get', 'people', 'chasing', 'dont', 'know', 'really', 'need', 'see', 'giving', 'us', 'different', 'scenes', 'offering', 'insight', 'strangeness', 'going', 'movie', 'apparently', 'studio', 'took', 'film', 'away', 'director', 'chopped', 'shows', 'mightve', 'pretty', 'decent', 'teen', 'mindfuck', 'movie', 'somewhere', 'guess', 'suits', 'decided', 'turning', 'music', 'video', 'little', 'edge', 'would', 'make', 'sense', 'actors', 'pretty', 'good', 'part', 'although', 'wes', 'bentley', 'seemed', 'playing', 'exact', 'character', 'american', 'beauty', 'new', 'neighborhood', 'biggest', 'kudos', 'go', 'sagemiller', 'holds', 'throughout', 'entire', 'film', 'actually', 'feeling', 'characters', 'unraveling', 'overall', 'film', 'doesnt', 'stick', 'doesnt', 'entertain', 'confusing', 'rarely', 'excites', 'feels', 'pretty', 'redundant', 'runtime', 'despite', 'pretty', 'cool', 'ending', 'explanation', 'craziness', 'came', 'oh', 'way', 'horror', 'teen', 'slasher', 'flick', 'packaged', 'look', 'way', 'someone', 'apparently', 'assuming', 'genre', 'still', 'hot', 'kids', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'sitting', 'shelves', 'ever', 'since', 'whatever', 'skip', 'wheres', 'joblo', 'coming', 'nightmare', 'elm', 'street', 'blair', 'witch', 'crow', 'crow', 'salvation', 'lost', 'highway', 'memento', 'others', 'stir', 'echoes']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/labhhc/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","metadata":{"id":"og0xKKweEWzu"},"source":["### Complete code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFRMGtMF89vZ","executionInfo":{"elapsed":525,"status":"ok","timestamp":1635136049507,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"c6e51eec-d2f7-4053-f625-dd10cb67bf08"},"source":["def clean_doc(doc):\n","  # 1.split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","  # 2. remove punctuation from each word\n","  tokens = [re_punc.sub('',w) for w in tokens]\n","  # 3. remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # 4. filter out stop word\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # 5. filter out short tokens\n","  tokens = [word for word in tokens if len(word) >1]\n","  return tokens\n","\n","#load document\n","\n","filename = '/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg/cv000_29416.txt'\n","text = load_doc(filename)\n","tokens = clean_doc(text)\n","print(tokens)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["['plot', 'two', 'teen', 'couples', 'go', 'church', 'party', 'drink', 'drive', 'get', 'accident', 'one', 'guys', 'dies', 'girlfriend', 'continues', 'see', 'life', 'nightmares', 'whats', 'deal', 'watch', 'movie', 'sorta', 'find', 'critique', 'mindfuck', 'movie', 'teen', 'generation', 'touches', 'cool', 'idea', 'presents', 'bad', 'package', 'makes', 'review', 'even', 'harder', 'one', 'write', 'since', 'generally', 'applaud', 'films', 'attempt', 'break', 'mold', 'mess', 'head', 'lost', 'highway', 'memento', 'good', 'bad', 'ways', 'making', 'types', 'films', 'folks', 'didnt', 'snag', 'one', 'correctly', 'seem', 'taken', 'pretty', 'neat', 'concept', 'executed', 'terribly', 'problems', 'movie', 'well', 'main', 'problem', 'simply', 'jumbled', 'starts', 'normal', 'downshifts', 'fantasy', 'world', 'audience', 'member', 'idea', 'whats', 'going', 'dreams', 'characters', 'coming', 'back', 'dead', 'others', 'look', 'like', 'dead', 'strange', 'apparitions', 'disappearances', 'looooot', 'chase', 'scenes', 'tons', 'weird', 'things', 'happen', 'simply', 'explained', 'personally', 'dont', 'mind', 'trying', 'unravel', 'film', 'every', 'give', 'clue', 'get', 'kind', 'fed', 'films', 'biggest', 'problem', 'obviously', 'got', 'big', 'secret', 'hide', 'seems', 'want', 'hide', 'completely', 'final', 'five', 'minutes', 'make', 'things', 'entertaining', 'thrilling', 'even', 'engaging', 'meantime', 'really', 'sad', 'part', 'arrow', 'dig', 'flicks', 'like', 'actually', 'figured', 'halfway', 'point', 'strangeness', 'start', 'make', 'little', 'bit', 'sense', 'still', 'didnt', 'make', 'film', 'entertaining', 'guess', 'bottom', 'line', 'movies', 'like', 'always', 'make', 'sure', 'audience', 'even', 'given', 'secret', 'password', 'enter', 'world', 'understanding', 'mean', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'visions', 'minutes', 'throughout', 'movie', 'plain', 'lazy', 'okay', 'get', 'people', 'chasing', 'dont', 'know', 'really', 'need', 'see', 'giving', 'us', 'different', 'scenes', 'offering', 'insight', 'strangeness', 'going', 'movie', 'apparently', 'studio', 'took', 'film', 'away', 'director', 'chopped', 'shows', 'mightve', 'pretty', 'decent', 'teen', 'mindfuck', 'movie', 'somewhere', 'guess', 'suits', 'decided', 'turning', 'music', 'video', 'little', 'edge', 'would', 'make', 'sense', 'actors', 'pretty', 'good', 'part', 'although', 'wes', 'bentley', 'seemed', 'playing', 'exact', 'character', 'american', 'beauty', 'new', 'neighborhood', 'biggest', 'kudos', 'go', 'sagemiller', 'holds', 'throughout', 'entire', 'film', 'actually', 'feeling', 'characters', 'unraveling', 'overall', 'film', 'doesnt', 'stick', 'doesnt', 'entertain', 'confusing', 'rarely', 'excites', 'feels', 'pretty', 'redundant', 'runtime', 'despite', 'pretty', 'cool', 'ending', 'explanation', 'craziness', 'came', 'oh', 'way', 'horror', 'teen', 'slasher', 'flick', 'packaged', 'look', 'way', 'someone', 'apparently', 'assuming', 'genre', 'still', 'hot', 'kids', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'sitting', 'shelves', 'ever', 'since', 'whatever', 'skip', 'wheres', 'joblo', 'coming', 'nightmare', 'elm', 'street', 'blair', 'witch', 'crow', 'crow', 'salvation', 'lost', 'highway', 'memento', 'others', 'stir', 'echoes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"iqL27uSVATo-"},"source":["## 1.3. Develop Vocabulary"]},{"cell_type":"code","metadata":{"id":"ix2k9ctqADsD"},"source":["# load doc and add to vocab\n","def add_doc_to_vocab(filename, vocab):\n","  # load doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # update counts\n","  vocab.update(tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bE_6H2cdBaQ7"},"source":["def process_docs(directory, vocab):\n","  # walk through that do not have the right extensions\n","  for filename in listdir(directory):\n","    if not filename.endswith('.txt'):\n","      next\n","  # create path\n","    path = directory + '/' + filename\n","  # add doc to vocab\n","    add_doc_to_vocab(path, vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GFqeZinhCny_"},"source":["#### Develop a full vocab from all documents in the dataset"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"AQcHeXJqC-Wp","outputId":"9373c910-320e-4715-ab92-0e6ef1320db2"},"source":["import string\n","import re\n","from os import listdir\n","from collections import Counter\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","\n","# 1. load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  #close the file\n","  file.close()\n","  return text\n","\n","# 2. turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('',w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop word\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) >1]\n","  return tokens\n","\n","# 3. load doc and add to vocab\n","def add_doc_to_vocab(filename, vocab):\n","  # load doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # update counts\n","  vocab.update(tokens)\n","\n","# 4. load all docs in a directory\n","def process_docs(directory, vocab):\n","  # walk through that do not have the right extensions\n","  for filename in listdir(directory):\n","    if not filename.endswith('.txt'):\n","      next\n","  # create path\n","    path = directory + '/' + filename\n","  # add doc to vocab\n","    add_doc_to_vocab(path, vocab)\n","\n","# define vocab\n","vocab = Counter()\n","# add all docs to vocab\n","process_docs('/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg', vocab)\n","process_docs('/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos', vocab)\n","print(len(vocab))"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/labhhc/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /home/labhhc/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dK7bZYIEElUP","executionInfo":{"elapsed":428,"status":"ok","timestamp":1634890977410,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"ac90a911-364d-44e7-ceb6-894e556d4c48"},"source":["# print the top words in the vocab\n","print(vocab.most_common(50))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[('film', 8860), ('one', 5521), ('movie', 5440), ('like', 3553), ('even', 2555), ('good', 2320), ('time', 2283), ('story', 2118), ('films', 2102), ('would', 2042), ('much', 2024), ('also', 1965), ('characters', 1947), ('get', 1921), ('character', 1906), ('two', 1825), ('first', 1768), ('see', 1730), ('well', 1694), ('way', 1668), ('make', 1590), ('really', 1563), ('little', 1491), ('life', 1472), ('plot', 1451), ('people', 1420), ('movies', 1416), ('could', 1395), ('bad', 1374), ('scene', 1373), ('never', 1364), ('best', 1301), ('new', 1277), ('many', 1268), ('doesnt', 1267), ('man', 1266), ('scenes', 1265), ('dont', 1210), ('know', 1207), ('hes', 1150), ('great', 1141), ('another', 1111), ('love', 1089), ('action', 1078), ('go', 1075), ('us', 1065), ('director', 1056), ('something', 1048), ('end', 1047), ('still', 1038)]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRVfgYZWGIWS","executionInfo":{"elapsed":5,"status":"ok","timestamp":1635136336276,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"795b99fc-1abe-401a-9000-c1550ec9beb7"},"source":["# keep tokens with > 5 occurence\n","min_occurance = 5\n","tokens = [k for k, c in vocab.items() if c >= min_occurance]\n","print(len(tokens))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["14803\n"]}]},{"cell_type":"code","metadata":{"id":"SMgr2m1OI6tj"},"source":["def save_list(lines, filename):\n","  data = '\\n'.join(lines)\n","  file = open(filename, 'w')\n","  file.write(data)\n","  file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xwjqrT0KIIq"},"source":["# save tokens to a vocabulary file\n","save_list(tokens, 'vocab.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i7zqz8gIK9eI"},"source":["## 1.4. Save Prepared Data"]},{"cell_type":"code","metadata":{"id":"hPb7NGpwKqeG"},"source":["# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file\n","  file.close()\n","  return text\n","\n","# load vocabulary\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0F0m87POPYNh"},"source":["# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  #load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  #filter by vocab\n","  tokens = [w for w in tokens if w in vocab]\n","  return ' '.join(tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmFCa7GSPs9A"},"source":["# load all docs in a directory\n","def process_docs(directory, vocab):\n","  lines = list()\n","  # walke through all files in the folder\n","  for filename in listdir(directory):\n","    #skip files that do not have the right extensions\n","    if not filename.endswith(\".txt\"):\n","      next\n","    # create the full path of file to open\n","    path = directory + '/' + filename\n","    # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B06vuD1fQWxh"},"source":["### Complete code"]},{"cell_type":"code","metadata":{"id":"IdrV5Ac8sSLC"},"source":["import string\n","import re\n","from os import listdir\n","from nltk.corpus import stopwords\n","\n","# 1. load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file\n","  file.close()\n","  return text\n","\n","# 2. Turn doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white spance\n","  tokens = doc.split()\n","  # prepare regix for char filtering\n","  re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('', w) for w in tokens]\n","  # remove remanining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha]\n","  # filter out stop word\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) >1]\n","  return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPd-GvCHQYo1"},"source":["\n","\n","\n","\n","# save list to file\n","def save_list(lines, filename):\n","  data = '\\n'.join(lines)\n","  file = open(filename, 'w')\n","  file.write(data)\n","  file.close()\n","\n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  #load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  #filter by vocab\n","  tokens = [w for w in tokens if w in vocab]\n","  return ' '.join(tokens)\n","\n","# load all docs in a directory\n","def process_docs(directory, vocab):\n","  lines = list()\n","  # walke through all files in the folder\n","  for filename in listdir(directory):\n","    #skip files that do not have the right extensions\n","    if not filename.endswith(\".txt\"):\n","      next\n","    # create the full path of file to open\n","    path = directory + '/' + filename\n","    # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGNvahASSGQX"},"source":["# load vocabulary\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)\n","\n","# prepare negative reviews\n","negative_lines = process_docs('/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg', vocab)\n","save_list(negative_lines, 'negative.txt')\n","\n","# prepare possitive reviews\n","possitive_lines = process_docs('/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos', vocab)\n","save_list(possitive_lines, 'possitive.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uBRrEugQF0yE"},"source":["# **2. Develop a Neural Bag-of-Words Model for Sentiment Analysis**"]},{"cell_type":"markdown","metadata":{"id":"2qKDU62fGTSj"},"source":["## 2.1. Data preparation"]},{"cell_type":"markdown","metadata":{"id":"ychmx5wUGiA3"},"source":["### 2.1.1. Load and Clean reviews\n","- Split tokens on white space\n","- Remove all punctuation form words\n","- Remove all words that are not purely comprised of alphabetical characters\n","- Remove all words that are known stop words\n","- Remove all words that have a lenght =< 1 character"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gljhqU9S3PS","executionInfo":{"elapsed":535,"status":"ok","timestamp":1635136572844,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"332df240-9946-4057-c048-18fcd565818a"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import string\n","import re\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file\n","  file.close()\n","  return text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('',w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word)>1]\n","  return tokens\n","\n","# load the document\n","filename = '/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos/cv000_29590.txt'\n","text = load_doc(filename)\n","tokens = clean_doc(text)\n","print(tokens)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","['films', 'adapted', 'comic', 'books', 'plenty', 'success', 'whether', 'theyre', 'superheroes', 'batman', 'superman', 'spawn', 'geared', 'toward', 'kids', 'casper', 'arthouse', 'crowd', 'ghost', 'world', 'theres', 'never', 'really', 'comic', 'book', 'like', 'hell', 'starters', 'created', 'alan', 'moore', 'eddie', 'campbell', 'brought', 'medium', 'whole', 'new', 'level', 'mid', 'series', 'called', 'watchmen', 'say', 'moore', 'campbell', 'thoroughly', 'researched', 'subject', 'jack', 'ripper', 'would', 'like', 'saying', 'michael', 'jackson', 'starting', 'look', 'little', 'odd', 'book', 'graphic', 'novel', 'pages', 'long', 'includes', 'nearly', 'consist', 'nothing', 'footnotes', 'words', 'dont', 'dismiss', 'film', 'source', 'get', 'past', 'whole', 'comic', 'book', 'thing', 'might', 'find', 'another', 'stumbling', 'block', 'hells', 'directors', 'albert', 'allen', 'hughes', 'getting', 'hughes', 'brothers', 'direct', 'seems', 'almost', 'ludicrous', 'casting', 'carrot', 'top', 'well', 'anything', 'riddle', 'better', 'direct', 'film', 'thats', 'set', 'ghetto', 'features', 'really', 'violent', 'street', 'crime', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', 'ghetto', 'question', 'course', 'whitechapel', 'londons', 'east', 'end', 'filthy', 'sooty', 'place', 'whores', 'called', 'unfortunates', 'starting', 'get', 'little', 'nervous', 'mysterious', 'psychopath', 'carving', 'profession', 'surgical', 'precision', 'first', 'stiff', 'turns', 'copper', 'peter', 'godley', 'robbie', 'coltrane', 'world', 'enough', 'calls', 'inspector', 'frederick', 'abberline', 'johnny', 'depp', 'blow', 'crack', 'case', 'abberline', 'widower', 'prophetic', 'dreams', 'unsuccessfully', 'tries', 'quell', 'copious', 'amounts', 'absinthe', 'opium', 'upon', 'arriving', 'whitechapel', 'befriends', 'unfortunate', 'named', 'mary', 'kelly', 'heather', 'graham', 'say', 'isnt', 'proceeds', 'investigate', 'horribly', 'gruesome', 'crimes', 'even', 'police', 'surgeon', 'cant', 'stomach', 'dont', 'think', 'anyone', 'needs', 'briefed', 'jack', 'ripper', 'wont', 'go', 'particulars', 'say', 'moore', 'campbell', 'unique', 'interesting', 'theory', 'identity', 'killer', 'reasons', 'chooses', 'slay', 'comic', 'dont', 'bother', 'cloaking', 'identity', 'ripper', 'screenwriters', 'terry', 'hayes', 'vertical', 'limit', 'rafael', 'yglesias', 'les', 'mis', 'rables', 'good', 'job', 'keeping', 'hidden', 'viewers', 'end', 'funny', 'watch', 'locals', 'blindly', 'point', 'finger', 'blame', 'jews', 'indians', 'englishman', 'could', 'never', 'capable', 'committing', 'ghastly', 'acts', 'hells', 'ending', 'whistling', 'stonecutters', 'song', 'simpsons', 'days', 'holds', 'back', 'electric', 'carwho', 'made', 'steve', 'guttenberg', 'star', 'dont', 'worry', 'itll', 'make', 'sense', 'see', 'onto', 'hells', 'appearance', 'certainly', 'dark', 'bleak', 'enough', 'surprising', 'see', 'much', 'looks', 'like', 'tim', 'burton', 'film', 'planet', 'apes', 'times', 'seems', 'like', 'sleepy', 'hollow', 'print', 'saw', 'wasnt', 'completely', 'finished', 'color', 'music', 'finalized', 'comments', 'marilyn', 'manson', 'cinematographer', 'peter', 'deming', 'dont', 'say', 'word', 'ably', 'captures', 'dreariness', 'victorianera', 'london', 'helped', 'make', 'flashy', 'killing', 'scenes', 'remind', 'crazy', 'flashbacks', 'twin', 'peaks', 'even', 'though', 'violence', 'film', 'pales', 'comparison', 'blackandwhite', 'comic', 'oscar', 'winner', 'martin', 'childs', 'shakespeare', 'love', 'production', 'design', 'turns', 'original', 'prague', 'surroundings', 'one', 'creepy', 'place', 'even', 'acting', 'hell', 'solid', 'dreamy', 'depp', 'turning', 'typically', 'strong', 'performance', 'deftly', 'handling', 'british', 'accent', 'ians', 'holm', 'joe', 'goulds', 'secret', 'richardson', 'dalmatians', 'log', 'great', 'supporting', 'roles', 'big', 'surprise', 'graham', 'cringed', 'first', 'time', 'opened', 'mouth', 'imagining', 'attempt', 'irish', 'accent', 'actually', 'wasnt', 'half', 'bad', 'film', 'however', 'good', 'strong', 'violencegore', 'sexuality', 'language', 'drug', 'content']\n"]}]},{"cell_type":"markdown","metadata":{"id":"B01c2k5IJLaO"},"source":["### 2.1.2. Define a vocabulary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZ5Sl17vHG2V","executionInfo":{"elapsed":4308,"status":"ok","timestamp":1635136587027,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"45023071-9aa3-4acc-c2a9-89604d3e25f7"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import string\n","import re\n","from os import listdir\n","from collections import Counter\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file\n","  file.close()\n","  return text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('',w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word)>1]\n","  return tokens\n","\n","# load doc and add to vocab\n","def add_doc_to_vocab(filename, vocab):\n","  # load doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # update counts\n","  vocab.update(tokens)\n","\n","# load all docs in a directory\n","def process_docs(directory, vocab):\n","  # walk through that do not have the right extensions\n","  for filename in listdir(directory):\n","    if filename.startswith('cv9'):\n","      continue\n","  # create path\n","    path = directory + '/' + filename\n","  # add doc to vocab\n","    add_doc_to_vocab(path, vocab)\n","\n","\n","# save list to file\n","def save_list(lines, filename):\n","  # convert lines to a single blob of text\n","  data = '\\n'.join(lines)\n","  #open file\n","  file = open(filename, 'w')\n","  # Write text\n","  file.write(data)\n","  # close file\n","  file.close()\n","\n","# define vocab\n","vocab = Counter()\n","# add all docs to vocab\n","process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab)\n","process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab)\n","# size\n","print(len(vocab))\n","# top words\n","print(vocab.most_common(50))\n","\n","# keep tokens with a min occurrence\n","min_occurrence = 2\n","tokens = [k for k, c in vocab.items() if c >= min_occurrence]\n","print(len(tokens))\n","# save tokens to a vocabulary file\n","save_list(tokens, 'vocab.txt')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","44276\n","[('film', 7983), ('one', 4946), ('movie', 4826), ('like', 3201), ('even', 2262), ('good', 2080), ('time', 2041), ('story', 1907), ('films', 1873), ('would', 1844), ('much', 1824), ('also', 1757), ('characters', 1735), ('get', 1724), ('character', 1703), ('two', 1643), ('first', 1588), ('see', 1557), ('way', 1515), ('well', 1511), ('make', 1418), ('really', 1407), ('little', 1351), ('life', 1334), ('plot', 1288), ('people', 1269), ('bad', 1248), ('could', 1248), ('scene', 1241), ('movies', 1238), ('never', 1201), ('best', 1179), ('new', 1140), ('scenes', 1135), ('man', 1131), ('many', 1130), ('doesnt', 1118), ('know', 1092), ('dont', 1086), ('hes', 1024), ('great', 1014), ('another', 992), ('action', 985), ('love', 977), ('us', 967), ('go', 952), ('director', 948), ('end', 946), ('something', 945), ('still', 936)]\n","25767\n"]}]},{"cell_type":"markdown","metadata":{"id":"2jCHchtMM6v4"},"source":["## 2.2. Bag-of-Words Representation"]},{"cell_type":"markdown","metadata":{"id":"OgNEqMIxOJFu"},"source":["### 2.2.1. Reviews to Lines of Tokens"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jr3xZgt1JlB4","executionInfo":{"elapsed":4237,"status":"ok","timestamp":1635136677798,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"adfb900e-c87d-4b05-8fc7-d788de06b77d"},"source":["import string\n","import re\n","from os import listdir\n","from nltk.corpus import stopwords\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only \n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file file.close()\n","  return text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]' % re.escape(string.punctuation)) \n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('', w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) > 1]\n","  return tokens\n","\n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  # load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab] \n","  return ' '.join(tokens)\n","\n","# load all docs in a directory\n","def process_docs(directory, vocab):\n","  lines = list()\n","  # walk through all files in the folder\n","  for filename in listdir(directory): \n","    # skip any reviews in the test set \n","    if filename.startswith('cv9'):\n","      continue\n","    # create the full path of the file to open\n","    path = directory + '/' + filename \n","    # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n","\n","# load and clean a dataset\n","def load_clean_dataset(vocab):\n","  # load documents\n","  neg = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab)\n","  pos = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab)\n","  docs = neg + pos\n","  # prepare labels\n","  labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))] \n","  return docs, labels\n","\n","# load the vocabulary\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)\n","# load all training reviews\n","docs, labels = load_clean_dataset(vocab) \n","# summarize what we have \n","print(len(docs), len(labels))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["1800 1800\n"]}]},{"cell_type":"markdown","metadata":{"id":"GWfwE7yYOMMp"},"source":["### 2.2.2. Movie Reviews to Bag of Words Vectors"]},{"cell_type":"code","metadata":{"id":"QW_XX4YpNN96"},"source":["from keras.preprocessing.text import Tokenizer\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(lines)\n","  return tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QObZehQ5PQYu","executionInfo":{"elapsed":6594,"status":"ok","timestamp":1635136736272,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"e95e9198-e649-4b07-def1-484e47626f0c"},"source":["import string\n","import re\n","from os import listdir\n","from nltk.corpus import stopwords\n","from keras_preprocessing.text import Tokenizer\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only \n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file file.close()\n","  return text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]' % re.escape(string.punctuation)) \n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('', w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) > 1]\n","  return tokens\n","\n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  # load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab] \n","  return ' '.join(tokens)\n","\n","# load all docs in a directory\n","def process_docs(directory, vocab, is_train):\n","  lines = list()\n","  # walk through all files in the folder\n","  for filename in listdir(directory):\n","    #skip any reviews in the test set\n","    if is_train and filename.startswith('cv9'):\n","      continue\n","    if not is_train and not filename.startswith('cv9'):\n","      continue\n","    # create the full path of the file to open\n","    path = directory + '/' + filename\n","    # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n","\n","# load and clean dataset\n","def load_clean_dataset(vocab, is_train):\n","  # load documents\n","  neg = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab, is_train)\n","  pos = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab, is_train)\n","  docs = neg + pos\n","  # prepare labels\n","  labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n","  return docs, labels\n","\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(lines)\n","  return tokenizer\n","\n","# load the vocabulary\n","\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = set(vocab.split())\n","\n","# load all reviews\n","train_docs, y_train = load_clean_dataset(vocab, True)\n","test_docs, y_test = load_clean_dataset(vocab, False)\n","\n","# Create the tokenizer\n","tokenizer = create_tokenizer(train_docs)\n","\n","# encode data\n","Xtrain = tokenizer.texts_to_matrix(train_docs, mode = 'freq')\n","Xtest = tokenizer.texts_to_matrix(test_docs, mode = 'freq')\n","print(Xtrain.shape, Xtest.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(1800, 25768) (200, 25768)\n"]}]},{"cell_type":"markdown","metadata":{"id":"2q-VQxqsSKXm"},"source":["## 2.3. Sentiment Analysis Models"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5wUklVpPPsL","executionInfo":{"elapsed":9601,"status":"ok","timestamp":1635136801700,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"fe1efc7f-3a0c-47cd-c5d8-b7a8d0b0b087"},"source":["from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy as np\n","\n","# define model\n","def define_model(n_words):\n","  # define network\n","  model = Sequential()\n","  model.add(Dense(50, input_shape=(n_words,), activation = 'relu'))\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # compile network\n","  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","  # summarize defined model\n","  model.summary()\n","  plot_model(model, to_file = \"model.png\", show_shapes = True)\n","  return model\n","\n","n_words = Xtest.shape[1]\n","model = define_model(n_words)\n","\n","# fit network\n","model.fit(Xtrain, np.array(y_train), epochs = 10, verbose = 2)\n","\n","# evaluate\n","loss, acc = model.evaluate(Xtest, np.array(y_test), verbose = 0)\n","print('Test Accuracy %f' %(acc*100))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 50)                1288450   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 51        \n","=================================================================\n","Total params: 1,288,501\n","Trainable params: 1,288,501\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","57/57 - 1s - loss: 0.6919 - accuracy: 0.5294\n","Epoch 2/10\n","57/57 - 1s - loss: 0.6828 - accuracy: 0.7183\n","Epoch 3/10\n","57/57 - 1s - loss: 0.6644 - accuracy: 0.6894\n","Epoch 4/10\n","57/57 - 1s - loss: 0.6351 - accuracy: 0.8700\n","Epoch 5/10\n","57/57 - 1s - loss: 0.5975 - accuracy: 0.9322\n","Epoch 6/10\n","57/57 - 1s - loss: 0.5540 - accuracy: 0.9350\n","Epoch 7/10\n","57/57 - 1s - loss: 0.5074 - accuracy: 0.9467\n","Epoch 8/10\n","57/57 - 1s - loss: 0.4613 - accuracy: 0.9567\n","Epoch 9/10\n","57/57 - 1s - loss: 0.4165 - accuracy: 0.9567\n","Epoch 10/10\n","57/57 - 1s - loss: 0.3752 - accuracy: 0.9656\n","Test Accuracy 87.000000\n"]}]},{"cell_type":"markdown","metadata":{"id":"gSOZBKzCVMf_"},"source":["## 2.4. Comparing Word Scoring methods"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Sn0QyF5rU3EY","executionInfo":{"elapsed":250316,"status":"ok","timestamp":1635137275904,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"a3b10a5a-1544-44d7-f9cf-ee0626ecd76a"},"source":["import string\n","import re\n","from os import listdir\n","from nltk.corpus import stopwords\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from pandas import DataFrame\n","import matplotlib.pyplot as plt\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only \n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file file.close()\n","  return text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]' % re.escape(string.punctuation)) \n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('', w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) > 1]\n","  return tokens\n","\n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  # load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab] \n","  return ' '.join(tokens)\n","\n","# load all docs in a directory\n","def process_docs(directory, vocab, is_train):\n","  lines = list()\n","  # walk through all files in the folder\n","  for filename in listdir(directory):\n","    # skip any reviews in the test set\n","    if is_train and filename.startswith('cv9'): \n","      continue\n","    if not is_train and not filename.startswith('cv9'): \n","      continue\n","    # create the full path of the file to open\n","    path = directory + '/' + filename # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n","\n","\n","\n","\n","# load and clean dataset\n","def load_clean_dataset(vocab, is_train):\n","  # load documents\n","  neg = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab, is_train)\n","  pos = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab, is_train)\n","  docs = neg + pos\n","  # prepare labels\n","  labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n","  return docs, labels\n","\n","\n","# define the model\n","def define_model(n_words):\n","  # define network\n","  model = Sequential()\n","  model.add(Dense(50, input_shape=(n_words,), activation='relu')) \n","  model.add(Dense(1, activation='sigmoid'))\n","  # compile network\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model\n","\n","# evaluate a neural network model\n","def evaluate_mode(Xtrain, ytrain, Xtest, ytest):\n","  scores = list()\n","  n_repeats = 10\n","  n_words = Xtest.shape[1]\n","  for i in range(n_repeats):\n","    # define network\n","    model = define_model(n_words)\n","    # fit network\n","    model.fit(Xtrain, np.array(ytrain), epochs=10, verbose=0)\n","    # evaluate\n","    _, acc = model.evaluate(Xtest, np.array(ytest), verbose=0) \n","    scores.append(acc)\n","    print('%d accuracy: %s' % ((i+1), acc))\n","  return scores\n","\n","# prepare bag of words encoding of docs\n","def prepare_data(train_docs, test_docs, mode):\n","  # create the tokenizer\n","  tokenizer = Tokenizer()\n","  # fit the tokenizer on the documents\n","  tokenizer.fit_on_texts(train_docs)\n","  # encode training data set\n","  Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n","  # encode training data set\n","  Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n","  return Xtrain, Xtest\n","\n","# load the vocabulary\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = set(vocab.split())\n","# load all reviews\n","train_docs, ytrain = load_clean_dataset(vocab, True) \n","test_docs, ytest = load_clean_dataset(vocab, False) \n","# run experiment\n","modes = ['binary', 'count', 'tfidf', 'freq']\n","results = DataFrame()\n","for mode in modes:\n","  # prepare data for mode\n","  Xtrain, Xtest = prepare_data(train_docs, test_docs, mode)\n","  # evaluate model on data for mode\n","  results[mode] = evaluate_mode(Xtrain, ytrain, Xtest, ytest)\n","# summarize results\n","print(results.describe())\n","# plot results\n","results.boxplot()\n","plt.show()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["1 accuracy: 0.9300000071525574\n","2 accuracy: 0.9300000071525574\n","3 accuracy: 0.9200000166893005\n","4 accuracy: 0.9449999928474426\n","5 accuracy: 0.9399999976158142\n","6 accuracy: 0.9449999928474426\n","7 accuracy: 0.9350000023841858\n","8 accuracy: 0.9350000023841858\n","9 accuracy: 0.9300000071525574\n","10 accuracy: 0.925000011920929\n","1 accuracy: 0.8799999952316284\n","2 accuracy: 0.9049999713897705\n","3 accuracy: 0.8949999809265137\n","4 accuracy: 0.9049999713897705\n","5 accuracy: 0.8999999761581421\n","6 accuracy: 0.9049999713897705\n","7 accuracy: 0.8949999809265137\n","8 accuracy: 0.8949999809265137\n","9 accuracy: 0.8949999809265137\n","10 accuracy: 0.8949999809265137\n","1 accuracy: 0.8899999856948853\n","2 accuracy: 0.8899999856948853\n","3 accuracy: 0.8550000190734863\n","4 accuracy: 0.8949999809265137\n","5 accuracy: 0.8899999856948853\n","6 accuracy: 0.8600000143051147\n","7 accuracy: 0.8600000143051147\n","8 accuracy: 0.8799999952316284\n","9 accuracy: 0.8799999952316284\n","10 accuracy: 0.8799999952316284\n","1 accuracy: 0.8700000047683716\n","2 accuracy: 0.8700000047683716\n","3 accuracy: 0.8550000190734863\n","4 accuracy: 0.8799999952316284\n","5 accuracy: 0.8700000047683716\n","6 accuracy: 0.8700000047683716\n","7 accuracy: 0.8600000143051147\n","8 accuracy: 0.875\n","9 accuracy: 0.8700000047683716\n","10 accuracy: 0.875\n","          binary      count      tfidf       freq\n","count  10.000000  10.000000  10.000000  10.000000\n","mean    0.933500   0.897000   0.878000   0.869500\n","std     0.008182   0.007528   0.014568   0.007246\n","min     0.920000   0.880000   0.855000   0.855000\n","25%     0.930000   0.895000   0.865000   0.870000\n","50%     0.932500   0.895000   0.880000   0.870000\n","75%     0.938750   0.903750   0.890000   0.873750\n","max     0.945000   0.905000   0.895000   0.880000\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"4k8-xyauX5Dz","executionInfo":{"elapsed":10,"status":"ok","timestamp":1634913021815,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"edcb644f-0e70-457c-d0bb-9ad186f383ea"},"source":["results.boxplot()"],"execution_count":null,"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fbcb33f8e50>"]},"execution_count":48,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"WJHLCl9GaXJu"},"source":["## 2.5. Predicting Sentiment for New Reviews"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"4SyWWNIiaKaH","executionInfo":{"elapsed":948,"status":"error","timestamp":1634957527334,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"4c1eccc8-275d-41ab-8675-6bf4e88f64b5"},"source":["# classify a review as negative or possitive\n","def predict_sentiment(review, vocab, tokenizer, model):\n","  # clean\n","  tokens = clean_doc(review)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab]\n","  # convert to line\n","  line = ' '.join(tokens)\n","  # encode\n","  encoded = tokenizer.texts_to_matrix([line], mode = 'binary')\n","  # predict sentiment\n","  yhat = model.predict(encoded, verbose = 0)\n","  # retrieve predicted percentage and label\n","  percent_pos = yhat[0,0]\n","  if round(percent_pos) == 0:\n","    return (1-percent_pos), 'NEGATIVE'\n","  return percent_pos, \"POSSITIVE\"\n","\n","# test positive text\n","text = 'Best movie ever! It was great, I recommend it.'\n","percent, sentiment = predict_sentiment(text, vocab, tokenizer, model) \n","print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100)) \n","\n","# test negative text\n","text = 'This is a bad movie.'\n","percent, sentiment = predict_sentiment(text, vocab, tokenizer, model) \n","print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))"],"execution_count":null,"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b59e538ae4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# test positive text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Best movie ever! It was great, I recommend it.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpercent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Review: [%s]\\nSentiment: %s (%.3f%%)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"vDuHQk9AcaHj"},"source":["## 2.6 COMPLETE CODE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"rE2Encfg6Y55","executionInfo":{"elapsed":57413,"status":"error","timestamp":1634957485055,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"ba79f898-c3bd-4d11-ab98-3e5db3d7cce6"},"source":["import string \n","import re\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from os import listdir\n","from keras_preprocessing.text import Tokenizer\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy as np\n","import tensorflow as tf\n","from collections import Counter\n","\n","# Func 1: load doc into memory\n","def load_doc(filename):\n","  # open file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file\n","  file.close()\n","  return text\n","\n","# Func 2: turn doc into tokens\n","def clean_doc(doc):\n","  # split into tokens by white spance\n","  tokens = doc.split()\n","  # reparare regex for char filtering\n","  re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('', w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) >1]\n","  return tokens\n","\n","# Func 3: load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  # load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab]\n","  return ' '.join(tokens)\n","\n","# Func 4: load all docs in directory\n","def process_docs(directory, vocab, is_train):\n","  lines = list()\n","  # walk through all files in the folder\n","  for filename in listdir(directory):\n","    # skip any reviews in the test set\n","    if is_train and filename.startswith('cv9'):\n","      continue\n","    if not is_train and not filename.startswith('cv9'):\n","      continue\n","    # create the full path of the file to open\n","    path = directory + '/' + filename\n","    # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n","\n","# Func 5: load and clean dataset\n","def load_clean_dataset(vocab, istrain):\n","  # load documents\n","  neg = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab, istrain)\n","  pos = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab, istrain)\n","  docs = neg + pos\n","  # prepare labels\n","  labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n","  return docs, labels\n","\n","# Func 6: fit a tokenizer\n","def create_tokenizer(lines):\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(lines)\n","  return tokenizer\n","\n","# Func 7: define model\n","def define_model(n_words):\n","  # define network\n","  model = Sequential()\n","  model.add(Dense(50, input_shape = (n_words,), activation = 'relu'))\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # compile network\n","  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","  # summarize defined model\n","  model.summary()\n","  plot_model(model, to_file = \"model.png\", show_shapes = True)\n","  return model\n","\n","# Func 8: classify a review as negative or possitive\n","def predict_sentiment(review, vocab, tokenizer, model):\n","  # clean\n","  tokens = clean_doc(review)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab]\n","  # convert to line\n","  line = ' '.join(tokens)\n","  # encode\n","  encoded = tokenizer.texts_to_matrix([line], mode = 'binary')\n","  # predict sentiment\n","  yhat = model.predict(encoded, verbose = 0)\n","  # retrieve predicted percentage and label\n","  percent_pos = yhat[0,0]\n","  if round(percent_pos) == 0:\n","    return (1-percent_pos), 'NEGATIVE'\n","  return percent_pos, \"POSSITIVE\"\n","\n","# Func 9: save list to file\n","def save_list(lines, filename):\n","  # convert lines to a single blob of text\n","  data = '\\n'.join(lines)\n","  #open file\n","  file = open(filename, 'w')\n","  # Write text\n","  file.write(data)\n","  # close file\n","  file.close()\n","\n","# Apply\n","\n","# define vocab\n","vocab = Counter()\n","# add all docs to vocab\n","process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab, True)\n","process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab, True)\n","# size\n","print(len(vocab))\n","# top words\n","print(vocab.most_common(50))\n","\n","# keep tokens with a min occurrence\n","min_occurrence = 2\n","tokens = [k for k, c in vocab.items() if c >= min_occurrence]\n","print(len(tokens))\n","# save tokens to a vocabulary file\n","save_list(tokens, 'vocab.txt')\n","\n","\n","# load the vocabulary\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = set(vocab.split())\n","\n","# load all reviews\n","train_docs, y_train = load_clean_dataset(vocab, True)\n","test_docs, y_test = load_clean_dataset(vocab, False)\n","\n","# Create the tokenizer\n","tokenizer = create_tokenizer(train_docs)\n","\n","# encode data\n","Xtrain = tokenizer.texts_to_matrix(train_docs, mode = 'freq')\n","Xtest = tokenizer.texts_to_matrix(test_docs, mode = 'freq')\n","print(Xtrain.shape, Xtest.shape)\n","\n","# define network\n","n_words = Xtrain.shape[1]\n","model = define_model(n_words)\n","# fit network\n","model.fit(Xtrain, np.array(ytrain), epochs=10, verbose=2)\n","# test positive text\n","text = 'Best movie ever! It was great, I recommend it.'\n","percent, sentiment = predict_sentiment(text, vocab, tokenizer, model) \n","print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100)) \n","# test negative text\n","text = 'This is a bad movie.'\n","percent, sentiment = predict_sentiment(text, vocab, tokenizer, model) \n","print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","0\n","[]\n","0\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-d327b5c5c879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;31m# encode data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'freq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0mXtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'freq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_matrix\u001b[0;34m(self, texts, mode)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \"\"\"\n\u001b[1;32m    382\u001b[0m         \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msequences_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36msequences_to_matrix\u001b[0;34m(self, sequences, mode)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 raise ValueError('Specify a dimension (`num_words` argument), '\n\u001b[0m\u001b[1;32m    405\u001b[0m                                  'or fit on some text data first.')\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Specify a dimension (`num_words` argument), or fit on some text data first."]}]},{"cell_type":"code","metadata":{"id":"Rry0tq5S7KXj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBEVg2EXcTBh","executionInfo":{"elapsed":13206,"status":"ok","timestamp":1634913776600,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"cb82b9d9-8e52-481b-c3e1-d92750185912"},"source":["import string\n","import re\n","from os import listdir\n","from nltk.corpus import stopwords\n","from keras_preprocessing.text import Tokenizer\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy as np\n","\n","# load doc into memory\n","def load_doc(filename):\n","  # open the file as read only \n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file file.close()\n","  return text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","  # split into tokens by white space\n","  tokens = doc.split()\n","  # prepare regex for char filtering\n","  re_punc = re.compile('[%s]' % re.escape(string.punctuation)) \n","  # remove punctuation from each word\n","  tokens = [re_punc.sub('', w) for w in tokens]\n","  # remove remaining tokens that are not alphabetic\n","  tokens = [word for word in tokens if word.isalpha()]\n","  # filter out stop words\n","  stop_words = set(stopwords.words('english'))\n","  tokens = [w for w in tokens if not w in stop_words]\n","  # filter out short tokens\n","  tokens = [word for word in tokens if len(word) > 1]\n","  return tokens\n","\n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","  # load the doc\n","  doc = load_doc(filename)\n","  # clean doc\n","  tokens = clean_doc(doc)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab] \n","  return ' '.join(tokens)\n","\n","# load all docs in a directory\n","def process_docs(directory, vocab, is_train):\n","  lines = list()\n","  # walk through all files in the folder\n","  for filename in listdir(directory):\n","    #skip any reviews in the test set\n","    if is_train and filename.startswith('cv9'):\n","      continue\n","    if not is_train and not filename.startswith('cv9'):\n","      continue\n","    # create the full path of the file to open\n","    path = directory + '/' + filename\n","    # load and clean the doc\n","    line = doc_to_line(path, vocab)\n","    # add to list\n","    lines.append(line)\n","  return lines\n","\n","# load and clean dataset\n","def load_clean_dataset(vocab, is_train):\n","  # load documents\n","  neg = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/neg\", vocab, is_train)\n","  pos = process_docs(\"/content/drive/MyDrive/Dataset/review_polarity/txt_sentoken/pos\", vocab, is_train)\n","  docs = neg + pos\n","  # prepare labels\n","  labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n","  return docs, labels\n","\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(lines)\n","  return tokenizer\n","\n","# define model\n","def define_model(n_words):\n","  # define network\n","  model = Sequential()\n","  model.add(Dense(50, input_shape=(n_words,), activation = 'relu'))\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # compile network\n","  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","  # summarize defined model\n","  model.summary()\n","  plot_model(model, to_file = \"model.png\", show_shapes = True)\n","  return model\n","\n","# classify a review as negative or possitive\n","def predict_sentiment(review, vocab, tokenizer, model):\n","  # clean\n","  tokens = clean_doc(review)\n","  # filter by vocab\n","  tokens = [w for w in tokens if w in vocab]\n","  # convert to line\n","  line = ' '.join(tokens)\n","  # encode\n","  encoded = tokenizer.texts_to_matrix([line], mode = 'binary')\n","  # predict sentiment\n","  yhat = model.predict(encoded, verbose = 0)\n","  # retrieve predicted percentage and label\n","  percent_pos = yhat[0,0]\n","  if round(percent_pos) == 0:\n","    return (1-percent_pos), 'NEGATIVE'\n","  return percent_pos, \"POSSITIVE\"\n","\n","# load the vocabulary\n","vocab_filename = 'vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = set(vocab.split())\n","\n","# load all reviews\n","train_docs, y_train = load_clean_dataset(vocab, True)\n","test_docs, y_test = load_clean_dataset(vocab, False)\n","\n","# Create the tokenizer\n","tokenizer = create_tokenizer(train_docs)\n","\n","# encode data\n","Xtrain = tokenizer.texts_to_matrix(train_docs, mode = 'freq')\n","Xtest = tokenizer.texts_to_matrix(test_docs, mode = 'freq')\n","print(Xtrain.shape, Xtest.shape)\n","\n","# define network\n","n_words = Xtrain.shape[1]\n","model = define_model(n_words)\n","# fit network\n","model.fit(Xtrain, np.array(ytrain), epochs=10, verbose=2)\n","# test positive text\n","text = 'Best movie ever! It was great, I recommend it.'\n","percent, sentiment = predict_sentiment(text, vocab, tokenizer, model) \n","print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100)) \n","# test negative text\n","text = 'This is a bad movie.'\n","percent, sentiment = predict_sentiment(text, vocab, tokenizer, model) \n","print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(1800, 25768) (200, 25768)\n","Model: \"sequential_49\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_90 (Dense)             (None, 50)                1288450   \n","_________________________________________________________________\n","dense_91 (Dense)             (None, 1)                 51        \n","=================================================================\n","Total params: 1,288,501\n","Trainable params: 1,288,501\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.6100\n","Epoch 2/10\n","57/57 - 1s - loss: 0.6810 - accuracy: 0.8044\n","Epoch 3/10\n","57/57 - 1s - loss: 0.6620 - accuracy: 0.8761\n","Epoch 4/10\n","57/57 - 1s - loss: 0.6333 - accuracy: 0.9106\n","Epoch 5/10\n","57/57 - 1s - loss: 0.5960 - accuracy: 0.9272\n","Epoch 6/10\n","57/57 - 1s - loss: 0.5522 - accuracy: 0.9406\n","Epoch 7/10\n","57/57 - 1s - loss: 0.5061 - accuracy: 0.9472\n","Epoch 8/10\n","57/57 - 1s - loss: 0.4594 - accuracy: 0.9533\n","Epoch 9/10\n","57/57 - 1s - loss: 0.4160 - accuracy: 0.9606\n","Epoch 10/10\n","57/57 - 1s - loss: 0.3742 - accuracy: 0.9650\n","Review: [Best movie ever! It was great, I recommend it.]\n","Sentiment: POSSITIVE (99.579%)\n","Review: [This is a bad movie.]\n","Sentiment: NEGATIVE (100.000%)\n"]}]},{"cell_type":"markdown","metadata":{"id":"XOICz9HPBeJv"},"source":["# ***WORD EMBEDDINGS***"]},{"cell_type":"markdown","metadata":{"id":"c8DroEnzBz2i"},"source":["# **3. Word Embeddings with Gensim**"]},{"cell_type":"markdown","metadata":{"id":"drNZjhgyDEQa"},"source":["## 3.1 Develop Word2Vec Embedding"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgLo63NQCDoM","executionInfo":{"elapsed":442,"status":"ok","timestamp":1634957610094,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"821bc4e0-6cc0-4769-be5a-5e36d62bbac2"},"source":["from gensim.models import Word2Vec\n","# define training data\n","sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n","['this', 'is', 'the', 'second', 'sentence'], ['yet', 'another', 'sentence'],\n","['one', 'more', 'sentence'],\n","['and', 'the', 'final', 'sentence']]\n","\n","# train model\n","model = Word2Vec(sentences, min_count = 1)\n","# summarize the loaded model\n","print(model)\n","# summarize the vocabulary\n","words = list(model.wv.vocab)\n","print(words)\n","# access vector for one word\n","print(model['sentence'])\n","# save model\n","model.save('model.bin')\n","# load model\n","new_model = Word2Vec.load('model.bin') \n","print(new_model)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Word2Vec(vocab=14, size=100, alpha=0.025)\n","['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec', 'second', 'yet', 'another', 'one', 'more', 'and', 'final']\n","[-2.6062101e-03  4.8146527e-03  3.8209406e-03 -3.5028085e-03\n"," -2.3539094e-03  2.4749124e-03  3.9515588e-03 -2.6104390e-03\n","  3.0833473e-03  2.4249158e-03  3.0639658e-03  2.9502690e-03\n"," -3.2957299e-03 -2.1512618e-03  1.7855539e-03 -1.7147292e-03\n","  1.1837251e-03 -4.7799577e-03 -4.9742516e-03 -6.5330986e-04\n","  4.8001166e-03  2.6075491e-03  3.0129005e-03 -2.5689094e-03\n"," -4.9290764e-03  3.6106710e-03 -4.2453785e-03  3.6488338e-03\n"," -3.5462468e-03  4.3271249e-03  4.0585767e-03 -8.1593142e-05\n"," -8.3581993e-04  2.7821646e-03  4.6722352e-04  4.1624135e-03\n","  7.0298422e-04 -7.1714399e-04 -1.7185238e-03  3.3197240e-03\n","  1.2963354e-03 -4.1343036e-04 -3.6400636e-03 -1.8883580e-03\n","  1.7598915e-03 -1.9218680e-03  4.1946135e-03 -3.6171617e-03\n","  2.7547223e-03 -3.0732735e-03  2.6187722e-03  1.8888679e-03\n","  7.0422841e-04  3.4545355e-03 -4.2398022e-03 -1.6323574e-03\n","  4.6095415e-03  3.3608074e-03  9.2184229e-04 -3.7044657e-03\n","  3.7736821e-03  1.6106063e-03 -1.2302778e-03  2.4444282e-03\n"," -9.0543862e-04 -4.9361903e-03  3.5557579e-03 -6.6859002e-04\n"," -1.0650576e-04 -1.9928731e-03 -1.1774272e-03  4.0417616e-03\n"," -2.4418053e-03 -4.0161619e-03  2.0135029e-03 -2.3099370e-03\n"," -7.8423566e-04 -3.7302352e-03  4.3216990e-03  3.6587266e-03\n"," -1.1966991e-03  3.3704689e-04  3.1413443e-03 -2.2609236e-03\n","  3.3388212e-03 -4.5854631e-03 -4.3929979e-04 -1.2579918e-03\n","  3.2092980e-04 -4.6534739e-03 -3.6859349e-03  2.2883170e-04\n","  3.8207367e-03  1.5889630e-03 -2.8584707e-03 -3.5874348e-03\n","  4.5346324e-03 -4.5489413e-03 -3.9586904e-03  2.1530578e-03]\n","Word2Vec(vocab=14, size=100, alpha=0.025)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  app.launch_new_instance()\n"]}]},{"cell_type":"markdown","metadata":{"id":"qHW3aASCDCes"},"source":["## 3.2. Visualize Word Embedding with PCA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"id":"lcPAGeGfdB6B","executionInfo":{"elapsed":719,"status":"ok","timestamp":1634957851280,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"de7624c5-9ff8-4bba-c061-65583e9c6aee"},"source":["from gensim.models import Word2Vec\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","\n","# define training data\n","sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n","['this', 'is', 'the', 'second', 'sentence'], ['yet', 'another', 'sentence'],\n","['one', 'more', 'sentence'],\n","['and', 'the', 'final', 'sentence']]\n","\n","# train model\n","model = Word2Vec(sentences, min_count = 1)\n","# fit a 2d PCA model to the vectors\n","X = model[model.wv.vocab]\n","pca = PCA(n_components = 2)\n","result = pca.fit_transform(X)\n","# create a scatter plot of the projection\n","plt.scatter(result[:,0], result[:,1])\n","\n","words = list(model.wv.vocab)\n","for i, word in enumerate(words):\n","  plt.annotate(word, xy=(result[i,0], result[i, 1]))\n","plt.show()"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  \n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"zWpfw_MSHWIL"},"source":["## 3.3 Google's Word2Vec Embedding"]},{"cell_type":"code","metadata":{"id":"re0Ro-1cFPS9"},"source":["from gensim.models import KeyedVectors\n","# load the google word2vec model\n","filename = '/content/drive/MyDrive/Dataset/GoogleNews-vectors-negative300.bin.gz'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SXg5BsxIsY-"},"source":["model = KeyedVectors.load_word2vec_format(filename, binary=True)\n","# calculate: (king - man) + woman = ?\n","result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1) \n","print(result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xkhz0ssrI4Y-"},"source":["## 3.4. Standford's GloVe Embedding"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaqdqJHcItlS","executionInfo":{"elapsed":49017,"status":"ok","timestamp":1635137552166,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"808a5898-7d05-48bd-ed5f-b667a2b6c207"},"source":["from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","# convert glove to word2vec format\n","glove_input_file = '/content/drive/MyDrive/GloVec/glove.6B.100d.txt' \n","word2vec_output_file = 'glove.6B.100d.txt.word2vec' \n","glove2word2vec(glove_input_file, word2vec_output_file)\n","# load the converted model\n","filename = 'glove.6B.100d.txt.word2vec'\n","model = KeyedVectors.load_word2vec_format(filename, binary=False)\n","# calculate: (king - man) + woman = ?\n","result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1) \n","print(result)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[('queen', 0.7698541283607483)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"10phSMgUJq-U"},"source":["# **4. Learn and Load Word Embeddings in Keras**"]},{"cell_type":"markdown","metadata":{"id":"uywuJRuGJzjQ"},"source":["## 4.1. Embedding"]},{"cell_type":"code","metadata":{"id":"3DbbIP3PJeI7"},"source":["# define documents\n","docs = ['Well done!', 'Good work',\n","'Great effort', 'nice work', 'Excellent!', 'Weak',\n","'Poor effort!',\n","'not good',\n","'poor work',\n","'Could have done better.']\n","# define class labels\n","labels = [1,1,1,1,1,0,0,0,0,0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yAtPEdxJ4dm","executionInfo":{"elapsed":1031,"status":"ok","timestamp":1634966520721,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"6c7ded64-0a22-47af-81c0-1d7efdab87eb"},"source":["from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten\n","from keras.layers.embeddings import Embedding\n","import numpy as np\n","import tensorflow as tf\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# define documents\n","docs = ['Well done!', 'Good work',\n","'Great effort', 'nice work', 'Excellent!', 'Weak',\n","'Poor effort!',\n","'not good',\n","'poor work',\n","'Could have done better.']\n","# define class labels\n","labels = np.array([1,1,1,1,1,0,0,0,0,0])\n","\n","# integer encode the documents\n","vocab_size = 50\n","encoded_docs = [one_hot(d, vocab_size) for d in docs]\n","print(encoded_docs)\n","\n","# pad documents to a max length of 4 words\n","max_length = 4\n","padded_docs = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\n","print(padded_docs)\n","\n","# define model\n","model = Sequential()\n","model.add(Embedding(vocab_size, 8, input_length = max_length))\n","model.add(Flatten())\n","model.add(Dense(1, activation = 'sigmoid'))\n","# compile the model\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","# summarize the model\n","model.summary()\n","# fit the model\n","model.fit(padded_docs, labels, epochs = 50, verbose = 0)\n","# evaluate the model\n","loss, acc = model.evaluate(padded_docs, labels, verbose = 0)\n","print(\"Accuracy : %f\" %(acc*100))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[39, 33], [19, 42], [44, 9], [32, 42], [21], [6], [10, 9], [13, 19], [10, 42], [25, 37, 33, 47]]\n","[[39 33  0  0]\n"," [19 42  0  0]\n"," [44  9  0  0]\n"," [32 42  0  0]\n"," [21  0  0  0]\n"," [ 6  0  0  0]\n"," [10  9  0  0]\n"," [13 19  0  0]\n"," [10 42  0  0]\n"," [25 37 33 47]]\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_6 (Embedding)      (None, 4, 8)              400       \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 32)                0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 433\n","Trainable params: 433\n","Non-trainable params: 0\n","_________________________________________________________________\n","Accuracy : 80.000001\n"]}]},{"cell_type":"markdown","metadata":{"id":"-5N702ogmeYm"},"source":["## 4.2. Pre-Trained GloVe Embedding"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AwRDS-yObnK","executionInfo":{"elapsed":12534,"status":"ok","timestamp":1635137338696,"user":{"displayName":"Tiểu Long Phan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06195310281051173481"},"user_tz":-420},"outputId":"1cc2cd0d-2cbb-4499-9892-3f86333b13bc"},"source":["from numpy import asarray\n","from numpy import zeros\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences \n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Embedding\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# define documents\n","docs = ['Well done!',\n","'Good work', 'Great effort', 'nice work', 'Excellent!', 'Weak',\n","'Poor effort!',\n","'not good',\n","'poor work',\n","'Could have done better.']\n","\n","# define class labels\n","labels = np.array([1,1,1,1,1,0,0,0,0,0])\n","\n","# prepare tokenizer\n","t = Tokenizer()\n","t.fit_on_texts(docs)\n","vocab_size = len(t.word_index) + 1\n","\n","# integer encode the documents\n","encoded_docs = t.texts_to_sequences(docs)\n","print(encoded_docs)\n","\n","# pad documents to a max length of 4 words\n","max_length = 4\n","padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post') \n","print(padded_docs)\n","\n","# load the whole embedding into memory\n","embeddings_index = dict()\n","f = open('/content/drive/MyDrive/GloVec/glove.6B.100d.txt', mode='rt', encoding='utf-8')\n","for line in f:\n","  values = line.split()\n","  word = values[0]\n","  coefs = asarray(values[1:], dtype='float32') \n","  embeddings_index[word] = coefs\n","f.close()\n","print('Loaded %s word vectors.' % len(embeddings_index)) \n","# create a weight matrix for words in training docs \n","embedding_matrix = zeros((vocab_size, 100))\n","for word, i in t.word_index.items():\n","  embedding_vector = embeddings_index.get(word)\n","  if embedding_vector is not None:\n","    embedding_matrix[i] = embedding_vector\n","\n","# define model\n","model = Sequential()\n","e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False) \n","model.add(e)\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","# summarize the model\n","model.summary()\n","# fit the model\n","model.fit(padded_docs, labels, epochs=50, verbose=0)\n","# evaluate the model\n","loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n","print('Accuracy: %f' % (accuracy*100))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n","[[ 6  2  0  0]\n"," [ 3  1  0  0]\n"," [ 7  4  0  0]\n"," [ 8  1  0  0]\n"," [ 9  0  0  0]\n"," [10  0  0  0]\n"," [ 5  4  0  0]\n"," [11  3  0  0]\n"," [ 5  1  0  0]\n"," [12 13  2 14]]\n","Loaded 400000 word vectors.\n","Model: \"sequential_41\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 4, 100)            1500      \n","_________________________________________________________________\n","flatten (Flatten)            (None, 400)               0         \n","_________________________________________________________________\n","dense_82 (Dense)             (None, 1)                 401       \n","=================================================================\n","Total params: 1,901\n","Trainable params: 401\n","Non-trainable params: 1,500\n","_________________________________________________________________\n","Accuracy: 100.000000\n"]}]},{"cell_type":"code","metadata":{"id":"Ic4eQKkhxyOw"},"source":[""],"execution_count":null,"outputs":[]}]}