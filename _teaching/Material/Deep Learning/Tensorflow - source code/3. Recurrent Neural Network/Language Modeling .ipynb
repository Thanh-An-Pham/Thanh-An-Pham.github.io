{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRovg52YEtDx"
   },
   "source": [
    "# **1. Develop a Character-Based Neural Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1635125000454,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "8m_BxQLrCxi6",
    "outputId": "c6858791-f563-410a-e373-60ba1d10afc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkZIG013EysQ"
   },
   "source": [
    "## 1.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2934,
     "status": "ok",
     "timestamp": 1635125015793,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "xGvUNCdgE4PD",
    "outputId": "4dbc70a0-d81b-4c86-88d5-2ecda744a429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sing a song of sixpence,\n",
      "A pocket full of rye.\n",
      "Four and twenty blackbirds,\n",
      "Baked in a pie.\n",
      "\n",
      "When the pie was opened\n",
      "The birds began to sing;\n",
      "Wasn't that a dainty dish,\n",
      "To set before the king.\n",
      "\n",
      "The king was in his counting house,\n",
      "Counting out his money;\n",
      "The queen was in the parlour,\n",
      "Eating bread and honey.\n",
      "\n",
      "The maid was in the garden,\n",
      "Hanging out the clothes,\n",
      "When down came a blackbird\n",
      "And pecked off her nose.\n",
      "Total Sequences: 399\n"
     ]
    }
   ],
   "source": [
    "# 1. load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only\n",
    "  file = open(filename, 'r')\n",
    "  # read all text\n",
    "  text = file.read()\n",
    "  # close\n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "# 2. save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "  data = '\\n'.join(lines)\n",
    "  file = open(filename, 'w')\n",
    "  file.write(data)\n",
    "  file.close()\n",
    "\n",
    "# load text\n",
    "raw_text = load_doc('/content/drive/MyDrive/Dataset/rhyme.txt') \n",
    "print(raw_text)\n",
    "# clean\n",
    "tokens = raw_text.split() \n",
    "raw_text = ' '.join(tokens)\n",
    "# organize into sequences of characters\n",
    "length = 10\n",
    "sequences = list()\n",
    "for i in range(length, len(raw_text)):\n",
    "  # select sequence of tokens\n",
    "  seq = raw_text[i-length:i+1]\n",
    "  # store\n",
    "  sequences.append(seq)\n",
    "\n",
    "print('Total Sequences: %d' % len(sequences)) \n",
    "# save sequences to file\n",
    "out_filename = 'char_sequences.txt' \n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3mmZ1E3G6z7"
   },
   "source": [
    "## 1.2. Train Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13957,
     "status": "ok",
     "timestamp": 1634993348612,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "nRzZBodoG4Fe",
    "outputId": "3395bf9e-d980-4412-cfa0-895c19c374f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 38\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 75)                34200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 38)                2888      \n",
      "=================================================================\n",
      "Total params: 37,088\n",
      "Trainable params: 37,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 3.6003 - accuracy: 0.1378\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.4460 - accuracy: 0.1905\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 3.1144 - accuracy: 0.1905\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 3.0363 - accuracy: 0.1930\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.9996 - accuracy: 0.1905\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.9816 - accuracy: 0.1905\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 2.9666 - accuracy: 0.1905\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 2.9443 - accuracy: 0.1905\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 2.9241 - accuracy: 0.1905\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 2.9088 - accuracy: 0.1905\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 2.8772 - accuracy: 0.1930\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 2.8514 - accuracy: 0.2281\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 2.8118 - accuracy: 0.2030\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 2.7757 - accuracy: 0.2381\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 2.7267 - accuracy: 0.2406\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 2.6918 - accuracy: 0.2356\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 2.6493 - accuracy: 0.2356\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 2.6158 - accuracy: 0.2531\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 2.5768 - accuracy: 0.2657\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 2.5446 - accuracy: 0.2657\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 2.4887 - accuracy: 0.2882\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 2.4374 - accuracy: 0.2957\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 2.4137 - accuracy: 0.2907\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 2.3742 - accuracy: 0.2932\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 2.3287 - accuracy: 0.3258\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 2.2914 - accuracy: 0.3208\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 2.2794 - accuracy: 0.3434\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 2.2314 - accuracy: 0.3358\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 2.2056 - accuracy: 0.3709\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 2.1303 - accuracy: 0.3885\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 2.0981 - accuracy: 0.4261\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 2.0700 - accuracy: 0.3709\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 2.0378 - accuracy: 0.4110\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 1.9729 - accuracy: 0.4486\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 1.9506 - accuracy: 0.4185\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 1.9081 - accuracy: 0.4912\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 1.8715 - accuracy: 0.4662\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 1.8361 - accuracy: 0.4987\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 1.7969 - accuracy: 0.4912\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 1.7454 - accuracy: 0.5414\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 1.7107 - accuracy: 0.5764\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 1.6663 - accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 1.6513 - accuracy: 0.5890\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 1.6138 - accuracy: 0.5789\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 1.5564 - accuracy: 0.5940\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 1.5095 - accuracy: 0.6241\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 1.4592 - accuracy: 0.6516\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 1.4226 - accuracy: 0.6516\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 1.3900 - accuracy: 0.6617\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 1.3368 - accuracy: 0.6767\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 1.3179 - accuracy: 0.6717\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 1.2562 - accuracy: 0.7068\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 1.2483 - accuracy: 0.7118\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 1.2334 - accuracy: 0.7018\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 1.1819 - accuracy: 0.7093\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 1.1502 - accuracy: 0.7243\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 1.1151 - accuracy: 0.7368\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 1.0606 - accuracy: 0.7669\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 1.0515 - accuracy: 0.7569\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 1.0050 - accuracy: 0.7769\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.9673 - accuracy: 0.8020\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.9250 - accuracy: 0.8095\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.9034 - accuracy: 0.8195\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.8713 - accuracy: 0.8246\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.8381 - accuracy: 0.8246\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.8205 - accuracy: 0.8246\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.7870 - accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.7671 - accuracy: 0.8546\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.7206 - accuracy: 0.8797\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.6985 - accuracy: 0.8872\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.6879 - accuracy: 0.8872\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.6558 - accuracy: 0.8972\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.6326 - accuracy: 0.8897\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.5956 - accuracy: 0.9123\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.5971 - accuracy: 0.9298\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.5630 - accuracy: 0.9148\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.5465 - accuracy: 0.9323\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.5314 - accuracy: 0.9549\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.5082 - accuracy: 0.9449\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.4876 - accuracy: 0.9499\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.4645 - accuracy: 0.9549\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 0.4502 - accuracy: 0.9649\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 0.4252 - accuracy: 0.9674\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 0.4105 - accuracy: 0.9699\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 0.3978 - accuracy: 0.9749\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 0.3791 - accuracy: 0.9749\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 0.3657 - accuracy: 0.9724\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 0.3548 - accuracy: 0.9850\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 0.3391 - accuracy: 0.9850\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 0.3305 - accuracy: 0.9825\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 0.3158 - accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 0.3162 - accuracy: 0.9825\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 0.3001 - accuracy: 0.9875\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 0.2875 - accuracy: 0.9900\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 0.2754 - accuracy: 0.9850\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 0.2733 - accuracy: 0.9875\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 0.2535 - accuracy: 0.9875\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 0.2438 - accuracy: 0.9875\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 0.2338 - accuracy: 0.9850\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pickle import dump\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# 1.load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only \n",
    "  file = open(filename, 'r')\n",
    "  # read all text\n",
    "  text = file.read()\n",
    "  # close the file \n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "# 2. define the model\n",
    "def define_model(X):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
    "  model.add(Dense(vocab_size, activation='softmax'))\n",
    "  # compile model\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "  # summarize defined model\n",
    "  model.summary()\n",
    "  plot_model(model, to_file='model.png', show_shapes=True)\n",
    "  return model\n",
    "\n",
    "# load\n",
    "in_filename = 'char_sequences.txt'\n",
    "raw_text = load_doc(in_filename)\n",
    "lines = raw_text.split('\\n')\n",
    "\n",
    "# integer encode sequences of characters\n",
    "chars = sorted(list(set(raw_text)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars)) \n",
    "sequences = list()\n",
    "\n",
    "for line in lines:\n",
    "  # integer encode line\n",
    "  encoded_seq = [mapping[char] for char in line]\n",
    "  # store\n",
    "  sequences.append(encoded_seq)\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(mapping)\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "# separate into input and output\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "sequences = [to_categorical(x, num_classes=vocab_size) for x in X] \n",
    "X = np.array(sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# define model\n",
    "model = define_model(X)\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=2)\n",
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the mapping\n",
    "dump(mapping, open('mapping.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634993348613,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "SmHg2b19IByM",
    "outputId": "03a73bfd-fc7d-4157-c1a6-29662d21e1c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_shapes= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBOmDfW6LR7C"
   },
   "source": [
    "## 1.3. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "error",
     "timestamp": 1634993445603,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "8A6cMVMHG4bH",
    "outputId": "119a13b3-9de5-4015-f9d4-ad07eba08c5b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7b9c60ff9207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mapping.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# test start of rhyme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sing a son'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m# test mid-line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'king was i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-7b9c60ff9207>\u001b[0m in \u001b[0;36mgenerate_seq\u001b[0;34m(model, mapping, seq_length, seed_text, n_chars)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# one hot encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# predict character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 380 into shape (1,1,10)"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "  in_text = seed_text\n",
    "  # generate a fixed number of characters\n",
    "  for _ in range(n_chars):\n",
    "    # encode the characters as integers\n",
    "    encoded = [mapping[char] for char in in_text]\n",
    "    # truncate sequences to a fixed length\n",
    "    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre') \n",
    "    # one hot encode\n",
    "    encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "    encoded = encoded.reshape(1, encoded.shape[0], encoded.shape[1])\n",
    "    # predict character\n",
    "    yhat = model.predict_classes(encoded, verbose=0)\n",
    "    # reverse map integer to character\n",
    "    out_char = ''\n",
    "    for char, index in mapping.items():\n",
    "      if index == yhat:\n",
    "       out_char = char\n",
    "       break\n",
    "    # append to input\n",
    "    in_text += out_char\n",
    "  return in_text\n",
    "\n",
    "# load the model\n",
    "model = load_model('model.h5') \n",
    "# load the mapping\n",
    "mapping = load(open('mapping.pkl', 'rb'))\n",
    "# test start of rhyme\n",
    "print(generate_seq(model, mapping, 10, 'Sing a son', 20)) \n",
    "# test mid-line\n",
    "print(generate_seq(model, mapping, 10, 'king was i', 20)) \n",
    "# test not in original\n",
    "print(generate_seq(model, mapping, 10, 'hello worl', 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vss7RffRDCDn"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc1TNTtIDCGQ"
   },
   "source": [
    "# **2. Develop a Word-Based Neural Language model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c3cDPmoDdkt"
   },
   "source": [
    "## 2.1. Model 1: One-Word_in, One-Word-Out Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13696,
     "status": "ok",
     "timestamp": 1635126479107,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "esEb3y6wLyTH",
    "outputId": "6146de2e-bbf4-4512-f6ce-aea2a17036d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n",
      "Total Sequences: 24\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 - 2s - loss: 3.0920 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 3.0912 - accuracy: 0.0417\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 3.0904 - accuracy: 0.2083\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 3.0896 - accuracy: 0.2083\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 3.0888 - accuracy: 0.1250\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 3.0880 - accuracy: 0.1250\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 3.0872 - accuracy: 0.1250\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 3.0864 - accuracy: 0.1250\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 3.0856 - accuracy: 0.1250\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 3.0848 - accuracy: 0.1250\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 3.0840 - accuracy: 0.1250\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 3.0831 - accuracy: 0.1250\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 3.0823 - accuracy: 0.1250\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 3.0815 - accuracy: 0.1250\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 3.0806 - accuracy: 0.1250\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 3.0797 - accuracy: 0.1250\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 3.0789 - accuracy: 0.1250\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 3.0780 - accuracy: 0.1250\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 3.0771 - accuracy: 0.1250\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 3.0761 - accuracy: 0.1250\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 3.0752 - accuracy: 0.1250\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 3.0742 - accuracy: 0.1250\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 3.0732 - accuracy: 0.1250\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 3.0722 - accuracy: 0.1250\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 3.0712 - accuracy: 0.1250\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 3.0701 - accuracy: 0.1250\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 3.0690 - accuracy: 0.1250\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 3.0679 - accuracy: 0.1250\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 3.0667 - accuracy: 0.1250\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 3.0655 - accuracy: 0.1250\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 3.0643 - accuracy: 0.1250\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 3.0631 - accuracy: 0.1250\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 3.0618 - accuracy: 0.1250\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 3.0605 - accuracy: 0.1250\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 3.0591 - accuracy: 0.1250\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 3.0577 - accuracy: 0.1250\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 3.0563 - accuracy: 0.1250\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 3.0548 - accuracy: 0.1250\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 3.0533 - accuracy: 0.1250\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 3.0517 - accuracy: 0.1250\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 3.0501 - accuracy: 0.1250\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 3.0485 - accuracy: 0.1250\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 3.0468 - accuracy: 0.1250\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 3.0450 - accuracy: 0.1250\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 3.0432 - accuracy: 0.1250\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 3.0413 - accuracy: 0.1250\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 3.0394 - accuracy: 0.1250\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 3.0374 - accuracy: 0.1250\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 3.0354 - accuracy: 0.1250\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 3.0333 - accuracy: 0.1250\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 3.0311 - accuracy: 0.1250\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 3.0289 - accuracy: 0.1250\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 3.0266 - accuracy: 0.1250\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 3.0243 - accuracy: 0.1250\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 3.0218 - accuracy: 0.1250\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 3.0193 - accuracy: 0.1250\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 3.0168 - accuracy: 0.1250\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 3.0141 - accuracy: 0.1250\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 3.0114 - accuracy: 0.1250\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 3.0086 - accuracy: 0.1250\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 3.0057 - accuracy: 0.1250\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 3.0027 - accuracy: 0.1250\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 2.9997 - accuracy: 0.1250\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 2.9965 - accuracy: 0.1250\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 2.9933 - accuracy: 0.1250\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 2.9899 - accuracy: 0.1250\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 2.9865 - accuracy: 0.1250\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 2.9830 - accuracy: 0.1250\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 2.9793 - accuracy: 0.1250\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 2.9756 - accuracy: 0.1250\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 2.9717 - accuracy: 0.1250\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 2.9678 - accuracy: 0.1250\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 2.9637 - accuracy: 0.1250\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 2.9595 - accuracy: 0.1250\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 2.9552 - accuracy: 0.1250\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 2.9508 - accuracy: 0.2083\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 2.9463 - accuracy: 0.2083\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 2.9416 - accuracy: 0.2083\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 2.9368 - accuracy: 0.2083\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 2.9319 - accuracy: 0.2083\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 2.9268 - accuracy: 0.2083\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 2.9217 - accuracy: 0.2083\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 2.9163 - accuracy: 0.2083\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 2.9109 - accuracy: 0.2083\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 2.9052 - accuracy: 0.2083\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 2.8995 - accuracy: 0.2083\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 2.8936 - accuracy: 0.2083\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 2.8875 - accuracy: 0.2083\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 2.8813 - accuracy: 0.2083\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 2.8750 - accuracy: 0.2083\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 2.8684 - accuracy: 0.2083\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 2.8618 - accuracy: 0.2083\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 2.8549 - accuracy: 0.2083\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 2.8479 - accuracy: 0.2083\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 2.8407 - accuracy: 0.2083\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 2.8334 - accuracy: 0.2083\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 2.8258 - accuracy: 0.2083\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 2.8182 - accuracy: 0.2083\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 2.8103 - accuracy: 0.2083\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 2.8022 - accuracy: 0.2083\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 2.7940 - accuracy: 0.2083\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 2.7856 - accuracy: 0.2083\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 2.7770 - accuracy: 0.2083\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 2.7683 - accuracy: 0.2083\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 2.7593 - accuracy: 0.2083\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 2.7502 - accuracy: 0.2083\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 2.7409 - accuracy: 0.2083\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 2.7314 - accuracy: 0.2083\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 2.7217 - accuracy: 0.2083\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 2.7119 - accuracy: 0.2083\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 2.7018 - accuracy: 0.2083\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 2.6916 - accuracy: 0.2083\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 2.6812 - accuracy: 0.2083\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 2.6706 - accuracy: 0.2083\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 2.6598 - accuracy: 0.2083\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 2.6488 - accuracy: 0.2083\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 2.6377 - accuracy: 0.2083\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 2.6264 - accuracy: 0.2083\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 2.6149 - accuracy: 0.2083\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 2.6032 - accuracy: 0.2083\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 2.5914 - accuracy: 0.2083\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 2.5794 - accuracy: 0.2083\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 2.5672 - accuracy: 0.2083\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 2.5549 - accuracy: 0.2083\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 2.5425 - accuracy: 0.2083\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 2.5298 - accuracy: 0.2083\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 2.5171 - accuracy: 0.2083\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 2.5042 - accuracy: 0.2083\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 2.4911 - accuracy: 0.2083\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 2.4780 - accuracy: 0.2083\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 2.4647 - accuracy: 0.2083\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 2.4512 - accuracy: 0.2083\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 2.4377 - accuracy: 0.2083\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 2.4240 - accuracy: 0.2083\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 2.4103 - accuracy: 0.2083\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 2.3964 - accuracy: 0.2083\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 2.3825 - accuracy: 0.2083\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 2.3685 - accuracy: 0.2083\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 2.3543 - accuracy: 0.2083\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 2.3401 - accuracy: 0.2083\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 2.3259 - accuracy: 0.2083\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 2.3115 - accuracy: 0.2083\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 2.2971 - accuracy: 0.2083\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 2.2827 - accuracy: 0.2083\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 2.2682 - accuracy: 0.2083\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 2.2536 - accuracy: 0.2083\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 2.2391 - accuracy: 0.2500\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 2.2244 - accuracy: 0.2500\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 2.2098 - accuracy: 0.2917\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 2.1951 - accuracy: 0.3333\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 2.1804 - accuracy: 0.3333\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 2.1656 - accuracy: 0.3333\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 2.1509 - accuracy: 0.3333\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 2.1361 - accuracy: 0.3333\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 2.1214 - accuracy: 0.3333\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 2.1066 - accuracy: 0.3333\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 2.0918 - accuracy: 0.3750\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 2.0770 - accuracy: 0.3750\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 2.0622 - accuracy: 0.4167\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 2.0474 - accuracy: 0.4167\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 2.0326 - accuracy: 0.4167\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 2.0178 - accuracy: 0.4167\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 2.0030 - accuracy: 0.4167\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 1.9882 - accuracy: 0.4167\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 1.9734 - accuracy: 0.4167\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 1.9586 - accuracy: 0.4583\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 1.9438 - accuracy: 0.5417\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 1.9291 - accuracy: 0.5417\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 1.9143 - accuracy: 0.5417\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 1.8996 - accuracy: 0.5417\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 1.8849 - accuracy: 0.5417\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 1.8702 - accuracy: 0.5417\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 1.8555 - accuracy: 0.5833\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 1.8408 - accuracy: 0.5833\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 1.8261 - accuracy: 0.5833\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 1.8115 - accuracy: 0.5833\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 1.7968 - accuracy: 0.6250\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 1.7822 - accuracy: 0.6250\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 1.7676 - accuracy: 0.6250\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 1.7531 - accuracy: 0.6250\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 1.7385 - accuracy: 0.6250\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 1.7240 - accuracy: 0.6250\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 1.7095 - accuracy: 0.6250\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 1.6950 - accuracy: 0.6250\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 1.6805 - accuracy: 0.6250\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 1.6661 - accuracy: 0.6250\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 1.6517 - accuracy: 0.6667\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 1.6374 - accuracy: 0.6667\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 1.6230 - accuracy: 0.7083\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 1.6087 - accuracy: 0.7083\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 1.5945 - accuracy: 0.7083\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 1.5802 - accuracy: 0.7083\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 1.5660 - accuracy: 0.7083\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 1.5519 - accuracy: 0.7500\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 1.5378 - accuracy: 0.7917\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 1.5237 - accuracy: 0.7917\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 1.5097 - accuracy: 0.7917\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 1.4957 - accuracy: 0.8333\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 1.4818 - accuracy: 0.8333\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 1.4679 - accuracy: 0.8333\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 1.4541 - accuracy: 0.8333\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 1.4403 - accuracy: 0.8333\n",
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 1.4266 - accuracy: 0.8333\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 1.4130 - accuracy: 0.8333\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 1.3994 - accuracy: 0.8333\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 1.3859 - accuracy: 0.8333\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 1.3724 - accuracy: 0.8333\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 1.3590 - accuracy: 0.8750\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 1.3457 - accuracy: 0.8750\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 1.3324 - accuracy: 0.8750\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 1.3192 - accuracy: 0.8750\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 1.3061 - accuracy: 0.8750\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 1.2931 - accuracy: 0.8750\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 1.2801 - accuracy: 0.8750\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 1.2673 - accuracy: 0.8750\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 1.2545 - accuracy: 0.8750\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 1.2418 - accuracy: 0.8750\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 1.2292 - accuracy: 0.8750\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 1.2166 - accuracy: 0.8750\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 1.2042 - accuracy: 0.8750\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 1.1919 - accuracy: 0.8750\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 1.1796 - accuracy: 0.8750\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 1.1674 - accuracy: 0.8750\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 1.1554 - accuracy: 0.8750\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 1.1434 - accuracy: 0.8750\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 1.1315 - accuracy: 0.8750\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 1.1198 - accuracy: 0.8750\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 1.1081 - accuracy: 0.8750\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 1.0965 - accuracy: 0.8750\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 1.0851 - accuracy: 0.8750\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 1.0737 - accuracy: 0.8750\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 1.0625 - accuracy: 0.8750\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 1.0513 - accuracy: 0.8750\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 1.0403 - accuracy: 0.8750\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 1.0294 - accuracy: 0.8750\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 1.0185 - accuracy: 0.8750\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 1.0078 - accuracy: 0.8750\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.9972 - accuracy: 0.8750\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.9867 - accuracy: 0.8750\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.9763 - accuracy: 0.8750\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.9660 - accuracy: 0.8750\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.9559 - accuracy: 0.8750\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.9458 - accuracy: 0.8750\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.9359 - accuracy: 0.8750\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.9260 - accuracy: 0.8750\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.9163 - accuracy: 0.8750\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.9067 - accuracy: 0.8750\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.8971 - accuracy: 0.8750\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.8877 - accuracy: 0.8750\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.8784 - accuracy: 0.8750\n",
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.8692 - accuracy: 0.8750\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.8602 - accuracy: 0.8750\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.8512 - accuracy: 0.8750\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.8423 - accuracy: 0.8750\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.8336 - accuracy: 0.8750\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.8249 - accuracy: 0.8750\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.8164 - accuracy: 0.8750\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.8079 - accuracy: 0.8750\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.7996 - accuracy: 0.8750\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.7913 - accuracy: 0.8750\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.7832 - accuracy: 0.8750\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.7752 - accuracy: 0.8750\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.7672 - accuracy: 0.8750\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 0.7594 - accuracy: 0.8750\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 0.7517 - accuracy: 0.8750\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 0.7440 - accuracy: 0.8750\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 0.7365 - accuracy: 0.8750\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 0.7291 - accuracy: 0.8750\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 0.7217 - accuracy: 0.8750\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 0.7145 - accuracy: 0.8750\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 0.7073 - accuracy: 0.8750\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 0.7003 - accuracy: 0.8750\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 0.6933 - accuracy: 0.8750\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 0.6865 - accuracy: 0.8750\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 0.6797 - accuracy: 0.8750\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 0.6730 - accuracy: 0.8750\n",
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 0.6664 - accuracy: 0.8750\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 0.6599 - accuracy: 0.8750\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 0.6535 - accuracy: 0.8750\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 0.6472 - accuracy: 0.8750\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 0.6410 - accuracy: 0.8750\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 0.6349 - accuracy: 0.8750\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 0.6288 - accuracy: 0.8750\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 0.6228 - accuracy: 0.8750\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 0.6169 - accuracy: 0.8750\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 0.6111 - accuracy: 0.8750\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 0.6054 - accuracy: 0.8750\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 0.5998 - accuracy: 0.8750\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 0.5942 - accuracy: 0.8750\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 0.5887 - accuracy: 0.8750\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 0.5833 - accuracy: 0.8750\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 0.5780 - accuracy: 0.8750\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 0.5728 - accuracy: 0.8750\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 0.5676 - accuracy: 0.8750\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 0.5625 - accuracy: 0.8750\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 0.5575 - accuracy: 0.8750\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 0.5526 - accuracy: 0.8750\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 0.5477 - accuracy: 0.8750\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 0.5429 - accuracy: 0.8750\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 0.5382 - accuracy: 0.8750\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 0.5336 - accuracy: 0.8750\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 0.5290 - accuracy: 0.8750\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 0.5245 - accuracy: 0.8750\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 0.5200 - accuracy: 0.8750\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 0.5156 - accuracy: 0.8750\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 0.5113 - accuracy: 0.8750\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 0.5071 - accuracy: 0.8750\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 0.5029 - accuracy: 0.8750\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 0.4988 - accuracy: 0.8750\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 0.4947 - accuracy: 0.8750\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 0.4907 - accuracy: 0.8750\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 0.4868 - accuracy: 0.8750\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 0.4829 - accuracy: 0.8750\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 0.4791 - accuracy: 0.8750\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 0.4754 - accuracy: 0.8750\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 0.4717 - accuracy: 0.8750\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 0.4680 - accuracy: 0.8750\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 0.4644 - accuracy: 0.8750\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 0.4609 - accuracy: 0.8750\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 0.4574 - accuracy: 0.8750\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 0.4540 - accuracy: 0.8750\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 0.4506 - accuracy: 0.8750\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 0.4473 - accuracy: 0.8750\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 0.4441 - accuracy: 0.8750\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 0.4408 - accuracy: 0.8750\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 0.4377 - accuracy: 0.8750\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 0.4345 - accuracy: 0.8750\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 0.4315 - accuracy: 0.8750\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 0.4284 - accuracy: 0.8750\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 0.4255 - accuracy: 0.8750\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 0.4225 - accuracy: 0.8750\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 0.4196 - accuracy: 0.8750\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 0.4168 - accuracy: 0.8750\n",
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 0.4140 - accuracy: 0.8750\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 0.4112 - accuracy: 0.8750\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 0.4085 - accuracy: 0.8750\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 0.4058 - accuracy: 0.8750\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 0.4032 - accuracy: 0.8750\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 0.4006 - accuracy: 0.8750\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 0.3980 - accuracy: 0.8750\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 0.3955 - accuracy: 0.8750\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 0.3930 - accuracy: 0.8750\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 0.3906 - accuracy: 0.8750\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 0.3881 - accuracy: 0.8750\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 0.3858 - accuracy: 0.8750\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 0.3834 - accuracy: 0.8750\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 0.3811 - accuracy: 0.8750\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 0.3788 - accuracy: 0.8750\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 0.3766 - accuracy: 0.8750\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 0.3744 - accuracy: 0.8750\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 0.3722 - accuracy: 0.8750\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 0.3701 - accuracy: 0.8750\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 0.3680 - accuracy: 0.8750\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 0.3659 - accuracy: 0.8750\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 0.3639 - accuracy: 0.8750\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 0.3619 - accuracy: 0.8750\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 0.3599 - accuracy: 0.8750\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 0.3579 - accuracy: 0.8750\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 0.3560 - accuracy: 0.8750\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 0.3541 - accuracy: 0.8750\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 0.3522 - accuracy: 0.8750\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 0.3504 - accuracy: 0.8750\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 0.3485 - accuracy: 0.8750\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 0.3467 - accuracy: 0.8750\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 0.3450 - accuracy: 0.8750\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 0.3432 - accuracy: 0.8750\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 0.3415 - accuracy: 0.8750\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 0.3398 - accuracy: 0.8750\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 0.3382 - accuracy: 0.8750\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 0.3365 - accuracy: 0.8750\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 0.3349 - accuracy: 0.8750\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 0.3333 - accuracy: 0.8750\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 0.3317 - accuracy: 0.8750\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 0.3302 - accuracy: 0.8750\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 0.3287 - accuracy: 0.8750\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 0.3272 - accuracy: 0.8750\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 0.3257 - accuracy: 0.8750\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 0.3242 - accuracy: 0.8750\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 0.3228 - accuracy: 0.8750\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 0.3214 - accuracy: 0.8750\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 0.3199 - accuracy: 0.8750\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 0.3186 - accuracy: 0.8750\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 0.3172 - accuracy: 0.8750\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 0.3159 - accuracy: 0.8750\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 0.3145 - accuracy: 0.8750\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 0.3132 - accuracy: 0.8750\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 0.3120 - accuracy: 0.8750\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 0.3107 - accuracy: 0.8750\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 0.3094 - accuracy: 0.8750\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 0.3082 - accuracy: 0.8750\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 0.3070 - accuracy: 0.8750\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 0.3058 - accuracy: 0.8750\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 0.3046 - accuracy: 0.8750\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 0.3034 - accuracy: 0.8750\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 0.3023 - accuracy: 0.8750\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 0.3012 - accuracy: 0.8750\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 0.3001 - accuracy: 0.8750\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 0.2990 - accuracy: 0.8750\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 0.2979 - accuracy: 0.8750\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 0.2968 - accuracy: 0.8750\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 0.2957 - accuracy: 0.8750\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 0.2947 - accuracy: 0.8750\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 0.2937 - accuracy: 0.8750\n",
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 0.2927 - accuracy: 0.8750\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 0.2917 - accuracy: 0.8750\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 0.2907 - accuracy: 0.8750\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 0.2897 - accuracy: 0.8750\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 0.2888 - accuracy: 0.8750\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 0.2878 - accuracy: 0.8750\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 0.2869 - accuracy: 0.8750\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 0.2860 - accuracy: 0.8750\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 0.2851 - accuracy: 0.8750\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 0.2842 - accuracy: 0.8750\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 0.2833 - accuracy: 0.8750\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 0.2824 - accuracy: 0.8750\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 0.2816 - accuracy: 0.8750\n",
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 0.2807 - accuracy: 0.8750\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 0.2799 - accuracy: 0.8750\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 0.2790 - accuracy: 0.8750\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 0.2782 - accuracy: 0.8750\n",
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 0.2774 - accuracy: 0.8750\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 0.2766 - accuracy: 0.8750\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 0.2759 - accuracy: 0.8750\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 0.2751 - accuracy: 0.8750\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 0.2743 - accuracy: 0.8750\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 0.2736 - accuracy: 0.8750\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 0.2728 - accuracy: 0.8750\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 0.2721 - accuracy: 0.8750\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 0.2714 - accuracy: 0.8750\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 0.2707 - accuracy: 0.8750\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 0.2700 - accuracy: 0.8750\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 0.2693 - accuracy: 0.8750\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 0.2686 - accuracy: 0.8750\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 0.2679 - accuracy: 0.8750\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 0.2673 - accuracy: 0.8750\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 0.2666 - accuracy: 0.8750\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 0.2660 - accuracy: 0.8750\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 0.2653 - accuracy: 0.8750\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 0.2647 - accuracy: 0.8750\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 0.2641 - accuracy: 0.8750\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 0.2634 - accuracy: 0.8750\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 0.2628 - accuracy: 0.8750\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 0.2622 - accuracy: 0.8750\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 0.2616 - accuracy: 0.8750\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 0.2611 - accuracy: 0.8750\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 0.2605 - accuracy: 0.8750\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 0.2599 - accuracy: 0.8750\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 0.2593 - accuracy: 0.8750\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 0.2588 - accuracy: 0.8750\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 0.2582 - accuracy: 0.8750\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 0.2577 - accuracy: 0.8750\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 0.2572 - accuracy: 0.8750\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 0.2566 - accuracy: 0.8750\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 0.2561 - accuracy: 0.8750\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 0.2556 - accuracy: 0.8750\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 0.2551 - accuracy: 0.8750\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 0.2546 - accuracy: 0.8750\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 0.2541 - accuracy: 0.8750\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 0.2536 - accuracy: 0.8750\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 0.2531 - accuracy: 0.8750\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 0.2526 - accuracy: 0.8750\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 0.2522 - accuracy: 0.8750\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 0.2517 - accuracy: 0.8750\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 0.2512 - accuracy: 0.8750\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 0.2508 - accuracy: 0.8750\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 0.2503 - accuracy: 0.8750\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 0.2499 - accuracy: 0.8750\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 0.2494 - accuracy: 0.8750\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 0.2490 - accuracy: 0.8750\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 0.2486 - accuracy: 0.8750\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 0.2481 - accuracy: 0.8750\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 0.2477 - accuracy: 0.8750\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 0.2473 - accuracy: 0.8750\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 0.2469 - accuracy: 0.8750\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 0.2465 - accuracy: 0.8750\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 0.2461 - accuracy: 0.8750\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 0.2457 - accuracy: 0.8750\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 0.2453 - accuracy: 0.8750\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 0.2449 - accuracy: 0.8750\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 0.2445 - accuracy: 0.8750\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 0.2441 - accuracy: 0.8750\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 0.2438 - accuracy: 0.8750\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 0.2434 - accuracy: 0.8750\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 0.2430 - accuracy: 0.8750\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 0.2427 - accuracy: 0.8750\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 0.2423 - accuracy: 0.8750\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 0.2420 - accuracy: 0.8750\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 0.2416 - accuracy: 0.8750\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 0.2413 - accuracy: 0.8750\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 0.2409 - accuracy: 0.8750\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 0.2406 - accuracy: 0.8750\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 0.2402 - accuracy: 0.8750\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 0.2399 - accuracy: 0.8750\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 0.2396 - accuracy: 0.8750\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 0.2393 - accuracy: 0.8750\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 0.2389 - accuracy: 0.8750\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 0.2386 - accuracy: 0.8750\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 0.2383 - accuracy: 0.8750\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 0.2380 - accuracy: 0.8750\n",
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 0.2377 - accuracy: 0.8750\n",
      "Jack and jill went up the hill\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "# generate a sequence from the model\n",
    "\n",
    "def generate_seq(model, tokenizer, seed_text, n_words):\n",
    "  in_text, result = seed_text, seed_text\n",
    "  # generate a fixed number of words\n",
    "  for _ in range(n_words):\n",
    "    # encode the text as integer\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    encoded = np.array(encoded)\n",
    "    # predict a word in the vocabulary\n",
    "    predict_x=model.predict(encoded, verbose=0) \n",
    "    yhat=np.argmax(predict_x,axis=1)\n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == yhat:\n",
    "        out_word = word\n",
    "        break\n",
    "    # append to input\n",
    "    in_text, result = out_word, result + ' ' + out_word\n",
    "  return result\n",
    "\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 10, input_length = 1))\n",
    "  model.add(LSTM(50))\n",
    "  model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "  # compile network\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "  # summarize defined model\n",
    "  model.summary()\n",
    "  plot_model(model, to_file ='model.png', show_shapes = True)\n",
    "  return model\n",
    "\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "    To fetch a pail of water\\n\n",
    "    Jack fell down and broke his crown\\n\n",
    "    And Jill came tumbling after\\n \"\"\"\n",
    "\n",
    "# integer encode text\n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0] \n",
    "\n",
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "# create word -> word sequences\n",
    "sequences = list()\n",
    "for i in range(1, len(encoded)):\n",
    "  sequence = encoded[i-1:i+1]\n",
    "  sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# split into X and y elements\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,0],sequences[:,1]\n",
    "# one hot encode outputs\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(vocab_size)\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate\n",
    "print(generate_seq(model, tokenizer, 'Jack', 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE2bQHDBI0FZ"
   },
   "source": [
    "## 2.2. Model 2: Line-by-Line Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11223,
     "status": "ok",
     "timestamp": 1635127032410,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "dg1nGVQ3InPc",
    "outputId": "43c8bc70-8d24-4b81-837c-89df026c0a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n",
      "Total Sequences: 21\n",
      "Max Sequence Length: 7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 6, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 - 2s - loss: 3.0920 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 3.0904 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 3.0889 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 3.0873 - accuracy: 0.0476\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 3.0856 - accuracy: 0.0476\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 3.0840 - accuracy: 0.0952\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 3.0823 - accuracy: 0.1429\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 3.0806 - accuracy: 0.1429\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 3.0788 - accuracy: 0.1429\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 3.0770 - accuracy: 0.1429\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 3.0751 - accuracy: 0.1429\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 3.0731 - accuracy: 0.1429\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 3.0710 - accuracy: 0.1429\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 3.0688 - accuracy: 0.1429\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 3.0665 - accuracy: 0.1429\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 3.0641 - accuracy: 0.1429\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 3.0615 - accuracy: 0.1429\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 3.0588 - accuracy: 0.1429\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 3.0559 - accuracy: 0.1429\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 3.0528 - accuracy: 0.1429\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 3.0495 - accuracy: 0.1429\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 3.0460 - accuracy: 0.1429\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 3.0422 - accuracy: 0.1429\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 3.0382 - accuracy: 0.1429\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 3.0338 - accuracy: 0.1429\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 3.0292 - accuracy: 0.1429\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 3.0242 - accuracy: 0.1429\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 3.0189 - accuracy: 0.1429\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 3.0131 - accuracy: 0.1429\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 3.0070 - accuracy: 0.1429\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 3.0004 - accuracy: 0.1429\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 2.9934 - accuracy: 0.1429\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 2.9860 - accuracy: 0.1429\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 2.9781 - accuracy: 0.1429\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 2.9698 - accuracy: 0.1429\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 2.9613 - accuracy: 0.1429\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 2.9525 - accuracy: 0.1429\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 2.9437 - accuracy: 0.1429\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 2.9351 - accuracy: 0.1429\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 2.9268 - accuracy: 0.1429\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 2.9191 - accuracy: 0.1429\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 2.9119 - accuracy: 0.1429\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 2.9050 - accuracy: 0.1429\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 2.8982 - accuracy: 0.1429\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 2.8908 - accuracy: 0.1429\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 2.8825 - accuracy: 0.1429\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 2.8734 - accuracy: 0.1429\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 2.8635 - accuracy: 0.1429\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 2.8530 - accuracy: 0.1429\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 2.8423 - accuracy: 0.1429\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 2.8314 - accuracy: 0.1429\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 2.8204 - accuracy: 0.1429\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 2.8091 - accuracy: 0.1429\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 2.7976 - accuracy: 0.1429\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 2.7855 - accuracy: 0.1429\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 2.7728 - accuracy: 0.1429\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 2.7593 - accuracy: 0.1429\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 2.7449 - accuracy: 0.1429\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 2.7296 - accuracy: 0.1429\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 2.7134 - accuracy: 0.1429\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 2.6963 - accuracy: 0.1429\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 2.6785 - accuracy: 0.1429\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 2.6598 - accuracy: 0.1429\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 2.6404 - accuracy: 0.1429\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 2.6202 - accuracy: 0.1429\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 2.5993 - accuracy: 0.1429\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 2.5777 - accuracy: 0.1429\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 2.5552 - accuracy: 0.1429\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 2.5321 - accuracy: 0.1429\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 2.5084 - accuracy: 0.1905\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 2.4842 - accuracy: 0.1905\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 2.4597 - accuracy: 0.1905\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 2.4350 - accuracy: 0.2381\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 2.4102 - accuracy: 0.2381\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 2.3853 - accuracy: 0.2381\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 2.3604 - accuracy: 0.2381\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 2.3354 - accuracy: 0.2381\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 2.3105 - accuracy: 0.2381\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 2.2855 - accuracy: 0.2381\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 2.2604 - accuracy: 0.2381\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 2.2352 - accuracy: 0.2381\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 2.2099 - accuracy: 0.2381\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 2.1844 - accuracy: 0.2381\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 2.1587 - accuracy: 0.2381\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 2.1327 - accuracy: 0.2381\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 2.1064 - accuracy: 0.2381\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 2.0799 - accuracy: 0.2381\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 2.0531 - accuracy: 0.2857\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 2.0261 - accuracy: 0.3333\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 1.9987 - accuracy: 0.3333\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 1.9709 - accuracy: 0.3333\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 1.9427 - accuracy: 0.3333\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 1.9142 - accuracy: 0.3333\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 1.8852 - accuracy: 0.3333\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 1.8557 - accuracy: 0.4286\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 1.8258 - accuracy: 0.4762\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 1.7954 - accuracy: 0.4762\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 1.7647 - accuracy: 0.4762\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 1.7339 - accuracy: 0.5238\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 1.7030 - accuracy: 0.5238\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 1.6723 - accuracy: 0.5238\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 1.6417 - accuracy: 0.5238\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 1.6114 - accuracy: 0.5238\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 1.5815 - accuracy: 0.5714\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 1.5522 - accuracy: 0.6190\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 1.5234 - accuracy: 0.6190\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 1.4952 - accuracy: 0.6190\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 1.4675 - accuracy: 0.6190\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 1.4404 - accuracy: 0.6190\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 1.4137 - accuracy: 0.6190\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 1.3877 - accuracy: 0.6190\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 1.3625 - accuracy: 0.6667\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 1.3379 - accuracy: 0.6667\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 1.3141 - accuracy: 0.6667\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 1.2908 - accuracy: 0.6667\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 1.2682 - accuracy: 0.6667\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 1.2462 - accuracy: 0.6667\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 1.2247 - accuracy: 0.6667\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 1.2038 - accuracy: 0.6667\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 1.1834 - accuracy: 0.6667\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 1.1634 - accuracy: 0.6667\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 1.1439 - accuracy: 0.6667\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 1.1247 - accuracy: 0.6667\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 1.1058 - accuracy: 0.7143\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 1.0873 - accuracy: 0.7143\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 1.0691 - accuracy: 0.7143\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 1.0514 - accuracy: 0.7143\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 1.0348 - accuracy: 0.7143\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 1.0199 - accuracy: 0.7619\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 1.0014 - accuracy: 0.7619\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 0.9849 - accuracy: 0.7619\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.9709 - accuracy: 0.7619\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.9538 - accuracy: 0.7619\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.9398 - accuracy: 0.7619\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 0.9252 - accuracy: 0.7619\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.9098 - accuracy: 0.7619\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 0.8973 - accuracy: 0.7619\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.8826 - accuracy: 0.7619\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 0.8696 - accuracy: 0.7619\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 0.8573 - accuracy: 0.7619\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 0.8438 - accuracy: 0.7619\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 0.8324 - accuracy: 0.7619\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 0.8198 - accuracy: 0.7619\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 0.8082 - accuracy: 0.8095\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 0.7971 - accuracy: 0.8095\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 0.7855 - accuracy: 0.8095\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 0.7751 - accuracy: 0.8095\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 0.7644 - accuracy: 0.8095\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 0.7539 - accuracy: 0.8095\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 0.7443 - accuracy: 0.8095\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 0.7342 - accuracy: 0.8095\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 0.7246 - accuracy: 0.8095\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 0.7156 - accuracy: 0.8095\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 0.7062 - accuracy: 0.8095\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 0.6972 - accuracy: 0.8095\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 0.6887 - accuracy: 0.8095\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 0.6799 - accuracy: 0.8095\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 0.6715 - accuracy: 0.8095\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 0.6635 - accuracy: 0.8095\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 0.6553 - accuracy: 0.8571\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 0.6473 - accuracy: 0.8571\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 0.6398 - accuracy: 0.8571\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 0.6321 - accuracy: 0.8571\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 0.6245 - accuracy: 0.8571\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 0.6173 - accuracy: 0.8571\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 0.6101 - accuracy: 0.8571\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.6029 - accuracy: 0.8571\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.5959 - accuracy: 0.8571\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.5891 - accuracy: 0.9048\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.5824 - accuracy: 0.9048\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.5757 - accuracy: 0.9048\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.5691 - accuracy: 0.9048\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.5628 - accuracy: 0.9048\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.5565 - accuracy: 0.9048\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.5502 - accuracy: 0.9048\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.5440 - accuracy: 0.9048\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 0.5380 - accuracy: 0.9048\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 0.5321 - accuracy: 0.9048\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 0.5263 - accuracy: 0.9048\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 0.5205 - accuracy: 0.9048\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 0.5148 - accuracy: 0.9048\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 0.5092 - accuracy: 0.9048\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 0.5037 - accuracy: 0.9048\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 0.4983 - accuracy: 0.9048\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 0.4929 - accuracy: 0.9048\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 0.4877 - accuracy: 0.9524\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 0.4825 - accuracy: 0.9048\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 0.4773 - accuracy: 0.9524\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 0.4723 - accuracy: 0.9524\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 0.4673 - accuracy: 0.9524\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 0.4623 - accuracy: 0.9524\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 0.4575 - accuracy: 0.9524\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 0.4527 - accuracy: 0.9524\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 0.4480 - accuracy: 0.9524\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 0.4435 - accuracy: 0.9524\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 0.4390 - accuracy: 0.9524\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 0.4347 - accuracy: 0.9524\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 0.4306 - accuracy: 0.9524\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 0.4265 - accuracy: 0.9524\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 0.4225 - accuracy: 0.9524\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 0.4176 - accuracy: 0.9524\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 0.4128 - accuracy: 0.9524\n",
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 0.4085 - accuracy: 0.9524\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 0.4048 - accuracy: 0.9524\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 0.4012 - accuracy: 0.9524\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 0.3970 - accuracy: 0.9524\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 0.3927 - accuracy: 0.9524\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 0.3887 - accuracy: 0.9524\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 0.3852 - accuracy: 0.9524\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 0.3817 - accuracy: 0.9524\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 0.3777 - accuracy: 0.9524\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 0.3739 - accuracy: 0.9524\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 0.3703 - accuracy: 0.9524\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 0.3670 - accuracy: 0.9524\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 0.3635 - accuracy: 0.9524\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 0.3599 - accuracy: 0.9524\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 0.3564 - accuracy: 0.9524\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 0.3531 - accuracy: 0.9524\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 0.3499 - accuracy: 0.9524\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 0.3466 - accuracy: 0.9524\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 0.3432 - accuracy: 0.9524\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 0.3400 - accuracy: 0.9524\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 0.3368 - accuracy: 0.9524\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 0.3338 - accuracy: 0.9524\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 0.3307 - accuracy: 0.9524\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 0.3276 - accuracy: 0.9524\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 0.3245 - accuracy: 0.9524\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 0.3216 - accuracy: 0.9524\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 0.3187 - accuracy: 0.9524\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 0.3158 - accuracy: 0.9524\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 0.3129 - accuracy: 0.9524\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 0.3100 - accuracy: 0.9524\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 0.3072 - accuracy: 0.9524\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 0.3044 - accuracy: 0.9524\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 0.3017 - accuracy: 0.9524\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 0.2990 - accuracy: 0.9524\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 0.2963 - accuracy: 0.9524\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.2936 - accuracy: 0.9524\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.2910 - accuracy: 0.9524\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.2884 - accuracy: 0.9524\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.2859 - accuracy: 0.9524\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.2834 - accuracy: 0.9524\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.2809 - accuracy: 0.9524\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.2784 - accuracy: 0.9524\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.2760 - accuracy: 0.9524\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.2735 - accuracy: 0.9524\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.2712 - accuracy: 0.9524\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.2688 - accuracy: 0.9524\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.2665 - accuracy: 0.9524\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.2642 - accuracy: 0.9524\n",
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.2619 - accuracy: 0.9524\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.2597 - accuracy: 0.9524\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.2575 - accuracy: 0.9524\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.2553 - accuracy: 0.9524\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.2531 - accuracy: 0.9524\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.2510 - accuracy: 0.9524\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.2489 - accuracy: 0.9524\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.2468 - accuracy: 0.9524\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.2448 - accuracy: 0.9524\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.2427 - accuracy: 0.9524\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.2407 - accuracy: 0.9524\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.2387 - accuracy: 0.9524\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.2368 - accuracy: 0.9524\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 0.2348 - accuracy: 0.9524\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 0.2329 - accuracy: 0.9524\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 0.2310 - accuracy: 0.9524\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 0.2292 - accuracy: 0.9524\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 0.2273 - accuracy: 0.9524\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 0.2255 - accuracy: 0.9524\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 0.2238 - accuracy: 0.9524\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 0.2220 - accuracy: 0.9524\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 0.2203 - accuracy: 0.9524\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 0.2186 - accuracy: 0.9524\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 0.2169 - accuracy: 0.9524\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 0.2153 - accuracy: 0.9524\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 0.2138 - accuracy: 0.9524\n",
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 0.2123 - accuracy: 0.9524\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 0.2108 - accuracy: 0.9524\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 0.2093 - accuracy: 0.9524\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 0.2076 - accuracy: 0.9524\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 0.2059 - accuracy: 0.9524\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 0.2041 - accuracy: 0.9524\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 0.2025 - accuracy: 0.9524\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 0.2010 - accuracy: 0.9524\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 0.1997 - accuracy: 0.9524\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 0.1984 - accuracy: 0.9524\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 0.1969 - accuracy: 0.9524\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 0.1953 - accuracy: 0.9524\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 0.1939 - accuracy: 0.9524\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 0.1925 - accuracy: 0.9524\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 0.1912 - accuracy: 0.9524\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 0.1899 - accuracy: 0.9524\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 0.1886 - accuracy: 0.9524\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 0.1872 - accuracy: 0.9524\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 0.1859 - accuracy: 0.9524\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 0.1847 - accuracy: 0.9524\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 0.1835 - accuracy: 0.9524\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 0.1822 - accuracy: 0.9524\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 0.1810 - accuracy: 0.9524\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 0.1798 - accuracy: 0.9524\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 0.1786 - accuracy: 0.9524\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 0.1774 - accuracy: 0.9524\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 0.1763 - accuracy: 0.9524\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 0.1752 - accuracy: 0.9524\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 0.1740 - accuracy: 0.9524\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 0.1729 - accuracy: 0.9524\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 0.1719 - accuracy: 0.9524\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 0.1708 - accuracy: 0.9524\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 0.1697 - accuracy: 0.9524\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 0.1687 - accuracy: 0.9524\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 0.1676 - accuracy: 0.9524\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 0.1666 - accuracy: 0.9524\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 0.1656 - accuracy: 0.9524\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 0.1647 - accuracy: 0.9524\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 0.1637 - accuracy: 0.9524\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 0.1627 - accuracy: 0.9524\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 0.1618 - accuracy: 0.9524\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 0.1608 - accuracy: 0.9524\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 0.1599 - accuracy: 0.9524\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 0.1590 - accuracy: 0.9524\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 0.1581 - accuracy: 0.9524\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 0.1572 - accuracy: 0.9524\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 0.1564 - accuracy: 0.9524\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 0.1555 - accuracy: 0.9524\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 0.1547 - accuracy: 0.9524\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 0.1538 - accuracy: 0.9524\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 0.1530 - accuracy: 0.9524\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 0.1522 - accuracy: 0.9524\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 0.1514 - accuracy: 0.9524\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 0.1506 - accuracy: 0.9524\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 0.1498 - accuracy: 0.9524\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 0.1490 - accuracy: 0.9524\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 0.1483 - accuracy: 0.9524\n",
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 0.1475 - accuracy: 0.9524\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 0.1468 - accuracy: 0.9524\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 0.1460 - accuracy: 0.9524\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 0.1453 - accuracy: 0.9524\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 0.1446 - accuracy: 0.9524\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 0.1439 - accuracy: 0.9524\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 0.1432 - accuracy: 0.9524\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 0.1425 - accuracy: 0.9524\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 0.1418 - accuracy: 0.9524\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 0.1412 - accuracy: 0.9524\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 0.1405 - accuracy: 0.9524\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 0.1399 - accuracy: 0.9524\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 0.1392 - accuracy: 0.9524\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 0.1386 - accuracy: 0.9524\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 0.1380 - accuracy: 0.9524\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 0.1373 - accuracy: 0.9524\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 0.1367 - accuracy: 0.9524\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 0.1361 - accuracy: 0.9524\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 0.1355 - accuracy: 0.9524\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 0.1350 - accuracy: 0.9524\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 0.1344 - accuracy: 0.9524\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 0.1338 - accuracy: 0.9524\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 0.1332 - accuracy: 0.9524\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 0.1327 - accuracy: 0.9524\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 0.1321 - accuracy: 0.9524\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 0.1316 - accuracy: 0.9524\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 0.1310 - accuracy: 0.9524\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 0.1305 - accuracy: 0.9524\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 0.1300 - accuracy: 0.9524\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 0.1295 - accuracy: 0.9524\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 0.1290 - accuracy: 0.9524\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 0.1285 - accuracy: 0.9524\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 0.1280 - accuracy: 0.9524\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 0.1275 - accuracy: 0.9524\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 0.1270 - accuracy: 0.9524\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 0.1265 - accuracy: 0.9524\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 0.1260 - accuracy: 0.9524\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 0.1255 - accuracy: 0.9524\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 0.1251 - accuracy: 0.9524\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 0.1246 - accuracy: 0.9524\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 0.1242 - accuracy: 0.9524\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 0.1237 - accuracy: 0.9524\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 0.1233 - accuracy: 0.9524\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 0.1228 - accuracy: 0.9524\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 0.1224 - accuracy: 0.9524\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 0.1220 - accuracy: 0.9524\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 0.1215 - accuracy: 0.9524\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 0.1211 - accuracy: 0.9524\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 0.1207 - accuracy: 0.9524\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 0.1203 - accuracy: 0.9524\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 0.1199 - accuracy: 0.9524\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 0.1195 - accuracy: 0.9524\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 0.1191 - accuracy: 0.9524\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 0.1187 - accuracy: 0.9524\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 0.1183 - accuracy: 0.9524\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 0.1179 - accuracy: 0.9524\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 0.1176 - accuracy: 0.9524\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 0.1172 - accuracy: 0.9524\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 0.1168 - accuracy: 0.9524\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 0.1165 - accuracy: 0.9524\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 0.1161 - accuracy: 0.9524\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 0.1157 - accuracy: 0.9524\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 0.1154 - accuracy: 0.9524\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 0.1150 - accuracy: 0.9524\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 0.1147 - accuracy: 0.9524\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 0.1143 - accuracy: 0.9524\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 0.1140 - accuracy: 0.9524\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 0.1137 - accuracy: 0.9524\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 0.1133 - accuracy: 0.9524\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 0.1130 - accuracy: 0.9524\n",
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 0.1127 - accuracy: 0.9524\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 0.1124 - accuracy: 0.9524\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 0.1120 - accuracy: 0.9524\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 0.1117 - accuracy: 0.9524\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 0.1114 - accuracy: 0.9524\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 0.1111 - accuracy: 0.9524\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 0.1108 - accuracy: 0.9524\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 0.1105 - accuracy: 0.9524\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 0.1102 - accuracy: 0.9524\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 0.1099 - accuracy: 0.9524\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 0.1096 - accuracy: 0.9524\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 0.1093 - accuracy: 0.9524\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 0.1090 - accuracy: 0.9524\n",
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 0.1088 - accuracy: 0.9524\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 0.1085 - accuracy: 0.9524\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 0.1082 - accuracy: 0.9524\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 0.1079 - accuracy: 0.9524\n",
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 0.1077 - accuracy: 0.9524\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 0.1074 - accuracy: 0.9524\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 0.1071 - accuracy: 0.9524\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 0.1069 - accuracy: 0.9524\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 0.1066 - accuracy: 0.9524\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 0.1063 - accuracy: 0.9524\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 0.1061 - accuracy: 0.9524\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 0.1058 - accuracy: 0.9524\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 0.1056 - accuracy: 0.9524\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 0.1053 - accuracy: 0.9524\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 0.1051 - accuracy: 0.9524\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 0.1049 - accuracy: 0.9524\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 0.1046 - accuracy: 0.9524\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 0.1044 - accuracy: 0.9524\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 0.1041 - accuracy: 0.9524\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 0.1039 - accuracy: 0.9524\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 0.1037 - accuracy: 0.9524\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 0.1035 - accuracy: 0.9524\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 0.1032 - accuracy: 0.9524\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 0.1030 - accuracy: 0.9524\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 0.1028 - accuracy: 0.9524\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 0.1026 - accuracy: 0.9524\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 0.1023 - accuracy: 0.9524\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 0.1021 - accuracy: 0.9524\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 0.1019 - accuracy: 0.9524\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 0.1017 - accuracy: 0.9524\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 0.1015 - accuracy: 0.9524\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 0.1013 - accuracy: 0.9524\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 0.1011 - accuracy: 0.9524\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 0.1009 - accuracy: 0.9524\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 0.1007 - accuracy: 0.9524\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 0.1005 - accuracy: 0.9524\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 0.1003 - accuracy: 0.9524\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 0.1001 - accuracy: 0.9524\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 0.0999 - accuracy: 0.9524\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 0.0997 - accuracy: 0.9524\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 0.0995 - accuracy: 0.9524\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 0.0993 - accuracy: 0.9524\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 0.0991 - accuracy: 0.9524\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 0.0990 - accuracy: 0.9524\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 0.0988 - accuracy: 0.9524\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 0.0986 - accuracy: 0.9524\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 0.0984 - accuracy: 0.9524\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 0.0982 - accuracy: 0.9524\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 0.0981 - accuracy: 0.9524\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 0.0979 - accuracy: 0.9524\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 0.0977 - accuracy: 0.9524\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 0.0975 - accuracy: 0.9524\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 0.0974 - accuracy: 0.9524\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 0.0972 - accuracy: 0.9524\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 0.0970 - accuracy: 0.9524\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 0.0969 - accuracy: 0.9524\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 0.0967 - accuracy: 0.9524\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 0.0965 - accuracy: 0.9524\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 0.0964 - accuracy: 0.9524\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 0.0962 - accuracy: 0.9524\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 0.0961 - accuracy: 0.9524\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 0.0959 - accuracy: 0.9524\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 0.0957 - accuracy: 0.9524\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 0.0956 - accuracy: 0.9524\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 0.0954 - accuracy: 0.9524\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 0.0953 - accuracy: 0.9524\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 0.0951 - accuracy: 0.9524\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 0.0950 - accuracy: 0.9524\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 0.0948 - accuracy: 0.9524\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 0.0947 - accuracy: 0.9524\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 0.0945 - accuracy: 0.9524\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 0.0944 - accuracy: 0.9524\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 0.0942 - accuracy: 0.9524\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 0.0941 - accuracy: 0.9524\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 0.0940 - accuracy: 0.9524\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 0.0938 - accuracy: 0.9524\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 0.0937 - accuracy: 0.9524\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 0.0935 - accuracy: 0.9524\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 0.0934 - accuracy: 0.9524\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 0.0933 - accuracy: 0.9524\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 0.0931 - accuracy: 0.9524\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 0.0930 - accuracy: 0.9524\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 0.0929 - accuracy: 0.9524\n",
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 0.0927 - accuracy: 0.9524\n",
      "Jack fell down and broke\n",
      "Jill jill came tumbling after\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "# generate a sequence from the model\n",
    "\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "  in_text = seed_text\n",
    "  # generate a fixed number of words\n",
    "  for _ in range(n_words):\n",
    "    # encode the text as integer\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    # pre-pad sequences to a fixed length\n",
    "    encoded = pad_sequences([encoded], maxlen = max_length, padding = 'pre')\n",
    "    # predict a word in the vocabulary\n",
    "    predict_x=model.predict(encoded, verbose=0) \n",
    "    yhat=np.argmax(predict_x,axis=1)\n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == yhat:\n",
    "        out_word = word\n",
    "        break\n",
    "    # append to input\n",
    "    in_text +=  ' ' + out_word\n",
    "  return in_text\n",
    "\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 10, input_length = max_length-1))\n",
    "  model.add(LSTM(50))\n",
    "  model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "  # compile network\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "  # summarize defined model\n",
    "  model.summary()\n",
    "  plot_model(model, to_file ='model.png', show_shapes = True)\n",
    "  return model\n",
    "\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "    To fetch a pail of water\\n\n",
    "    Jack fell down and broke his crown\\n\n",
    "    And Jill came tumbling after\\n \"\"\"\n",
    "\n",
    "# prepare the tokenizer on the source text \n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts([data])\n",
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "# create line-based sequences\n",
    "sequences = list()\n",
    "for line in data.split('\\n'):\n",
    "  encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "  for i in range(1, len(encoded)):\n",
    "    sequence = encoded[:i+1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "# pad input sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre') \n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(vocab_size, max_length)\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack', 4)) \n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCgS9HUFK2kt"
   },
   "source": [
    "## 2.3. Model 3: Two-Words-In, One-Word-Out Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10304,
     "status": "ok",
     "timestamp": 1635127531133,
     "user": {
      "displayName": "Tiểu Long Phan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06195310281051173481"
     },
     "user_tz": -420
    },
    "id": "rhQnjhhEHD53",
    "outputId": "aecc393d-d60e-4a1f-f1d0-9f525277e0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n",
      "Total Sequences: 23\n",
      "Max Sequence Length: 3\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 2, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 - 2s - loss: 3.0914 - accuracy: 0.0870\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 3.0905 - accuracy: 0.1739\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 3.0897 - accuracy: 0.1304\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 3.0888 - accuracy: 0.0870\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 3.0879 - accuracy: 0.0870\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 3.0871 - accuracy: 0.0870\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 3.0862 - accuracy: 0.0870\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 3.0853 - accuracy: 0.0870\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 3.0844 - accuracy: 0.0870\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 3.0835 - accuracy: 0.0870\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 3.0826 - accuracy: 0.0870\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 3.0816 - accuracy: 0.0870\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 3.0807 - accuracy: 0.0870\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 3.0797 - accuracy: 0.0870\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 3.0787 - accuracy: 0.0870\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 3.0776 - accuracy: 0.0870\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 3.0765 - accuracy: 0.0870\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 3.0754 - accuracy: 0.0870\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 3.0743 - accuracy: 0.0870\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 3.0731 - accuracy: 0.0870\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 3.0719 - accuracy: 0.0870\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 3.0706 - accuracy: 0.0870\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 3.0693 - accuracy: 0.0870\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 3.0679 - accuracy: 0.0870\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 3.0665 - accuracy: 0.0870\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 3.0651 - accuracy: 0.0870\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 3.0636 - accuracy: 0.0870\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 3.0620 - accuracy: 0.0870\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 3.0604 - accuracy: 0.0870\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 3.0587 - accuracy: 0.0870\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 3.0569 - accuracy: 0.0870\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 3.0551 - accuracy: 0.0870\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 3.0532 - accuracy: 0.0870\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 3.0512 - accuracy: 0.0870\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 3.0491 - accuracy: 0.0870\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 3.0470 - accuracy: 0.0870\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 3.0448 - accuracy: 0.0870\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 3.0425 - accuracy: 0.0870\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 3.0400 - accuracy: 0.0870\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 3.0375 - accuracy: 0.0870\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 3.0349 - accuracy: 0.0870\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 3.0322 - accuracy: 0.0870\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 3.0293 - accuracy: 0.0870\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 3.0263 - accuracy: 0.0870\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 3.0232 - accuracy: 0.0870\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 3.0200 - accuracy: 0.0870\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 3.0167 - accuracy: 0.0870\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 3.0132 - accuracy: 0.1304\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 3.0095 - accuracy: 0.1304\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 3.0057 - accuracy: 0.1304\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 3.0017 - accuracy: 0.1304\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 2.9976 - accuracy: 0.1304\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 2.9933 - accuracy: 0.1304\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 2.9888 - accuracy: 0.1304\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 2.9841 - accuracy: 0.1304\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 2.9792 - accuracy: 0.1304\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 2.9741 - accuracy: 0.1304\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 2.9688 - accuracy: 0.1304\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 2.9633 - accuracy: 0.1304\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 2.9575 - accuracy: 0.1304\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 2.9515 - accuracy: 0.1304\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 2.9453 - accuracy: 0.1304\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 2.9388 - accuracy: 0.1304\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 2.9320 - accuracy: 0.1304\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 2.9250 - accuracy: 0.1304\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 2.9176 - accuracy: 0.1304\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 2.9100 - accuracy: 0.1304\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 2.9021 - accuracy: 0.1304\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 2.8939 - accuracy: 0.1304\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 2.8853 - accuracy: 0.1304\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 2.8764 - accuracy: 0.1304\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 2.8672 - accuracy: 0.1304\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 2.8577 - accuracy: 0.1304\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 2.8478 - accuracy: 0.1304\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 2.8375 - accuracy: 0.1304\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 2.8269 - accuracy: 0.1304\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 2.8159 - accuracy: 0.1304\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 2.8045 - accuracy: 0.1304\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 2.7928 - accuracy: 0.1304\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 2.7807 - accuracy: 0.1304\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 2.7681 - accuracy: 0.1304\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 2.7552 - accuracy: 0.1739\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 2.7419 - accuracy: 0.2174\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 2.7282 - accuracy: 0.2174\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 2.7141 - accuracy: 0.2174\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 2.6996 - accuracy: 0.2174\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 2.6847 - accuracy: 0.2174\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 2.6694 - accuracy: 0.2174\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 2.6537 - accuracy: 0.2174\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 2.6376 - accuracy: 0.2174\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 2.6211 - accuracy: 0.2174\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 2.6042 - accuracy: 0.2174\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 2.5870 - accuracy: 0.2174\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 2.5693 - accuracy: 0.2174\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 2.5513 - accuracy: 0.2174\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 2.5330 - accuracy: 0.2609\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 2.5143 - accuracy: 0.3043\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 2.4952 - accuracy: 0.3478\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 2.4758 - accuracy: 0.3478\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 2.4561 - accuracy: 0.3478\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 2.4361 - accuracy: 0.3478\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 2.4159 - accuracy: 0.3478\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 2.3953 - accuracy: 0.3478\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 2.3745 - accuracy: 0.3478\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 2.3534 - accuracy: 0.3478\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 2.3321 - accuracy: 0.3478\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 2.3105 - accuracy: 0.3478\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 2.2888 - accuracy: 0.3478\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 2.2669 - accuracy: 0.3478\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 2.2448 - accuracy: 0.3478\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 2.2226 - accuracy: 0.3913\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 2.2002 - accuracy: 0.4348\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 2.1776 - accuracy: 0.4348\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 2.1550 - accuracy: 0.4348\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 2.1322 - accuracy: 0.4783\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 2.1093 - accuracy: 0.4783\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 2.0864 - accuracy: 0.4783\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 2.0633 - accuracy: 0.5217\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 2.0402 - accuracy: 0.5217\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 2.0171 - accuracy: 0.5217\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 1.9938 - accuracy: 0.4783\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 1.9706 - accuracy: 0.4783\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 1.9473 - accuracy: 0.4783\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 1.9240 - accuracy: 0.4783\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 1.9007 - accuracy: 0.4783\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 1.8774 - accuracy: 0.4783\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 1.8541 - accuracy: 0.5217\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 1.8309 - accuracy: 0.5217\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 1.8077 - accuracy: 0.5217\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 1.7845 - accuracy: 0.5217\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 1.7614 - accuracy: 0.5217\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 1.7383 - accuracy: 0.5217\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 1.7153 - accuracy: 0.5217\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 1.6924 - accuracy: 0.5652\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 1.6696 - accuracy: 0.5652\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 1.6468 - accuracy: 0.5652\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 1.6242 - accuracy: 0.6522\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 1.6017 - accuracy: 0.6522\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 1.5793 - accuracy: 0.6522\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 1.5570 - accuracy: 0.6522\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 1.5348 - accuracy: 0.7391\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 1.5127 - accuracy: 0.7391\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 1.4907 - accuracy: 0.7391\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 1.4689 - accuracy: 0.7391\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 1.4471 - accuracy: 0.7391\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 1.4255 - accuracy: 0.7391\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 1.4040 - accuracy: 0.7391\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 1.3826 - accuracy: 0.7391\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 1.3612 - accuracy: 0.7391\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 1.3400 - accuracy: 0.7391\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 1.3189 - accuracy: 0.7391\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 1.2979 - accuracy: 0.7826\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 1.2769 - accuracy: 0.7826\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 1.2561 - accuracy: 0.7826\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 1.2354 - accuracy: 0.7826\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 1.2147 - accuracy: 0.7826\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 1.1942 - accuracy: 0.7826\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 1.1737 - accuracy: 0.8696\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 1.1534 - accuracy: 0.9130\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 1.1332 - accuracy: 0.9130\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 1.1130 - accuracy: 0.9130\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 1.0930 - accuracy: 0.9130\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 1.0732 - accuracy: 0.9130\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 1.0534 - accuracy: 0.9130\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 1.0338 - accuracy: 0.9130\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 1.0143 - accuracy: 0.9130\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.9950 - accuracy: 0.9130\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.9758 - accuracy: 0.9130\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.9568 - accuracy: 0.9130\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.9380 - accuracy: 0.9130\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.9194 - accuracy: 0.9130\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.9010 - accuracy: 0.9130\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.8828 - accuracy: 0.9130\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.8648 - accuracy: 0.9130\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.8470 - accuracy: 0.9130\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.8295 - accuracy: 0.9130\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 0.8122 - accuracy: 0.9130\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 0.7952 - accuracy: 0.9130\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 0.7784 - accuracy: 0.9130\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 0.7619 - accuracy: 0.9130\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 0.7457 - accuracy: 0.9130\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 0.7298 - accuracy: 0.9130\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 0.7142 - accuracy: 0.9130\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 0.6988 - accuracy: 0.9130\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 0.6838 - accuracy: 0.9130\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 0.6691 - accuracy: 0.9130\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 0.6546 - accuracy: 0.9130\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 0.6405 - accuracy: 0.9130\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 0.6267 - accuracy: 0.9130\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 0.6132 - accuracy: 0.9565\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 0.6001 - accuracy: 0.9565\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 0.5872 - accuracy: 0.9565\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 0.5746 - accuracy: 0.9565\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 0.5624 - accuracy: 0.9565\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 0.5504 - accuracy: 0.9565\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 0.5387 - accuracy: 0.9565\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 0.5274 - accuracy: 0.9565\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 0.5163 - accuracy: 0.9565\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 0.5055 - accuracy: 0.9565\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 0.4950 - accuracy: 0.9565\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 0.4847 - accuracy: 0.9565\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 0.4747 - accuracy: 0.9565\n",
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 0.4650 - accuracy: 0.9565\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 0.4556 - accuracy: 0.9565\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 0.4464 - accuracy: 0.9565\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 0.4374 - accuracy: 0.9565\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 0.4287 - accuracy: 0.9565\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 0.4202 - accuracy: 0.9565\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 0.4120 - accuracy: 0.9565\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 0.4040 - accuracy: 0.9565\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 0.3962 - accuracy: 0.9565\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 0.3886 - accuracy: 0.9565\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 0.3812 - accuracy: 0.9565\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 0.3741 - accuracy: 0.9565\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 0.3671 - accuracy: 0.9565\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 0.3603 - accuracy: 0.9565\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 0.3537 - accuracy: 0.9565\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 0.3472 - accuracy: 0.9565\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 0.3410 - accuracy: 0.9565\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 0.3349 - accuracy: 0.9565\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 0.3289 - accuracy: 0.9565\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 0.3231 - accuracy: 0.9565\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 0.3175 - accuracy: 0.9565\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 0.3120 - accuracy: 0.9565\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 0.3067 - accuracy: 0.9565\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 0.3015 - accuracy: 0.9565\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 0.2964 - accuracy: 0.9565\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 0.2915 - accuracy: 0.9565\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 0.2866 - accuracy: 0.9565\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 0.2819 - accuracy: 0.9565\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 0.2773 - accuracy: 0.9565\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 0.2729 - accuracy: 0.9565\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 0.2685 - accuracy: 0.9565\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 0.2642 - accuracy: 0.9565\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 0.2601 - accuracy: 0.9565\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 0.2560 - accuracy: 0.9565\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 0.2521 - accuracy: 0.9565\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.2482 - accuracy: 0.9565\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.2444 - accuracy: 0.9565\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.2407 - accuracy: 0.9565\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.2371 - accuracy: 0.9565\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.2336 - accuracy: 0.9565\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.2301 - accuracy: 0.9565\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.2268 - accuracy: 0.9565\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.2235 - accuracy: 0.9565\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.2203 - accuracy: 0.9565\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.2172 - accuracy: 0.9565\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.2141 - accuracy: 0.9565\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.2111 - accuracy: 0.9565\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.2082 - accuracy: 0.9565\n",
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.2053 - accuracy: 0.9565\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.2025 - accuracy: 0.9565\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.1998 - accuracy: 0.9565\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.1972 - accuracy: 0.9565\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.1946 - accuracy: 0.9565\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.1920 - accuracy: 0.9565\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.1895 - accuracy: 0.9565\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.1871 - accuracy: 0.9565\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.1848 - accuracy: 0.9565\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.1824 - accuracy: 0.9565\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.1802 - accuracy: 0.9565\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.1780 - accuracy: 0.9565\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.1758 - accuracy: 0.9565\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 0.1737 - accuracy: 0.9565\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 0.1717 - accuracy: 0.9565\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 0.1697 - accuracy: 0.9565\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 0.1678 - accuracy: 0.9565\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 0.1658 - accuracy: 0.9565\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 0.1640 - accuracy: 0.9565\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 0.1622 - accuracy: 0.9565\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 0.1604 - accuracy: 0.9565\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 0.1587 - accuracy: 0.9565\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 0.1570 - accuracy: 0.9565\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 0.1553 - accuracy: 0.9565\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 0.1537 - accuracy: 0.9565\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 0.1521 - accuracy: 0.9565\n",
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 0.1506 - accuracy: 0.9565\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 0.1491 - accuracy: 0.9565\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 0.1477 - accuracy: 0.9565\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 0.1462 - accuracy: 0.9565\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 0.1448 - accuracy: 0.9565\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 0.1435 - accuracy: 0.9565\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 0.1421 - accuracy: 0.9565\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 0.1408 - accuracy: 0.9565\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 0.1396 - accuracy: 0.9565\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 0.1383 - accuracy: 0.9565\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 0.1371 - accuracy: 0.9565\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 0.1359 - accuracy: 0.9565\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 0.1348 - accuracy: 0.9565\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 0.1336 - accuracy: 0.9565\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 0.1325 - accuracy: 0.9565\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 0.1314 - accuracy: 0.9565\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 0.1304 - accuracy: 0.9565\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 0.1294 - accuracy: 0.9565\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 0.1283 - accuracy: 0.9565\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 0.1274 - accuracy: 0.9565\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 0.1264 - accuracy: 0.9565\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 0.1254 - accuracy: 0.9565\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 0.1245 - accuracy: 0.9565\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 0.1236 - accuracy: 0.9565\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 0.1227 - accuracy: 0.9565\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 0.1219 - accuracy: 0.9565\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 0.1210 - accuracy: 0.9565\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 0.1202 - accuracy: 0.9565\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 0.1194 - accuracy: 0.9565\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 0.1186 - accuracy: 0.9565\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 0.1178 - accuracy: 0.9565\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 0.1170 - accuracy: 0.9565\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 0.1163 - accuracy: 0.9565\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 0.1155 - accuracy: 0.9565\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 0.1148 - accuracy: 0.9565\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 0.1141 - accuracy: 0.9565\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 0.1134 - accuracy: 0.9565\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 0.1127 - accuracy: 0.9565\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 0.1121 - accuracy: 0.9565\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 0.1114 - accuracy: 0.9565\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 0.1108 - accuracy: 0.9565\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 0.1102 - accuracy: 0.9565\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 0.1095 - accuracy: 0.9565\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 0.1089 - accuracy: 0.9565\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 0.1084 - accuracy: 0.9565\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 0.1078 - accuracy: 0.9565\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 0.1072 - accuracy: 0.9565\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 0.1066 - accuracy: 0.9565\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 0.1061 - accuracy: 0.9565\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 0.1056 - accuracy: 0.9565\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 0.1050 - accuracy: 0.9565\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 0.1045 - accuracy: 0.9565\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 0.1040 - accuracy: 0.9565\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 0.1035 - accuracy: 0.9565\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 0.1030 - accuracy: 0.9565\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 0.1025 - accuracy: 0.9565\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 0.1021 - accuracy: 0.9565\n",
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 0.1016 - accuracy: 0.9565\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 0.1011 - accuracy: 0.9565\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 0.1007 - accuracy: 0.9565\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 0.1002 - accuracy: 0.9565\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 0.0998 - accuracy: 0.9565\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 0.0994 - accuracy: 0.9565\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 0.0990 - accuracy: 0.9565\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 0.0986 - accuracy: 0.9565\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 0.0981 - accuracy: 0.9565\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 0.0977 - accuracy: 0.9565\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 0.0974 - accuracy: 0.9565\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 0.0970 - accuracy: 0.9565\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 0.0966 - accuracy: 0.9565\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 0.0962 - accuracy: 0.9565\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 0.0958 - accuracy: 0.9565\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 0.0955 - accuracy: 0.9565\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 0.0951 - accuracy: 0.9565\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 0.0948 - accuracy: 0.9565\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 0.0944 - accuracy: 0.9565\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 0.0941 - accuracy: 0.9565\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 0.0938 - accuracy: 0.9565\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 0.0934 - accuracy: 0.9565\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 0.0931 - accuracy: 0.9565\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 0.0928 - accuracy: 0.9565\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 0.0925 - accuracy: 0.9565\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 0.0922 - accuracy: 0.9565\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 0.0919 - accuracy: 0.9565\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 0.0916 - accuracy: 0.9565\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 0.0913 - accuracy: 0.9565\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 0.0910 - accuracy: 0.9565\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 0.0907 - accuracy: 0.9565\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 0.0904 - accuracy: 0.9565\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 0.0901 - accuracy: 0.9565\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 0.0899 - accuracy: 0.9565\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 0.0896 - accuracy: 0.9565\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 0.0893 - accuracy: 0.9565\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 0.0891 - accuracy: 0.9565\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 0.0888 - accuracy: 0.9565\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 0.0885 - accuracy: 0.9565\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 0.0883 - accuracy: 0.9565\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 0.0880 - accuracy: 0.9565\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 0.0878 - accuracy: 0.9565\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 0.0876 - accuracy: 0.9565\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 0.0873 - accuracy: 0.9565\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 0.0871 - accuracy: 0.9565\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 0.0869 - accuracy: 0.9565\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 0.0866 - accuracy: 0.9565\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 0.0864 - accuracy: 0.9565\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 0.0862 - accuracy: 0.9565\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 0.0860 - accuracy: 0.9565\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 0.0857 - accuracy: 0.9565\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 0.0855 - accuracy: 0.9565\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 0.0853 - accuracy: 0.9565\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 0.0851 - accuracy: 0.9565\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 0.0849 - accuracy: 0.9565\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 0.0847 - accuracy: 0.9565\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 0.0845 - accuracy: 0.9565\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 0.0843 - accuracy: 0.9565\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 0.0841 - accuracy: 0.9565\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 0.0839 - accuracy: 0.9565\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 0.0837 - accuracy: 0.9565\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 0.0835 - accuracy: 0.9565\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 0.0834 - accuracy: 0.9565\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 0.0832 - accuracy: 0.9565\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 0.0830 - accuracy: 0.9565\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 0.0828 - accuracy: 0.9565\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 0.0826 - accuracy: 0.9565\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 0.0825 - accuracy: 0.9565\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 0.0823 - accuracy: 0.9565\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 0.0821 - accuracy: 0.9565\n",
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 0.0820 - accuracy: 0.9565\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 0.0818 - accuracy: 0.9565\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 0.0816 - accuracy: 0.9565\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 0.0815 - accuracy: 0.9565\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 0.0813 - accuracy: 0.9565\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 0.0812 - accuracy: 0.9565\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 0.0810 - accuracy: 0.9565\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 0.0808 - accuracy: 0.9565\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 0.0807 - accuracy: 0.9565\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 0.0805 - accuracy: 0.9565\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 0.0804 - accuracy: 0.9565\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 0.0802 - accuracy: 0.9565\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 0.0801 - accuracy: 0.9565\n",
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 0.0800 - accuracy: 0.9565\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 0.0798 - accuracy: 0.9565\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 0.0797 - accuracy: 0.9565\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 0.0795 - accuracy: 0.9565\n",
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 0.0794 - accuracy: 0.9565\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 0.0793 - accuracy: 0.9565\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 0.0791 - accuracy: 0.9565\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 0.0790 - accuracy: 0.9565\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 0.0789 - accuracy: 0.9565\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 0.0787 - accuracy: 0.9565\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 0.0786 - accuracy: 0.9565\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 0.0785 - accuracy: 0.9565\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 0.0784 - accuracy: 0.9565\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 0.0782 - accuracy: 0.9565\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 0.0781 - accuracy: 0.9565\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 0.0780 - accuracy: 0.9565\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 0.0779 - accuracy: 0.9565\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 0.0778 - accuracy: 0.9565\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 0.0776 - accuracy: 0.9565\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 0.0775 - accuracy: 0.9565\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 0.0774 - accuracy: 0.9565\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 0.0773 - accuracy: 0.9565\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 0.0772 - accuracy: 0.9565\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 0.0771 - accuracy: 0.9565\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 0.0770 - accuracy: 0.9565\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 0.0768 - accuracy: 0.9565\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 0.0767 - accuracy: 0.9565\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 0.0766 - accuracy: 0.9565\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 0.0765 - accuracy: 0.9565\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 0.0764 - accuracy: 0.9565\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 0.0763 - accuracy: 0.9565\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 0.0762 - accuracy: 0.9565\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 0.0761 - accuracy: 0.9565\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 0.0760 - accuracy: 0.9565\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 0.0759 - accuracy: 0.9565\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 0.0758 - accuracy: 0.9565\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 0.0757 - accuracy: 0.9565\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 0.0756 - accuracy: 0.9565\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 0.0755 - accuracy: 0.9565\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 0.0754 - accuracy: 0.9565\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 0.0753 - accuracy: 0.9565\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 0.0752 - accuracy: 0.9565\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 0.0752 - accuracy: 0.9565\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 0.0751 - accuracy: 0.9565\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 0.0750 - accuracy: 0.9565\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 0.0749 - accuracy: 0.9565\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 0.0748 - accuracy: 0.9565\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 0.0747 - accuracy: 0.9565\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 0.0746 - accuracy: 0.9565\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 0.0745 - accuracy: 0.9565\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 0.0745 - accuracy: 0.9565\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 0.0744 - accuracy: 0.9565\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 0.0743 - accuracy: 0.9565\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 0.0742 - accuracy: 0.9565\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 0.0741 - accuracy: 0.9565\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 0.0740 - accuracy: 0.9565\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 0.0740 - accuracy: 0.9565\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 0.0739 - accuracy: 0.9565\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 0.0738 - accuracy: 0.9565\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 0.0737 - accuracy: 0.9565\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 0.0736 - accuracy: 0.9565\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 0.0736 - accuracy: 0.9565\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 0.0735 - accuracy: 0.9565\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 0.0734 - accuracy: 0.9565\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 0.0733 - accuracy: 0.9565\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 0.0733 - accuracy: 0.9565\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 0.0732 - accuracy: 0.9565\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 0.0731 - accuracy: 0.9565\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 0.0731 - accuracy: 0.9565\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 0.0730 - accuracy: 0.9565\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 0.0729 - accuracy: 0.9565\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 0.0728 - accuracy: 0.9565\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 0.0728 - accuracy: 0.9565\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 0.0727 - accuracy: 0.9565\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 0.0726 - accuracy: 0.9565\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 0.0726 - accuracy: 0.9565\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 0.0725 - accuracy: 0.9565\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 0.0724 - accuracy: 0.9565\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 0.0724 - accuracy: 0.9565\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 0.0723 - accuracy: 0.9565\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 0.0722 - accuracy: 0.9565\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 0.0722 - accuracy: 0.9565\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 0.0721 - accuracy: 0.9565\n",
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 0.0720 - accuracy: 0.9565\n",
      "Jack and jill went up the hill\n",
      "And Jill went up the\n",
      "fell down and broke his crown and\n",
      "pail of water jack fell down and\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "  in_text = seed_text\n",
    "  # generate a fixed number of words\n",
    "  for _ in range(n_words):\n",
    "    # encode the text as integer\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    # pre-pad sequences to a fixed length\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre') \n",
    "    # predict probabilities for each word\n",
    "    predict_x=model.predict(encoded, verbose=0) \n",
    "    yhat=np.argmax(predict_x,axis=1)\n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "     if index == yhat:\n",
    "       out_word = word\n",
    "       break\n",
    "    # append to input\n",
    "    in_text += ' ' + out_word \n",
    "  return in_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "  model.add(LSTM(50))\n",
    "  model.add(Dense(vocab_size, activation='softmax'))\n",
    "  # compile network\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "  # summarize defined model\n",
    "  model.summary()\n",
    "  plot_model(model, to_file='model.png', show_shapes=True)\n",
    "  return model\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "    To fetch a pail of water\\n\n",
    "    Jack fell down and broke his crown\\n\n",
    "    And Jill came tumbling after\\n \"\"\"\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0] \n",
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "  sequence = encoded[i-2:i+1]\n",
    "  sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(vocab_size, max_length)\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5)) \n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3)) \n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5)) \n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCs4jgyXM3vV"
   },
   "source": [
    "# 3. Develop a Neural Language Model for Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNktm5jULgg4"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "# open the file as read only file = open(filename, 'r')\n",
    "# read all text\n",
    "text = file.read()\n",
    "# close the file file.close()\n",
    "return text\n",
    "\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size, seq_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "  model.add(LSTM(100, return_sequences=True))\n",
    "  model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # summarize defined model\n",
    "model.summary()\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "return model\n",
    "# load\n",
    "in_filename = 'republic_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer() tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines) # vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    "# define model\n",
    "model = define_model(vocab_size, seq_length)\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=100)\n",
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOtR2RJgSvUgu6YF53vC2/E",
   "collapsed_sections": [],
   "mount_file_id": "1DxsbxJPeY13KcadvtegR3qDbgbuAru03",
   "name": "Language Modeling .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
