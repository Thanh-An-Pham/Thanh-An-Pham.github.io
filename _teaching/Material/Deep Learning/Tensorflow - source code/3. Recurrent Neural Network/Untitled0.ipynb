{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"mount_file_id":"155wMtz9TDgGg7DtnzqibJtOMTiX6qmHe","authorship_tag":"ABX9TyP+bpuwebqDzs01nQsZj/H3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eBMATqFBvJSH"},"source":["import string\n","import re\n","from os import listdir\n","from collections import Counter\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","\n","class vocab:\n","  def __init__(self, filename):\n","    self.filename = filename\n","    self.vocab = Counter()\n"," \n","  # 1. load doc into memory\n","  def load_doc(self):\n","    # open the file as read only\n","    file = open(self.filename, 'r')\n","    # read all text\n","    text = file.read()\n","    #close the file\n","    file.close()\n","    return text\n","\n","  # 2. turn a doc into clean tokens\n","  def clean_doc(doc):\n","    # split into tokens by white space\n","    tokens = doc.split()\n","    # prepare regex for char filtering\n","    re_punc = re.compile('[%s]'% re.escape(string.punctuation))\n","    # remove punctuation from each word\n","    tokens = [re_punc.sub('',w) for w in tokens]\n","    # remove remaining tokens that are not alphabetic\n","    tokens = [word for word in tokens if word.isalpha()]\n","    # filter out stop word\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [w for w in tokens if not w in stop_words]\n","    # filter out short tokens\n","    tokens = [word for word in tokens if len(word) >1]\n","    return tokens\n","\n","    # 3. load doc and add to vocab\n","  def add_doc_to_vocab(filename, vocab):\n","    # load doc\n","    doc = self.load_doc()\n","    # clean doc\n","    tokens = self.clean_doc(doc)\n","    # update counts\n","    self.vocab.update(tokens)\n","\n","  # 4. load all docs in a directory\n","  def process_docs(directory, vocab):\n","    # walk through that do not have the right extensions\n","    for filename in listdir(directory):\n","      if not filename.endswith('.txt'):\n","        next\n","    # create path\n","      path = directory + '/' + filename\n","    # add doc to vocab\n","      add_doc_to_vocab(path, vocab)\n","\n","  # 5. Activate\n"],"execution_count":null,"outputs":[]}]}